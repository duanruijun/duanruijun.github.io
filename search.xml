<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[zabbix监控项目接口]]></title>
    <url>%2F2019%2F10%2F10%2Fzabbix%E7%9B%91%E6%8E%A7%E9%A1%B9%E7%9B%AE%E6%8E%A5%E5%8F%A3%2F</url>
    <content type="text"><![CDATA[## 背景国庆期间出现项目访问异常，zabbix也没报警。通过线上日志排查，初步判断是由于内存溢出导致，在项目接口方面由于没做监控，导致不能及时发现和响应问题。急需监控处理 解决方案考虑到后续域名动态更新及维护效率，把所有域名放置gitlab中，每次监控程序自动刷新配置，有问题则直接报警，代码如下： 1234567891011121314151617181920212223242526272829303132333435363738394041[root@support zabbix]# cat checkDomainApi.py # -*- coding: UTF-8 -*-# @File : checkDomainApi.py# @Time : 2019/10/10# @Author : Duan.rj&apos;&apos;&apos;说明； git中获取最新接口文件(domainApiList)，判断文件内所有接口是否异常(正常为True，其他都为异常) \ 如有异常则发送异常api&apos;&apos;&apos;import urllib2domainFileDir = &apos;/opt/Script&apos;domainFile = domainFileDir + &apos;/domainApiList&apos;domainErrorList = []# 获取最新文件with open(domainFile) as f: domainUrls = f.readlines() # readlines读取时会带 &quot;\n&quot;换行符，需要二次过滤 domainUrlsList = &apos;&apos;.join(domainUrls).strip(&apos;\n&apos;).splitlines() for domainUrl in domainUrlsList: try: getValue = urllib2.urlopen(&apos;http://&apos; + domainUrl + &apos;/monit/heartbeat&apos;) if getValue.read() != &apos;true&apos;: domainErrorList.append(domainUrl) except Exception: domainErrorList.append(domainUrl)if domainErrorList != []: for domainUrl in domainErrorList: print(&apos;GET &quot;&apos; + domainUrl + &apos;&quot; API Error!&apos;)else: print(0) 要想避免脚本或者监控的域名文件(这里是domainApiList)每次不能实时更新，推荐使用crontab定时更新： 123[root@support zabbix]# crontab -l# check domain script and domain file00 */1 * * * cd /opt/Script/ops/zabbix;git pull 2&gt;&amp;1 &gt;&gt; /var/log/messages 这样，本地有任何改动，当push到git server后，服务端就会定期更新。 zabbix配置新建模板，并定义监控项和触发器，由于异常返回为字符串，注意在监控项中信息类型要配置正确 触发器配置 当域名有问题时，收到报警如下： 完。]]></content>
      <categories>
        <category>Server</category>
      </categories>
      <tags>
        <tag>zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker学习笔记]]></title>
    <url>%2F2019%2F09%2F27%2Fdocker%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[docker学习笔记镜像操作搜索镜像docker search 镜像名称 123456789[root@bogon ~]# docker search centosINDEX NAME DESCRIPTION STARS OFFICIAL AUTOMATEDdocker.io docker.io/centos The official build of CentOS. 5571 [OK] docker.io docker.io/ansible/centos7-ansible Ansible on Centos7 123 [OK]docker.io docker.io/jdeathe/centos-ssh OpenSSH / Supervisor / EPEL/IUS/SCL Repos ... 112 [OK]docker.io docker.io/consol/centos-xfce-vnc Centos container with &quot;headless&quot; VNC sessi... 99 [OK]docker.io docker.io/centos/mysql-57-centos7 MySQL 5.7 SQL database server 63 docker.io docker.io/imagine10255/centos6-lnmp-php56 centos6-lnmp-php56 57 [OK].... 获取镜像docker pull 镜像名称 12345678# 示例[root@bogon ~]# docker pull docker.io/centosUsing default tag: latestTrying to pull repository docker.io/library/centos ... latest: Pulling from docker.io/library/centosd8d02d457314: Pull complete Digest: sha256:307835c385f656ec2e2fec602cf093224173c51119bbebd602c53c3653a3d6ebStatus: Downloaded newer image for docker.io/centos:latest 查看镜像信息docker images 12345# 示例[root@bogon ~]# docker imagesREPOSITORY TAG IMAGE ID CREATED SIZEtest latest adca3d04a9c3 9 minutes ago 202 MBdocker.io/centos latest 67fa590cfc1c 4 weeks ago 202 MB 删除镜像docker rmi 镜像名称 1234# 示例[root@bogon ~]# docker rmi centosUntagged: centos:latestUntagged: docker.io/centos@sha256:307835c385f656ec2e2fec602cf093224173c51119bbebd602c53c3653a3d6eb 创建镜像基于已有镜像的容器创建docker commit … 123-a, --author=&quot;&quot; 作者信息-m, --message=&quot;&quot; 提交信息-p, --pause==true 提交时暂停容器运行 123456789101112131415161718# 示例[root@bogon ~]# docker imagesREPOSITORY TAG IMAGE ID CREATED SIZEdocker.io/centos latest 67fa590cfc1c 4 weeks ago 202 MB[root@bogon ~]# docker run -ti docker.io/centos /bin/bash[root@507ae2970ce5 /]# touch test[root@507ae2970ce5 /]# exit[root@bogon ~]# docker commit -m &quot;add a new file&quot; -a &quot;Duan.rj&quot; 507ae2970ce5 testsha256:adca3d04a9c3857e0debf1814ebf68c639bb013630910adcbcb2463b05044f12# 成功后会返回新创建的镜像ID，如上图# 查看新创建的镜像：[root@bogon ~]# docker imagesREPOSITORY TAG IMAGE ID CREATED SIZEtest latest adca3d04a9c3 56 seconds ago 202 MBdocker.io/centos latest 67fa590cfc1c 4 weeks ago 202 MB 容器操作新建容器docker create -it … 123456# 示例[root@bogon ~]# docker create -it centos:latest3f1b6af49bb02c329b1cd9ad9414797978963a3909477e0b2dfce125860d571c[root@bogon ~]# docker ps -aCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES3f1b6af49bb0 centos:latest &quot;/bin/bash&quot; 17 seconds ago Created flamboyant_easley 上述为新建一个容器，但是处于停止状态，可以使用docker start命令启动它。 123456# 示例[root@bogon ~]# docker start 3f1b6af49bb03f1b6af49bb0[root@bogon ~]# docker ps -aCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES3f1b6af49bb0 centos:latest &quot;/bin/bash&quot; 3 minutes ago Up 4 seconds flamboyant_easley 新建并启动容器启动容器有两种方式，一种是基于镜像新建一个容器并启动，另外一种是将在终止状态的容器重新启动。所需命令为docker run，等价于先执行docker create命令，再执行docker start命令。 1234567# 示例[root@bogon ~]# docker run centos /bin/echo &quot;Hello world&quot;Hello world[root@bogon ~]# docker ps -aCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMESc2ded0c4a577 centos &quot;/bin/echo &apos;Hello ...&quot; 4 seconds ago Exited (0) 3 seconds ago silly_hoover3f1b6af49bb0 centos:latest &quot;/bin/bash&quot; 9 minutes ago Up 5 minutes flamboyant_easley 启动一个bash终端，允许用户进行交互：123456789101112# 示例[root@bogon ~]# docker run -t -i centos /bin/bash[root@a61f9ada2179 /]# pwd/[root@a61f9ada2179 /]# lsanaconda-post.log bin dev etc home lib lib64 media mnt opt proc root run sbin srv sys tmp usr var[root@a61f9ada2179 /]# ps PID TTY TIME CMD 1 ? 00:00:00 bash 15 ? 00:00:00 ps[root@a61f9ada2179 /]# exitexit 守护状态运行通过“-d”参数实现 1234567891011# 示例[root@bogon ~]# docker run -d centos /bin/sh -c &quot;while true;do echo hello world; sleep 1;done&quot;4ef71250e5e534176e7b3ff59f238b26b771612707a415786d0433ee3eea9859[root@bogon ~]# docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES4ef71250e5e5 centos &quot;/bin/sh -c &apos;while...&quot; 6 seconds ago Up 5 seconds vibrant_wiles3f1b6af49bb0 centos:latest &quot;/bin/bash&quot; 14 minutes ago Up 10 minutes flamboyant_easley[root@bogon ~]# docker logs 4ef7hello worldhello world... 终止容器可以通过docker stop终止运行中的容器，命令格式为docker stop [-t|—time[=10]]。它会首先向容器发送SIGTERM信号，等待一段时间后（默认为10秒），再发送SIGKILL信号终止容器 12345678910# 示例[root@bogon ~]# docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES4ef71250e5e5 centos &quot;/bin/sh -c &apos;while...&quot; 7 minutes ago Up 7 minutes vibrant_wiles3f1b6af49bb0 centos:latest &quot;/bin/bash&quot; 21 minutes ago Up 18 minutes flamboyant_easley[root@bogon ~]# docker stop 4ef71250e5e54ef71250e5e5[root@bogon ~]# docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES3f1b6af49bb0 centos:latest &quot;/bin/bash&quot; 22 minutes ago Up 18 minutes flamboyant_easley 进入容器在使用-d进入后台后，如果需要进入容器进行操作，可以使用docker attach、docker exec、nsenter工具等。 docker attach1234567# 示例[root@bogon ~]# docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES3f1b6af49bb0 centos:latest &quot;/bin/bash&quot; 32 minutes ago Up 28 minutes flamboyant_easley[root@bogon ~]# docker exec -ti 3f1b6af49bb0 /bin/bash[root@3f1b6af49bb0 /]# lsanaconda-post.log bin dev etc home lib lib64 media mnt opt proc root run sbin srv sys tmp usr var 删除容器docker rm删除一个处于停止状态的容器 123-f, --force=false 强行终止并删除一个运行中的容器。-l, --link=false 删除容器的连接，但保留容器。-v, --volumes=false 删除容器挂载的数据卷。 12345678910111213141516171819202122# 示例[root@bogon ~]# docker ps -aCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES4482fc316c14 centos &quot;/bin/bash&quot; 6 minutes ago Exited (0) 4 minutes ago nifty_jennings4ef71250e5e5 centos &quot;/bin/sh -c &apos;while...&quot; 22 minutes ago Exited (137) 14 minutes ago vibrant_wilesa61f9ada2179 centos &quot;/bin/bash&quot; 25 minutes ago Exited (0) 25 minutes ago vibrant_brattainc2ded0c4a577 centos &quot;/bin/echo &apos;Hello ...&quot; 27 minutes ago Exited (0) 27 minutes ago silly_hoover3f1b6af49bb0 centos:latest &quot;/bin/bash&quot; 36 minutes ago Up 32 minutes flamboyant_easley1fa5a642a73d test &quot;/bin/bash&quot; 58 minutes ago Exited (0) 58 minutes ago brave_meitner507ae2970ce5 docker.io/centos &quot;/bin/bash&quot; About an hour ago Exited (0) About an hour ago xenodochial_wiles[root@bogon ~]# docker rm 4482fc316c144482fc316c14[root@bogon ~]# docker ps -aCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES4ef71250e5e5 centos &quot;/bin/sh -c &apos;while...&quot; 23 minutes ago Exited (137) 14 minutes ago vibrant_wilesa61f9ada2179 centos &quot;/bin/bash&quot; 26 minutes ago Exited (0) 26 minutes ago vibrant_brattainc2ded0c4a577 centos &quot;/bin/echo &apos;Hello ...&quot; 28 minutes ago Exited (0) 28 minutes ago silly_hoover3f1b6af49bb0 centos:latest &quot;/bin/bash&quot; 37 minutes ago Up 33 minutes flamboyant_easley1fa5a642a73d test &quot;/bin/bash&quot; 58 minutes ago Exited (0) 58 minutes ago brave_meitner507ae2970ce5 docker.io/centos &quot;/bin/bash&quot; About an hour ago Exited (0) About an hour ago xenodochial_wiles 仓库registry镜像方式搭建本地私有仓库12# 示例docker run -d -p 5000:5000 registry 此时，这将下载并启动一个监听5000端口的registry容器，创建本地私有仓库服务。默认情况下，会将仓库创建在容器的/tmp/registry目录下，可以通过-v参数来将镜像文件存放在本地其他指定路径下： 12# 示例docker run -d -p 5000:5000 -v /opt/data/registry:/tmp/registry registry 上传镜像 1234567# 查看镜像[root@bogon tmp]# docker imagesREPOSITORY TAG IMAGE ID CREATED SIZEdocker.io/centos latest 67fa590cfc1c 5 weeks ago 202 MB# docker tag命令将要上传的镜像(docker.io/centos)标记为仓库地址(格式为：docker tag IMAGES[:TAG] [REGISTRYHOST/][USERNAME/]NAME[:TAG]):[root@bogon tmp]# docker tag centos:latest 192.168.1.187:5000/test 192.168.1.187为仓库地址，接下来上传至仓库 1234# 示例[root@bogon tmp]# docker push 192.168.1.187:5000/testThe push refers to a repository [192.168.1.187:5000/test]Get https://192.168.1.187:5000/v1/_ping: http: server gave HTTP response to HTTPS client 这里出错，提示不是HTTPS协议，docker官方强烈推荐https协议，如果没有，可在docker配置文件中添加“insecure-registries”:[“192.168.1.187:5000”]指定： 123# 示例[root@bogon tmp]# cat /etc/docker/daemon.json &#123; &quot;insecure-registries&quot;:[&quot;192.168.1.187:5000&quot;] &#125; 重启docker并再次push操作 123456# 示例[root@bogon tmp]# systemctl restart docker[root@bogon tmp]# docker push 192.168.1.187:5000/testThe push refers to a repository [192.168.1.187:5000/test]877b494a9f30: Pushed latest: digest: sha256:a36b9e68613d07eec4ef553da84d0012a5ca5ae4a830cf825bb68b929475c869 size: 529 这样，就能push上去了，可在其他docker客户端配置中下载： 123456789101112# 示例[root@localhost ~]# docker pull 192.168.1.187:5000/testUsing default tag: latestTrying to pull repository 192.168.1.187:5000/test ... latest: Pulling from 192.168.1.187:5000/testd8d02d457314: Pull complete Digest: sha256:a36b9e68613d07eec4ef553da84d0012a5ca5ae4a830cf825bb68b929475c869Status: Downloaded newer image for 192.168.1.187:5000/test:latest[root@localhost ~]# docker imagesREPOSITORY TAG IMAGE ID CREATED SIZE192.168.1.187:5000/test latest 67fa590cfc1c 5 weeks ago 202 MB 数据管理数据卷(volume)配置与本地host主机挂载，配置选项-v: 123456789101112131415161718192021# 示例[root@bogon ~]# docker run --name b2 -it -v /data centos[root@fa04a6cb63cf /]# #宿主机上查看b2容器的挂载情况[root@bogon ~]# docker inspect b2...&quot;Mounts&quot;: [ &#123; &quot;Type&quot;: &quot;volume&quot;, &quot;Name&quot;: &quot;d40f1da12c8409119d25d847b9e17242d3ae2fe4bca7936764c04446b87cee44&quot;, &quot;Source&quot;: &quot;/var/lib/docker/volumes/d40f1da12c8409119d25d847b9e17242d3ae2fe4bca7936764c04446b87cee44/_data&quot;, ... &#125; ],&quot;Config&quot;: &#123; ... &quot;Volumes&quot;: &#123; &quot;/data&quot;: &#123;&#125; &#125;, ... 上述配置信息看到b2相关的volume存储位置在/data目录中，而挂载的宿主机的位置为：/var/lib/docker/volumes/d40f1da12c8409119d25d847b9e17242d3ae2fe4bca7936764c04446b87cee44/_data，我们可以在宿主机的这个目录中和b2的volume中分别测试验证挂载： 12345678# 示例# 宿主机执行[root@bogon ~]# cd /var/lib/docker/volumes/d40f1da12c8409119d25d847b9e17242d3ae2fe4bca7936764c04446b87cee44/_data/[root@bogon _data]# echo &quot;hello container&quot; &gt;&gt; test.html# b2容器执行[root@fa04a6cb63cf /]# cat data/test.html hello container 可以看到挂载成功，如果我们要指定宿主机的挂载位置只要在选项参数-v后添加相关位置即可，格式为：-v 宿主机位置:容器位置（例如：-v /data/volume/b2:/data），这种别称为绑定挂载卷 12# 示例[root@bogon ~]# docker run --name b2 -it -v /data/volume/b2:/data centos 把容器b2的/data目录挂载至宿主机的/data/volume/b2目录下，这样访问容器b2的/data目录中的数据实际是访问的宿主机的/data/volume/b2目录下的数据资源。 12345678910111213141516# 示例[root@bogon _data]# docker inspect b2[ ... &quot;Mounts&quot;: [ &#123; &quot;Type&quot;: &quot;bind&quot;, &quot;Source&quot;: &quot;/data/volume/b2&quot;, &quot;Destination&quot;: &quot;/data&quot;, &quot;Mode&quot;: &quot;&quot;, &quot;RW&quot;: true, &quot;Propagation&quot;: &quot;rprivate&quot; &#125; ], ...] docker容器网络容器虚拟化网络大家知道Linux内核支持六中名称空间： UTS 管理主机名和域名 User 用户管理 Mount 挂载管理 IPC 管理进程间通信 Pid 进程id Net 网络管理 所谓网络名称空间是为了协议栈的隔离 未完待续。。。]]></content>
      <categories>
        <category>Server</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[jenkinsfile声明式流水线配置说明]]></title>
    <url>%2F2019%2F05%2F15%2Fjenkinsfile%E5%A3%B0%E6%98%8E%E5%BC%8F%E6%B5%81%E6%B0%B4%E7%BA%BF%E9%85%8D%E7%BD%AE%E8%AF%B4%E6%98%8E%2F</url>
    <content type="text"><![CDATA[jenkinsfile声明式流水线配置说明声明式流水线结构说明 主要模块介绍 pipeline pipeline模块是Jenkins声明式流水线中必须的，它是最外面的部分，同时也是一个流水线项目的标志，其语法为pipeline {},其他的代码都放在这个闭包里 123pipeline &#123; // 流水线代码区域&#125; agent 指定整个流水线或者一个特定阶段在哪运行，在pipeline代码块中，必须要有一个agent指令用来指定默认的执行节点。然而在单个阶段的开始也可以可选地使用一个agent指令，用来指定该阶段应该在哪执行 123456agent any 可运行在任何一个定义好的代理节点上agent none 需要为单个阶段指定代理节点agent &#123; label &quot;&lt;label&gt;&quot;&#125; 流水线可以运行任意一个具有&lt;lable&gt;标签的代理节点上 environment 可选指令，设置环境变量 123456pipeline &#123; agent any environment &#123; TIMEZONE = 'Shanghai' &#125;&#125; 上述代码为定义一个TIMEZONE的变量，稍后会在后续例子中介绍调用。 options 可选参数，指定在jenkins配置选项中的一些配置值，例如输出带时间戳，构建历史保留次数等等 1234options &#123; // 操作台输出日志(需要安装timestamps插件) timestamps() &#125; timestamps需要额外安装Timestamper插件才能使用。 后续待更新。。。]]></content>
      <categories>
        <category>Server</category>
      </categories>
      <tags>
        <tag>jenkins</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[jenkins基本使用]]></title>
    <url>%2F2019%2F02%2F15%2Fjenkins%E8%87%AA%E5%AE%9A%E4%B9%89tag%2F</url>
    <content type="text"><![CDATA[创建证书步骤证书存放目录123cd /home/gitsource/mkdir &lt;item_name&gt;cd &lt;item_name&gt; 创建全局存储证书1git config --global credential.helper store 获取版本(账号|密码)1git clone &lt;Gitlab_url&gt; 获取tag列表1git ls-remote -h -t &lt;Gitlab_url&gt; refs/tags/* Jenkins配置添加动态选择变量12345678910111213141516171819202122232425262728# 创建变量参数Dynamic Choice ParameterName =&gt;select_tagChoices =&gt;proc1 = [&apos;/bin/bash&apos;, &apos;-c&apos;, &quot;git ls-remote -h -t http://git.epailive.com/epailive/phpweb.git refs/tags/v* &quot;].execute()proc2 = [&apos;/bin/bash&apos;, &apos;-c&apos;, &quot;awk &apos;&#123;print \$2&#125;&apos;&quot;].execute()proc3 = [&apos;/bin/bash&apos;, &apos;-c&apos;, &quot;sed s%^refs/heads%origin%&quot;].execute()proc4 = [&apos;/bin/bash&apos;, &apos;-c&apos;, &quot;sort -nr&quot;].execute()proc5 = [&apos;/bin/bash&apos;, &apos;-c&apos;, &quot;grep -v &#123;&#125;&quot;].execute()all = proc1 | proc2 | proc3 | proc4 |proc5String result = all.textresult.tokenize()=&gt; 更改后，获取的字符串确实不用sed替换proc1 = [&apos;/bin/bash&apos;, &apos;-c&apos;, &quot;git ls-remote -h -t http://git.epailive.com/epailive/phpweb.git refs/tags/v* &quot;].execute()proc2 = [&apos;/bin/bash&apos;, &apos;-c&apos;, &quot;awk &apos;&#123;print \$2&#125;&apos;&quot;].execute()proc3 = [&apos;/bin/bash&apos;, &apos;-c&apos;, &quot;sort -nr&quot;].execute()proc4 = [&apos;/bin/bash&apos;, &apos;-c&apos;, &quot;grep -v &#123;&#125;&quot;].execute()all = proc1 | proc2 | proc3 | proc4String result = all.textresult.tokenize() 修改gitlab拉取规则123456789101112131415# 资源管理Git# Repository URL&lt;gitlab url&gt;# Credentials账号密码# Branch Specifier (blank for &apos;any&apos;)$&#123;select_tag&#125;# Additional Behaviours## check out to a sub-directory$&#123;BUILD_TAG&#125; //内置变量]]></content>
      <categories>
        <category>Server</category>
      </categories>
      <tags>
        <tag>jenkins</tag>
      </tags>
  </entry>
  <entry>
    <title></title>
    <url>%2F2018%2F05%2F11%2Fpython_%E8%A3%85%E9%A5%B0%E5%99%A8%2F</url>
    <content type="text"><![CDATA[函数带参数 #-*- coding:utf-8 -*- def outer(fun): def wrapper(arg): print_r('验证') fun(arg) print_r('你好') @outer def Func1(arg): print_r('func1', arg) return 'return' a = Func1('sundshinerj') print_r(a) 结果 验证 func1 sundshinerj nihao return]]></content>
  </entry>
  <entry>
    <title></title>
    <url>%2F2018%2F03%2F13%2Fcentos7.5%E5%86%85%E5%AE%B9%E5%B4%A9%E6%BA%83%2F</url>
    <content type="text"><![CDATA[问题描述公司一台dell服务器(dell 2950)在正常运行后突然出现系统内容崩溃，开机启动加载centos7.5后出现如下图： ， 思考出现此类问题后，第一时间马上整理宕机后的问题： 业务影响范围？ 什么原因导致的？ 如何修复系统？ 带着问题去解决 业务影响范围 根据第一时间的了解和公司业务信息查阅，此服务器只影响公司人员正常使用文档库，系统宕机在周五晚上，公司人员在休息中使用较少，所以影响范围不大，但是里面数据集成了公司日常的工作内容，需要加急处理。 什么原因导致的 服务器在此前迁移时有一次意外停机，通过人工启动后一直运行正常，但是最近有出现SSH服务连接异常(ICMP测试没问题)，对外提供的服务也正常运行，通过宿主机连接查看系统日志无异常行为，所以修复优先级排后，后来发现问题原因基本是因此次意外宕机造成的。 如何修复系统 在修复前准备工作中，考虑了几个修复方案：光盘修复工具、raid修复系统、系统盘挂载至其他服务器上修复并copy数据、U盘可读写方式进入系统挂载并copy数据，如果修复比较困难，应立即做好数据迁移准备：准备新环境（由于文档库的附件资料存在服务器中，内容信息存在数据库中(数据和附件不在同一台服务器上)，所以重点考虑附件的恢复）。 光盘镜像修复工具 通过光盘镜像挂载选择系统急救模式进入系统后发现init丢失，lib库及命令也同样丢失，通过自行尝试修复及网上资料查阅也无济于事。可见问题已经难以解决，所以，应当采取第二个措施，数据的copy及新环境的准备(光盘镜像中挂载U盘需要安装驱动，安装失败，放弃)。 raid修复系统 此服务器做的是raid1，在raid配置中尝试修复，没有成功，放弃。 挂载至其他服务器上 系统盘挂载其他服务器上，不识别，放弃。 U盘启动COPY数据 通过U盘启动并进入系统急救模式，参照提示切换至系统(chroot /mnt/images)，查看源数据无损坏，并挂载U盘(成功)，进行数据的copy并迁移至新环境中，成功。 总结前前后后折腾了一天时间，好歹问题出在放假途中，对员工使用影响很少，有大量的时间去查阅问题资料，造成这种问题的主要原因有几个： 系统单点没做好冗余； 数据的存储没做好备份或者进行分布式存储策略； 当问题已经开始有不好的预兆时应及时处理。]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>centos7.5 内容崩溃</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[jenkins maven项目实战1]]></title>
    <url>%2F2018%2F03%2F07%2Fjenkins_maven%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%981%2F</url>
    <content type="text"><![CDATA[环境 gitlab: http://192.168.62.206 jenkins: http://192.168.62.210:8080 depserver: 192.168.63.116 实例说明 gitlab工程地址：git@192.168.62.206:Mall/eureka.git jenkins构建完成后本地存放位置：/target depserver工程目录：/home/jiagouzu/tingyun/target/ 流程 jenkins通过gitlab pull工程代码 jenkins通过本地maven工具构建、打包工程代码 jenkins把完成的.jar推送到服务器相应目录下 注意事项 jenkins pull代码时，gitlab要确保有jenkins的Deploy key key信息 gitlab的项目“Mall/eureka”启用deploy key(settings–&gt; Repository–&gt;Deploy Keys)： jenkins配置说明jenkins配置depServer节点 添加depserver服务器节点（系统管理–&gt;系统设置–&gt;SSH Servers） 新建一个Server,完成后选择高级配置相关信息： 其他保持默认，最后选择Test Configuration可测试下 配置拉取gitlab地址私钥信息这里就不多讲了，具体步骤可见jenkins基本使用 创建项目 新建一个项目，类型为自由风格的（maven类型有很多限制），这里我的名称为“商城” 配置“商城”，在General标签里配置相关信息，注意点开“高级”选择“使用自定义的工作空间” 源码管理 构建触发器 手动还是自动构建，这里也可以看之前的文章jenkins基本使用 构建环境 构建（mvn命令执行构建） 这里注意mvn命令的位置，jenkins默认安装选择在 /home/apache-maven-3.5.2/bin/mvn 可通过（系统管理–&gt;全局工具配置）进行相应的更改，但要给予jenkins执行的权限，这里我把命令ln到/usr/local/bin目录下，chmod +x mvn 如果没有设置会报类似错误： [/target] $ /bin/sh -xe /tmp/jenkins6497126245319590786.sh + mvn clean package /tmp/jenkins6497126245319590786.sh: line 2: mvn: command not found Build step 'Execute shell' marked build as failure SSH: Current build result is [FAILURE], not going to run. 构建后操作（完成构建后的部署工作） 选择“Send build artifacts over SSH”,注意要安装 over ssh插件 注意： 这里的Remote directory指的就是前面配置depserver的工程目录地址“/home/jiagouzu/tingyun” 点击完成后就可以测试了，默认maven构建的配置文件直接找的官方地址，在构建日志当中会出现如下信息 https://repo.maven.apache.org/maven2/org/hibernate/hibernate-validator/5.3.6.Final/hibernate-validator-5.3.6.Final.jar (727 kB at 2.4 kB/s) Downloading from central: https://repo.maven.apache.org/maven2/org/springframework/boot/spring-boot-starter-actuator/1.5.9.RELEASE/spring-boot-starter-actuator-1.5.9.RELEASE.jar 这里需要注意： 第一次构建时，maven需要下载部署工程所需要的jar包； 改善办法之一是同开发要一份maven构建工具的settings.xml 配置文件替换你的maven工具里的settings.xml（一般开发会有自己的内部仓库），在这里是我的jenkins服务器中的“/home/apache-maven-3.5.2/conf/settings.xml”，注意修改里面的“/MavenRepository”这是指你存放maven工具所需jar包的目录，别忘了给jenkins能执行的权限。 最后测试输出类似信息证明配置成功： [INFO] BUILD SUCCESS [INFO] ------------------------------------------------------------------------ [INFO] Total time: 4.246 s [INFO] Finished at: 2018-03-07T14:54:53+08:00 [INFO] Final Memory: 36M/203M [INFO] ------------------------------------------------------------------------ SSH: Failed to get hostname [192v168v62v210: 192v168v62v210: 未知的名称或服务] SSH: Connecting with configuration [192.168.63.116] ... SSH: EXEC: STDOUT/STDERR from command [/bin/bash /home/mall_start.sh start] ... SSH: EXEC: completed after 200 ms SSH: Disconnecting configuration [192.168.63.116] ... SSH: Transferred 1 file(s) Finished: SUCCESS]]></content>
      <categories>
        <category>Server</category>
      </categories>
      <tags>
        <tag>jenkins</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一次数据表损坏的修复过程]]></title>
    <url>%2F2017%2F12%2F15%2FMySQL_%E4%B8%80%E6%AC%A1%E6%95%B0%E6%8D%AE%E8%A1%A8%E6%8D%9F%E5%9D%8F%E8%AE%B0%E5%BD%95%E4%BF%AE%E5%A4%8D%2F</url>
    <content type="text"><![CDATA[一、数据库表损坏现象mysql数据库非正常停止，导致所有数据库（除自身数据库信息）信息表名正常显示，但打开表提示：表不存在，数据库数据存放路径信息显示占用大小正常，证明数据没有丢失，数据库启动报错如下信息： 123456789101112131415161718192021222324252019-01-25 13:46:19 13621 [Note] Server socket created on IP: '::'.2019-01-25 13:46:19 13621 [Warning] InnoDB: Cannot open table mysql/slave_master_info from the internal data dictionary of InnoDB though the .frm file for the table exists. See http://dev.mysql.com/doc/refman/5.6/en/innodb-troubleshooting.html for how you can resolve the problem.2019-01-25 13:46:19 13621 [Warning] Info table is not ready to be used. Table 'mysql.slave_master_info' cannot be opened.2019-01-25 13:46:19 13621 [Warning] InnoDB: Cannot open table mysql/slave_worker_info from the internal data dictionary of InnoDB though the .frm file for the table exists. See http://dev.mysql.com/doc/refman/5.6/en/innodb-troubleshooting.html for how you can resolve the problem.2019-01-25 13:46:19 13621 [Warning] InnoDB: Cannot open table mysql/slave_relay_log_info from the internal data dictionary of InnoDB though the .frm file for the table exists. See http://dev.mysql.com/doc/refman/5.6/en/innodb-troubleshooting.html for how you can resolve the problem.2019-01-25 13:46:19 13621 [Warning] Info table is not ready to be used. Table 'mysql.slave_relay_log_info' cannot be opened.2019-01-25 13:46:19 13621 [Note] Event Scheduler: Loaded 0 events2019-01-25 13:46:19 13621 [Note] /usr/local/mysql/bin/mysqld: ready for connections.Version: '5.6.29-log' socket: '/usr/local/mysql/mysqld.sock' port: 3306 Source distribution2019-01-25 13:47:23 13621 [Note] /usr/local/mysql/bin/mysqld: Normal shutdown 上述日志获取到： InnoDB: Cannot open table mysql/slave_worker_info from the internal data dictionary of InnoDB though the .frm file for the table exists. 尽管表“slave_worker_info”已经存在，但是获取不到信息。而且报大量类似表的错误信息 解决 根据错误提示及尝试打开表操作证明数据没有丢失，只是表丢失而已，把表删除，新建表结构，重新挂在数据节点即可： 备份原始表数据（例如：这里操作auth_user表） 12345ls dataDir auth_user.frm auth_user.ibd 删除表 1DROP TABLE IF EXISTS `auth_user 删除ibd文件 1rm -rf push_user_question_record.ibd 重新创建表 1CREATE TABLE `auth_user 丢弃新建表的表空间 1ALTER TABLE auth_user DISCARD TABLESPACE; 复制备份的数据信息 1\cp /BACKUPDIR/auth_user.* MYSQLDATA/DATABASES/ 授权 1chown -R mysql.mysql base_area.* 挂载数据 1ALTER TABLE auth_user IMPORT TABLESPACE; 二、用户添加索引权限mysql给用户添加索引权限： 1grant index on *.* to username@'%' 注意： 这里只是给用户赋予了添加和删除索引的权限，如果想要修改的话，用户\&lt;username>还需要有alter权限，否则会报如下错误： 11142 - ALTER command denied to user 'xxxx'@'xx.xx.xx.xx' tor table 'TABLE_NAME' 添加alter权限： 1grant alter on xx.xx to username@'xx' 三、停止执行过长的sql1234mysql&gt; show processlist;此时可以看到MySQL中正在运行的进程：mysql&gt; kill [Id NAME]]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ping包检测]]></title>
    <url>%2F2017%2F10%2F10%2Fpython_ping%E5%8C%85%E6%A3%80%E6%B5%8B%2F</url>
    <content type="text"><![CDATA[ping包检测 #!/usr/bin/env python #-*- coding: utf-8 -*- import re import subprocess def check_alive(ip,count=1,timeout=1): ''' ping网络测试,通过调用ping命令,发送一个icmp包，从结果中通过正则匹配是否有100%关键字，有则表示丢包，无则表示正常 ''' cmd = 'ping -c %d -w %d %s' % (count,timeout,ip) p = subprocess.Popen(cmd, stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.PIPE, shell=True ) result = p.stdout.read() regex = re.findall('100% packet loss',result) if len(regex) == 0: print "\033[31m%s UP\033[0m" % (ip) else: print "\033[32m%s DOWN\033[0m" % (ip) if __name__ == "__main__": with file('/root/ip.txt','r') as f: for line in f.readlines(): ip = line.strip() check_alive(ip)]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>python随笔</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[shell文件对比]]></title>
    <url>%2F2017%2F10%2F10%2Fshell%E6%96%87%E4%BB%B6%E5%AF%B9%E6%AF%94%2F</url>
    <content type="text"><![CDATA[#!/bin/bash #----判断给定的文件是否存在---- if [ -d $1 ] && [ -d $2 ];then echo -e "俩个文件夹都存在,开始对俩个文件夹进行比对." else if [ -d $1 ];then echo "不存在文件夹:$2" exit else echo "不存在文件夹:$1" exit fi fi #----判断俩个文件中改动过的文件有哪些---- #判断俩个文件的文件和文件夹的个数 echo -e "\e[1;32m######查询每个文件总共有多少个文件和文件夹######\e[0m" fnum1=`ls -Rl $1|grep -e "^-"|wc -l` fnum2=`ls -Rl $2|grep -e "^-"|wc -l` dnum1=`ls -Rl $1|grep -e "^d"|wc -l` dnum2=`ls -Rl $2|grep -e "^d"|wc -l` echo -e "$1:下总共有\e[1;31m$dnum1\e[0m个文件夹,\e[1;31m$fnum1\e[0m个文件." echo -e "$2:下总共有\e[1;31m$dnum2\e[0m个文件夹,\e[1;31m$fnum2\e[0m个文件." #判断$2中新增或者减少的文件夹和文件有哪些 echo -e "\e[1;32m######查看$2中新增或者减少的文件或文件夹########\e[0m" only1=`diff -rq $1 $2|grep "^Only"|awk '{print $3,$4}'|grep -v "WEB\-INF"` only2=`diff -rq $1 $2|grep "^Only"|awk '{print $3,$4}'|grep "WEB\-INF"` echo -e "$only1" echo -e "\e[1;31m$only2\e[0m" #判断$2中改变的文件有哪些 echo -e "\e[1;32m############查看$2中改变的文件有哪些############\e[0m" change1=`diff -rq $1 $2|grep "^File"|awk '{print $2,"------",$4}'|grep -v "WEB\-INF"` change2=`diff -rq $1 $2|grep "^File"|awk '{print $2,"------",$4}'|grep "WEB\-INF"` echo -e "$change1" echo -e "\e[1;31m$change2\e[0m" #查看版本号是否已经更改 echo -e "\e[1;32m######---------查看是否更改版本号---------######\e[0m" cd $1 if [ -f version.html ];then version1=`cat version.html` else echo -e "\e[1;31m$1没有版本号信息.\e[0m" exit fi cd $2 if [ -f version.html ];then version2=`cat version.html` else echo -e "\e[1;31m$2没有版本号信息.\e[0m" exit fi if [ $version1 == $version2 ];then echo -e "\e[1;31m版本号未改动,$1和$2的版本号为$version1\e[0m" else echo -e "\e[1;31;1m版本号已经改动过\e[0m,$1的版本号为\e[1;31;1m$version1\e[0m,$2的版本号为\e[1;31;1m$version2\e[0m." fi]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>shell随笔</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[记录linux用户操作]]></title>
    <url>%2F2017%2F08%2F23%2Flinux%E8%AE%B0%E5%BD%95%E7%94%A8%E6%88%B7%E6%93%8D%E4%BD%9C%2F</url>
    <content type="text"><![CDATA[记录用户操作追加在 /etc/profilePS1=”whoami@hostname:”‘[$PWD]’historyUSER_IP=who -u am i 2&gt;/dev/null| awk &#39;{print $NF}&#39;|sed -e &#39;s/[()]//g&#39;if [ “$USER_IP” = “” ]thenUSER_IP=hostnamefiif [ ! -d /tmp/dbasky ]thenmkdir /tmp/dbaskychmod 777 /tmp/dbaskyfiif [ ! -d /tmp/dbasky/${LOGNAME} ]thenmkdir /tmp/dbasky/${LOGNAME}chmod 300 /tmp/dbasky/${LOGNAME}fiexport HISTSIZE=4096DT=date &quot;+%Y-%m-%d_%H:%M:%S&quot;export HISTFILE=”/tmp/dbasky/${LOGNAME}/${USER_IP} dbasky.$DT”chmod 600 /tmp/dbasky/${LOGNAME}/dbasky 2&gt;/dev/nullPS1=”whoami@hostname:”‘[$PWD]’historyUSER_IP=who -u am i 2&gt;/dev/null| awk &#39;{print $NF}&#39;|sed -e &#39;s/[()]//g&#39;if [ “$USER_IP” = “” ]thenUSER_IP=hostnamefiif [ ! -d /tmp/dbasky ]thenmkdir /tmp/dbaskychmod 777 /tmp/dbaskyfiif [ ! -d /tmp/dbasky/${LOGNAME} ]thenmkdir /tmp/dbasky/${LOGNAME}chmod 300 /tmp/dbasky/${LOGNAME}fiexport HISTSIZE=4096DT=date &quot;+%Y-%m-%d_%H:%M:%S&quot;export HISTFILE=”/tmp/dbasky/${LOGNAME}/${USER_IP} dbasky.$DT”chmod 600 /tmp/dbasky/${LOGNAME}/dbasky 2&gt;/dev/nullPS1=”whoami@hostname:”‘[$PWD]’historyUSER_IP=who -u am i 2&gt;/dev/null| awk &#39;{print $NF}&#39;|sed -e &#39;s/[()]//g&#39;if [ “$USER_IP” = “” ]thenUSER_IP=hostnamefiif [ ! -d /tmp/dbasky ]thenmkdir /tmp/dbaskychmod 777 /tmp/dbaskyfiif [ ! -d /tmp/dbasky/${LOGNAME} ]thenmkdir /tmp/dbasky/${LOGNAME}chmod 300 /tmp/dbasky/${LOGNAME}fiexport HISTSIZE=4096DT=date &quot;+%Y-%m-%d_%H:%M:%S&quot;export HISTFILE=”/tmp/dbasky/${LOGNAME}/${USER_IP} dbasky.$DT”chmod 600 /tmp/dbasky/${LOGNAME}/dbasky 2&gt;/dev/nullPS1=”whoami@hostname:”‘[$PWD]’historyUSER_IP=who -u am i 2&gt;/dev/null| awk &#39;{print $NF}&#39;|sed -e &#39;s/[()]//g&#39;if [ “$USER_IP” = “” ]thenUSER_IP=hostnamefiif [ ! -d /tmp/dbasky ]thenmkdir /tmp/dbaskychmod 777 /tmp/dbaskyfiif [ ! -d /tmp/dbasky/${LOGNAME} ]thenmkdir /tmp/dbasky/${LOGNAME}chmod 300 /tmp/dbasky/${LOGNAME}fiexport HISTSIZE=4096DT=date &quot;+%Y-%m-%d_%H:%M:%S&quot;export HISTFILE=”/tmp/dbasky/${LOGNAME}/${USER_IP} dbasky.$DT”chmod 600 /tmp/dbasky/${LOGNAME}/dbasky 2&gt;/dev/nullPS1=”whoami@hostname:”‘[$PWD]’historyUSER_IP=who -u am i 2&gt;/dev/null| awk &#39;{print $NF}&#39;|sed -e &#39;s/[()]//g&#39;if [ “$USER_IP” = “” ]thenUSER_IP=hostnamefiif [ ! -d /tmp/dbasky ]thenmkdir /tmp/dbaskychmod 777 /tmp/dbaskyfiif [ ! -d /tmp/dbasky/${LOGNAME} ]thenmkdir /tmp/dbasky/${LOGNAME}chmod 300 /tmp/dbasky/${LOGNAME}fiexport HISTSIZE=4096DT=date &quot;+%Y-%m-%d_%H:%M:%S&quot;export HISTFILE=”/tmp/dbasky/${LOGNAME}/${USER_IP} dbasky.$DT”chmod 600 /tmp/dbasky/${LOGNAME}/dbasky 2&gt;/dev/nullPS1=”whoami@hostname:”‘[$PWD]’historyUSER_IP=who -u am i 2&gt;/dev/null| awk &#39;{print $NF}&#39;|sed -e &#39;s/[()]//g&#39;if [ “$USER_IP” = “” ]thenUSER_IP=hostnamefiif [ ! -d /tmp/dbasky ]thenmkdir /tmp/dbaskychmod 777 /tmp/dbaskyfiif [ ! -d /tmp/dbasky/${LOGNAME} ]thenmkdir /tmp/dbasky/${LOGNAME}chmod 300 /tmp/dbasky/${LOGNAME}fiexport HISTSIZE=4096DT=date &quot;+%Y-%m-%d_%H:%M:%S&quot;export HISTFILE=”/tmp/dbasky/${LOGNAME}/${USER_IP} dbasky.$DT”chmod 600 /tmp/dbasky/${LOGNAME}/dbasky 2&gt;/dev/nullPS1=”whoami@hostname:”‘[$PWD]’historyUSER_IP=who -u am i 2&gt;/dev/null| awk &#39;{print $NF}&#39;|sed -e &#39;s/[()]//g&#39;if [ “$USER_IP” = “” ]thenUSER_IP=hostnamefiif [ ! -d /tmp/dbasky ]thenmkdir /tmp/dbaskychmod 777 /tmp/dbaskyfiif [ ! -d /tmp/dbasky/${LOGNAME} ]thenmkdir /tmp/dbasky/${LOGNAME}chmod 300 /tmp/dbasky/${LOGNAME}fiexport HISTSIZE=4096DT=date &quot;+%Y-%m-%d_%H:%M:%S&quot;export HISTFILE=”/tmp/dbasky/${LOGNAME}/${USER_IP} dbasky.$DT”chmod 600 /tmp/dbasky/${LOGNAME}/dbasky 2&gt;/dev/null]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[http请求方法介绍]]></title>
    <url>%2F2017%2F08%2F23%2Fhttp_%E8%AF%B7%E6%B1%82%E6%96%B9%E6%B3%95%E4%BB%8B%E7%BB%8D%2F</url>
    <content type="text"><![CDATA[HTTP方法（通常也被称为“动作”）告诉服务器一个页面请求要 做 什么。以下是常见 的方法 GET浏览器告诉服务器只要 得到 页面上的信息并发送这些信息。这可能是最常见的 方法。 HEAD浏览器告诉服务器想要得到信息，但是只要得到 信息头 就行了，页面内容不要。 一个应用应该像接受到一个 GET 请求一样运行，但是不传递实际的内容。在 Flask 中，你根本不必理会这个，下层的 Werkzeug 库会为你处理好。 POST浏览器告诉服务器想要向 URL 发表 一些新的信息，服务器必须确保数据被保存好 且只保存了一次。 HTML 表单实际上就是使用这个访求向服务器传送数据的。 PUT与 POST 方法类似，不同的是服务器可能触发多次储存过程而把旧的值覆盖掉。你 可能会问这样做有什么用？这样做是有原因的。假设在传输过程中连接丢失的情况 下，一个处于浏览器和服务器之间的系统可以在不中断的情况下安全地接收第二次 请求。在这种情况下，使用 POST 方法就无法做到了，因为它只被触发一次。 DELETE删除给定位置的信息。 OPTIONS为客户端提供一个查询 URL 支持哪些方法的捷径。从 Flask 0.6 开始，自动为你 实现了这个方法。有趣的是在 HTML4 和 XHTML1 中，表单只能使用 GET 和 POST 方法。但是 JavaScript 和未来的 HTML 标准中可以使用其他的方法。此外， HTTP 近来已经变得相当 流行，浏览器不再只是唯一使用 HTTP 的客户端。比如许多版本控制系统也使用 HTTP 。]]></content>
      <categories>
        <category>Server</category>
      </categories>
      <tags>
        <tag>http</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[常用函数]]></title>
    <url>%2F2017%2F07%2F28%2Fpython_%E5%B8%B8%E7%94%A8%E5%87%BD%E6%95%B0%2F</url>
    <content type="text"><![CDATA[isinstance判断一个对象是否是一个已知的类型，类似 type()isinstance() 与 type() 区别： type() 不会认为子类是一种父类类型，不考虑继承关系。 isinstance() 会认为子类是一种父类类型，考虑继承关系。 例如 class A: pass class B: pass isinstance(A(), A) # reutrn True type(A()) == A # return True isinstance(B(), A) # return True type(B()) == A # return False Iterable判断一个对象是否可迭代 例如 >>> from collections import Iterable >>> isinstance('abc', Iterable) # str是否可迭代 True >>> isinstance([1,2,3], Iterable) # # list是否可迭代 True >>> isinstance(123, Iterable) # 整数是否可迭代 False enumerate把一个list变成索引-元素对，这样就可以在for循环中同时迭代索引和元素本身 例如 >>> for i, value in enumerate(['a', 'b', 'c']): ... print(i, value) ... (0, 'a') (1, 'b') (2, 'c')]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>python随笔</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[正则]]></title>
    <url>%2F2017%2F07%2F20%2Fpython_%E6%AD%A3%E5%88%99%2F</url>
    <content type="text"><![CDATA[正则表达式字符 \d： 数字 \w： 字母 \t： 制表符 . ： 除回车外所有字符 次数 *： 大于等于0 +： 大于等1 {m}： 次数 {m,n}： {3,5}从3到5 re.match和re.searchre.match: 给出的字符串起始位置去匹配 re.search: 整个字符串去匹配 例子 import re result1 = re.match(&apos;\d+&apos;, &apos;a123fdsa234f4532&apos;) result2 = re.search(&apos;\d+&apos;, &apos;a123fdsa234f4532&apos;) print(result1) print(result2) 结果 None &lt;_sre.SRE_Match object; span=(1, 4), match=&apos;123&apos;&gt; 上面可看到，如果没有返回None，否则返回一个对象，如果要取到值则为print(result2.group())。 re.findall一直找到所有相关匹配项（适合一次，100次需要编译一百次）。 例子 result3 = re.findall(&apos;\d+&apos;,&apos;a123fdsa234f4532&apos;) print(result3) 结果 [&apos;123&apos;, &apos;234&apos;, &apos;4532&apos;] re.compile返回一个对象需要用findall函数获取字符串来匹配（适合多次）。 例子 com = re.compile(&apos;\d+&apos;) print(com.findall(&apos;a123fdsa234f4532&apos;)) 结果 [&apos;123&apos;, &apos;234&apos;, &apos;4532&apos;] re.group和re.groups re.group： 获取所有 re.groups：（只获取组里面（括号里）的匹配值） 例子 result3 = re.search(&apos;(\d+)fdsa(\d+)&apos;, &apos;a123fdsa234f4532&apos;) print(result3.group()) print(result3.groups()) 结果 123fdsa234 (&apos;123&apos;, &apos;234&apos;) 查找IP 例子 ip = &apos;12.32.123.432.23432fdsa+fds;fdsa192.23.32.44_fdsa#@9ds&apos; print(re.findall(&apos;(?:\d{1,3}\.){3}\d{1,3}&apos;, ip)) 结果 [&apos;12.32.123.432&apos;, &apos;192.23.32.44&apos;]]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>python随笔</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[zabbix 监控cpu load]]></title>
    <url>%2F2017%2F03%2F12%2Fzabbix_%E7%9B%91%E6%8E%A7CPUload%2F</url>
    <content type="text"><![CDATA[场景 zabbix的cpu load要与系统（linux）上的对应（top）； 服务器的CPU核数不一致； 监控CPU核数总数/2触发报警； 思路 要动态获取zabbix-agent的core； 两个监控项目对比的差异（cpu_load&gt;cpu_num/2）并触发相关报警。 解决办法方法一 在各agent端配置自定义key，并在zabbix-server上设置相关触发器； 方法二 zabbix-server从触发器入手，直接动态获取； 方法一固然可行，但是在服务器数量庞大的基础下，虽然通过ansible等之类的工具把自定义key推送过去后再配置触发器，这样是不是有点“笨拙”？能不能从zabbix-server现有的key中寻找另一条路呢？答案当然是可以的！ 关键的两个key system.cpu.load[all,avg1] #1分钟的所有核数负载值 system.cpu.num 系统总核数 自定义触发器可参考触发器表达式,通过对自定义触发器的了解，就可以进行配置相关操作！ 展示效果{Template OS Linux-18:system.cpu.load[all,avg1].min(5m)}&gt;{Template OS Linux-18:system.cpu.num.last()}/2 最近5分钟的负载大于一半的核数就触发报警]]></content>
      <categories>
        <category>Server</category>
      </categories>
      <tags>
        <tag>zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[devops书籍]]></title>
    <url>%2F2017%2F03%2F05%2Fdevops%E4%B9%A6%E7%B1%8D%2F</url>
    <content type="text"><![CDATA[书籍收藏]]></content>
      <categories>
        <category>DevOps</category>
      </categories>
      <tags>
        <tag>devops书籍</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[django笔记]]></title>
    <url>%2F2017%2F02%2F27%2Fdjango%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[概述官网很多相关文档，省略。。。 一些文档是整理的网上资源，可以参考Yuan先生 的技术博客。 环境 python： 3.6 pip： 9.0.1 django： 1.11.7 安装Django 根据自己环境安装pip pip install Django 新建django工程 创建Django工程（根据自己环境配置修改） c:\Python36\Scripts\django-admin.exe startproject mysite mysite：django工程名称 cd mysite目录下 python manage.py startapp blog blog：应用名称 启动 python manage.py runserver 8090 目录结构mysite目录 manage.py #入口文件 mysite __init__.py #初始化文件 settings.py #项目主配置文件 urls.py #路由分配配置文件 wsgi.py #Django web server(封装socket,解析APP) blog目录 __init__.py admin.py apps.py models.py #数据库相关配置(orm) tests.py #检测、测试 views.py #视图函数 settings.py文件配置定义templates位置修改TEMPLATES中的DIRS: 'DIRS': [os.path.join(BASE_DIR, 'templates')], 最后效果为 TEMPLATES = [ { 'BACKEND': 'django.template.backends.django.DjangoTemplates', 'DIRS': [os.path.join(BASE_DIR, 'templates')], 'APP_DIRS': True, 'OPTIONS': { 'context_processors': [ 'django.template.context_processors.debug', 'django.template.context_processors.request', 'django.contrib.auth.context_processors.auth', 'django.contrib.messages.context_processors.messages', ], }, }, ] 创建APP后要在 INSTALLED_APPS 添加相应名称比如，我这里创建的是blog应用 INSTALLED_APPS = [ 'django.contrib.admin', 'django.contrib.auth', 'django.contrib.contenttypes', 'django.contrib.sessions', 'django.contrib.messages', 'django.contrib.staticfiles', 'blog', ] 添加mysql数据库连接DATABASES 中修改 DATABASES = { 'default': { # 'ENGINE': 'django.db.backends.sqlite3', # 'NAME': os.path.join(BASE_DIR, 'db.sqlite3'), 'ENGINE': 'django.db.backends.mysql', 'NAME': 'DBNAME', 'USER': 'username', 'PASSWORD': 'password', 'HOST': 'db_host', 'PORT': 'port', } } 注释掉错误警告 MIDDLEWARE = [ 'django.middleware.security.SecurityMiddleware', 'django.contrib.sessions.middleware.SessionMiddleware', 'django.middleware.common.CommonMiddleware', # 'django.middleware.csrf.CsrfViewMiddleware', 'django.contrib.auth.middleware.AuthenticationMiddleware', 'django.contrib.messages.middleware.MessageMiddleware', 'django.middleware.clickjacking.XFrameOptionsMiddleware', ] 指定静态文件位置（如：js、css、jpg等） STATICFILES_DIRS = ( os.path.join(BASE_DIR, 'statics') ) 开启配置之旅第一个页面 blog APP下views.py文件添加一个展示数据的函数 from django.shortcuts import render, HttpResponse # Create your views here. def cur_time(request): return HttpResponse('hello world!') request： 请求，参数可以自定义，但必须有 HttpResponse： 返回（当请求成功后要返回的信息） mysite下的urls.py添加相关路由信息 from blog import views #导入blog下的views模块 urlpatterns = [ url(r'^admin/', admin.site.urls), url(r'^cur_time', views.cur_time), ] 运行启动命令 python manage.py runserver 8090 浏览器打开 localhost:8090/cur_time 就能看到 hello world!信息了。 添加html文件之前在 settings.py 配置文件中指定了html文件的路径。所以，django会在 templates 目录下获取html文件，在mysite工程下新建一个 templates 目录，最后整个工程目录机构为： mysite +mysite +blog +templates 在templates目录下新键一个cur_time.html的html文件并进行编辑，最后代码为 cat views.py from django.shortcuts import render, HttpResponse # Create your views here. import datetime def cur_time(request): times = datetime.datetime.now() return render(request, 'cur_time.html', {'abc': times}) cat cur_time.html &lt;!DOCTYPE html&gt; &lt;html lang="en"&gt; &lt;body&gt; 当前时间： &lt;/body&gt; &lt;/html&gt; 解释 render： 模版渲染,第一个是请求参数&lt;request&gt;,第二个参数是跳转的url名称，第三个是传递变量 abc cur_time.html中的｛｛｝｝是jinja2的模版语言，abc 则是render传过来的变量名，注意两边有空格 再次访问浏览器，应该就能看到当前时间了。 HttpResponse与render的区别 HttpResponse： 一个类，后面跟一个字符串，是实例化的一个对象，直接返回给客户端浏览器，django所有返回给客户端浏览器都是通过这个类实现的 render 渲染工作，首先指定一个html文件，解析完成后调用HttpResponse类返回给客户端浏览器，html文件中的变量、｛｝都不会显示在客户端浏览器上 数据库连接做一个userInfo信息表单，当用户填入相关信息提交后，数据存入数据库中，并展示信息功能 如前面settings.py中的配置文件指定的数据库userInfo信息有三个字段：username、sex、email,所以需要在blog中的models.py进行初始化数据库操作 from django.db import models # Create your models here. class UserInfo(models.Model): username = models.CharField(max_length=64) sex = models.CharField(max_length=64) email = models.CharField(max_length=64) 运行初始化数据命令 python manage.py makemigrations 如果报类似如下错误 File "C:\Python36\lib\site-packages\django\db\__init__.py", line 33, in __getattr__ return getattr(connections[DEFAULT_DB_ALIAS], item) File "C:\Python36\lib\site-packages\django\db\utils.py", line 211, in __getitem__ backend = load_backend(db['ENGINE']) File "C:\Python36\lib\site-packages\django\db\utils.py", line 115, in load_backend return import_module('%s.base' % backend_name) File "C:\Python36\lib\importlib\__init__.py", line 126, in import_module return _bootstrap._gcd_import(name[level:], package, level) File "C:\Python36\lib\site-packages\django\db\backends\mysql\base.py", line 30, in 'Did you install mysqlclient or MySQL-python?' % e django.core.exceptions.ImproperlyConfigured: Error loading MySQLdb module: No module named 'MySQLdb'. Did you install mysqlclient or MySQL-python? 原因：python3不支持MySQLdb，需要在工程mysite下的init.py文件中添加如下内容 import pymysql pymysql.install_as_MySQLdb() 切记 settings.py里的INSTALLED_APPS添加应用名称，否则报错： File "C:\Python36\lib\site-packages\django\db\models\base.py", line 118, in __new__ "INSTALLED_APPS." % (module, name) RuntimeError: Model class blog.models.UserInfo doesn't declare an explicit app_label and isn't in an application in INSTALLED_APPS. django不会创建数据库，所以要提前手动创建。 mysite下的urls.py添加路由指向 from django.conf.urls import url from django.contrib import admin from blog import views urlpatterns = [ url(r'^admin/', admin.site.urls), url(r'^cur_time', views.cur_time), url(r'^userInfo', views.userInfo), #添加userInfo路由指向 ] views.py更新后的内容为： from django.shortcuts import render, HttpResponse from blog import models #导入models模块，用于数据库操作 # Create your views here. import datetime def cur_time(request): times = datetime.datetime.now() # return HttpResponse('hello world!') return render(request, 'cur_time.html', {'abc': times}) def userInfo(req): if req.method == "POST": u = req.POST.get('username', None) s = req.POST.get('sex', None) e = req.POST.get('email', None) # user={'username':username,"sex": sex, "email": email} models.UserInfo.objects.create( #插入数据 username=u, sex=s, email=e ) user_list = models.UserInfo.objects.all() #从数据库中获取所有数据 return render(req, "index.html", {"user_list": user_list}) index.html文件内容 &lt;!DOCTYPE html&gt; &lt;html lang="en"&gt; &lt;body&gt; &lt;form action="/userInfo/" method="post"&gt; &lt;p&gt;姓名&lt;input type="text" name="username"&gt;&lt;/p&gt; &lt;p&gt;性别&lt;input type="text" name="sex"&gt;&lt;/p&gt; &lt;p&gt;邮箱&lt;input type="text" name="email"&gt;&lt;/p&gt; &lt;p&gt;&lt;input type="submit" value="submit"&gt;&lt;/p&gt; &lt;/form&gt; &lt;table border="1px"&gt; &lt;tr&gt; &lt;td&gt;姓名&lt;/td&gt; &lt;td&gt;性别&lt;/td&gt; &lt;td&gt;邮箱&lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;/body&gt; &lt;/html&gt; 表单以 post 提交后跳转到 userInfo 页面。 Django URL(路由系统)URL配置(URLconf)就像Django 所支撑网站的目录。它的本质是URL模式以及要为该URL模式调用的视图函数之间的映射表；你就是以这种方式告诉Django，对于这个URL调用这段代码，对于那个URL调用那段代码。 urlpatterns = [ url(正则表达式, views视图函数，参数，别名), ] 参数： 一个正则表达式字符串 一个可调用对象，通常为一个视图函数或一个指定视图函数路径的字符串 可选的要传递给视图函数的默认参数（字典形式） 一个可选的name参数 示例 from django.conf.urls import url from django.contrib import admin from blog import views urlpatterns = [ url(r'^admin/', admin.site.urls), url(r'^cur_time', views.cur_time), url(r'^userInfo', views.userInfo), url(r'^articles/2003/$', views.special_case_2003), #url(r'^articles/[0-9]{4}/$', views.year_archive), url(r'^articles/([0-9]{4})/$', views.year_archive), #no_named group url(r'^articles/([0-9]{4})/([0-9]{2})/$', views.month_archive), url(r'^articles/([0-9]{4})/([0-9]{2})/([0-9]+)/$', views.article_detail), ] URL匹配规则是由上到下，比如url(r’^articles/2003/$’, views.special_case_2003)和url(r’^articles/([0-9]{4})/$’, views.year_archive) 这两条，都是匹配四个数字。如果URL是articles/2003，虽然也属于^articles/([0-9]{4})，但是会优先匹配url(r’^articles/2003/$’, views.special_case_2003)。 正则表达式添加（）后，指定的views的视图函数也要增加一个自定义的形参，如上面的url(r’^articles/([0-9]{4})/$’, views.year_archive)，在views.year_archive中的year_archive视图函数定义时也要添加一个形参： def year_archive(req,year): return HttpResponse(year) 浏览器访问时就会返回year值 多个()，year_archive要设定多个形参 正则分组（Named groups）有时候URL传参需要指定值，这里就会用到Python正则表达式的?Ppattern， named groups ret=re.search('(?P\d{3})/(?P\w{3})','weeew34ttt123/ooo') print(ret.group()) print(ret.group('id')) print(ret.group('name')) from django.conf.urls import url from . import views urlpatterns = [ url(r'^articles/2003/$', views.special_case_2003), url(r'^articles/(?P[0-9]{4})/$', views.year_archive), url(r'^articles/(?P[0-9]{4})/(?P[0-9]{2})/$', views.month_archive), url(r'^articles/(?P[0-9]{4})/(?P[0-9]{2})/(?P[0-9]{2})/$', views.article_detail), ] 参数名称（name param） urlpatterns = [ url(r'^index',views.index,name='bieming'), ] def index(req): if req.method=='POST': username=req.POST.get('username') password=req.POST.get('password') if username=='alex' and password=='123': return HttpResponse("登陆成功") return render(req,'index.html') &lt;!DOCTYPE html&gt; &lt;html lang="en"&gt; &lt;body&gt; &lt;form action="｛% url 'bieming' %｝" method="post"&gt; 用户名:&lt;input type="text" name="username"&gt; 密码:&lt;input type="password" name="password"&gt; &lt;input type="submit" value="submit"&gt; &lt;/form&gt; &lt;/body&gt; &lt;/html&gt; 导入其他URLconfs #At any point, your urlpatterns can “include” other URLconf modules. This #essentially “roots” a set of URLs below other ones. #For example, here’s an excerpt of the URLconf for the Django website itself. #It includes a number of other URLconfs: from django.conf.urls import include, url urlpatterns = [ url(r'^admin/', admin.site.urls), url(r'^blog/', include('blog.urls')), ] Django Views(视图函数)浏览器 –(Rquest)–&gt; WebServer 浏览器 &lt;–(Response)– WebServer http请求中产生两个核心对象： - http请求： HttpRequest对象 - http响应： HttpResponse对象 HttpRequest对象的属性和方法： # path： 请求页面的全路径，不包括域名 # # method： 请求中使用的HTTP方法的字符串表示。全大写表示。例如 # # if req.method=="GET": # # do_something() # # elseif req.method=="POST": # # do_something_else() # # GET: 包含所有HTTP GET参数的类字典对象 # # POST： 包含所有HTTP POST参数的类字典对象 # # 服务器收到空的POST请求的情况也是可能发生的，也就是说，表单form通过 # HTTP POST方法提交请求，但是表单中可能没有数据，因此不能使用 # if req.POST来判断是否使用了HTTP POST 方法；应该使用 if req.method=="POST" # # # # COOKIES: 包含所有cookies的标准Python字典对象；keys和values都是字符串。 # # FILES： 包含所有上传文件的类字典对象；FILES中的每一个Key都是标签中 name属性的值，FILES中的每一个value同时也是一个标准的python字典对象，包含下面三个Keys： # # filename： 上传文件名，用字符串表示 # content_type: 上传文件的Content Type # content： 上传文件的原始内容 # # # user： 是一个django.contrib.auth.models.User对象，代表当前登陆的用户。如果访问用户当前 # 没有登陆，user将被初始化为django.contrib.auth.models.AnonymousUser的实例。你 # 可以通过user的is_authenticated()方法来辨别用户是否登陆： # if req.user.is_authenticated();只有激活Django中的AuthenticationMiddleware # 时该属性才可用 # # session： 唯一可读写的属性，代表当前会话的字典对象；自己有激活Django中的session支持时该属性才可用。 #方法 get_full_path(), 比如：http://127.0.0.1:8000/index33/?name=123 ,req.get_full_path()得到的结果就是/index33/?name=123 req.path:/index33 注意一个常用方法：request.POST.getlist(‘’) HttpResponse对象： 对于HttpRequest对象来说，是由django自动创建的，但是，HttpResponse对象就必须我们自己创建。每个view请求处理方法必须返回一个HttpResponse对象。 HttpResponse类在django.http.HttpResponse 在HttpResponse对象上扩展的常用方法： 页面渲染： render()（推荐） render_to_response(), 页面跳转： redirect("路径") locals()： 可以直接将函数中所有的变量传给模板 url.py url(r"login", views.login), url(r"yuan_back", views.yuan_back), views.py def login(req): if req.method=="POST": if 1: # return redirect("/yuan_back/") name="yuanhao" return render(req,"my backend.html",locals()) return render(req,"login.html",locals()) def yuan_back(req): name="duanruijun" return render(req,"my backend.html",locals()) login.html &lt;form action="/login/" method="post"&gt; &lt;p&gt;姓名&lt;input type="text" name="username"&gt;&lt;/p&gt; &lt;p&gt;性别&lt;input type="text" name="sex"&gt;&lt;/p&gt; &lt;p&gt;邮箱&lt;input type="text" name="email"&gt;&lt;/p&gt; &lt;p&gt;&lt;input type="submit" value="submit"&gt;&lt;/p&gt; &lt;/form&gt; my backend.html &lt;h1&gt;用户｛｛ name ｝｝你好&lt;/h1&gt; #总结: render和redirect的区别: # 1 if render的页面需要模板语言渲染,需要的将数据库的数据加载到html,那么所有的这一部分 # 除了写在yuan_back的视图函数中,必须还要写在login中,代码重复,没有解耦. # 2 the most important: url没有跳转到/yuan_back/,而是还在/login/,所以当刷新后 # 又得重新登录. 模版什么是模版语言简单说就是html+逻辑控制语句。 模版常用用例 – 万能的句号点（.）urls.py from django.conf.urls import url from django.contrib import admin from app01 import views urlpatterns = [ url(r'^admin/', admin.site.urls), url(r'^index/', views.index), views.py from django.shortcuts import render import datetime # Create your views here. def index(req): class profile(object): def __init__(self, name, age): self.name = name self.age = age s1 = [1,22,333] s2 = {'username': 'duanrj', 'email': '123@qq.com'} s3 = datetime.datetime.now() s4 = profile("Bob", "20") s5 = 'hello' s6 = 6 s7 = [] s8 = "跳转" return render(req, 'index.html', { 'value1': s1, 'value2': s2, 'value3': s3, 'value4': s4, 'value5': s5, 'value6': s6, 'value7': s7, 'value8': s8, }) index.html &lt;!DOCTYPE html&gt; &lt;html lang="en"&gt; &lt;body&gt; ====打印列表第n个值==== ｛｛ value1.2 ｝｝ ====打印dict的username值==== ｛｛ value2.username ｝｝ 打印对象的属性 ｛｛ value3.year ｝｝ ====打印对象的属性2==== ｛｛ value4 ｝｝ ｛｛ value4.name ｝｝ ｛｛ value4.age ｝｝ ====模版语言中的遍历==== ｛% for i in obj %｝ ｛｛ forloop.counter ｝｝:｛｛ i ｝｝ //索引从1开始 ｛｛ forloop.counter0 ｝｝:｛｛ i ｝｝ //索引从0开始 ｛% endfor %｝ ====filter:小写转为大写==== ｛｛ value5 | upper ｝｝ ｛｛ value5 | lower ｝｝ ｛｛ value5 | capfirst ｝｝ ｛｛ value5 | first ｝｝ ====算数运算==== ｛｛ value6 | add:5 ｝｝ ====为空时提示信息==== ｛｛ value7 | default:'空的' ｝｝ ====当成普通字符串处理==== ｛｛ value8 ｝｝ 如果想把类似于html 标签的都渲染出来可以这样 ｛% autoescape off %} ｛｛ value8 ｝｝ ｛% endautoescape %} 也可以用safe ｛｛ obj|safe ｝｝ ====禁止render==== ｛% verbatim %｝ ｛｛ name ｝｝ ｛% endverbatim %｝ &lt;/body&gt; &lt;/html&gt; filter作用于简单操作，简化前后端开发重复性工作]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>django笔记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[zabbix低级发现]]></title>
    <url>%2F2017%2F02%2F24%2Fzabbix_%E4%BD%8E%E7%BA%A7%E5%8F%91%E7%8E%B0%2F</url>
    <content type="text"><![CDATA[一、(low level discover)概述 什么是lld ？即低水平自动发现，使用它可以自动创建项目、触发器及被监控主机上的实体图。如zabbix 可以自动监控主机上的文件系统和网络拉口，而不需要为每个监控项创建items 。此处，其也可以实现被监控项目的自动删除 。上面的话不是我的总结，是我从官方文档上翻译过来的话。 二、创建模版 由于创建模板不是本篇的重点，就不提创建模板的过程了 。这里重点提下如何在模板中创建自动发现规则。 1. 创建自动发现规则 步骤为：配置 –&gt; 模版 –&gt; 选中之前创建好的模版(这里我用 app discover) –&gt; 自动发现规则 –&gt; 创建发现规则 2. 选择监控项原型并创建监控项 名称：｛#DISCOVER} 自定义的宏变量（后续脚本会提到)； 类型：根据自身主动/被动模式选择； 键值：后续监控的自定义Key会提到。 3. 触发器类型 可根据自身情况做定义 三、客户端配置脚本（在配置发现的主机上配置，比如zabbix-server的agentd） 配置发现规则 这里发现规则是找的/app目录下的所有目录名（公司的所有项目都创建在/app目录下） cat check_app.py #!/usr/bin/env python #-*- coding:utf-8 -*- #@author: sundsinerj #@date: 2017/9/28 import os import json import getopt import sys #list app name app_list = os.listdir(os.path.expanduser("/app")) if 'lost+found' in app_list: del app_list[app_list.index('lost+found')] elif 'zabbix' in app_list: del app_list[app_list.index('lost+found')] elif 'tomcat-6.0.48_wp' in app_list: del app_list[app_list.index('lost+found')] opts, arge = getopt.getopt(sys.argv[1:],[]) #print appname for json pool_list = [] for appname in app_list: #def json data pool_list += [｛'｛#DISCOVER｝': appname｝] print json.dumps({'data': pool_list},sort_keys=True,indent=4,separators=(',',':')) 配置监控项规则 cat check_app.sh #! /bin/bash help() { echo "USAGE:`basename $0` [-n] the name of app" exit -1 } while getopts ":n" opt do case $opt in n) appname=$OPTARG ;; h) help ;; *) unkown=$OPTARG echo "error,plase check for help,USAGE:./`basename $0` -h" exit $STAT_UNKNOWN ;; esac done apppid=`ps aux | grep "$appname" | grep -v grep | wc -c` if [ $apppid -eq 0 ] then echo 0 exit 0 else echo 1 exit 1 fi 发现规则必需是json格式的 *｛#DISCOVER｝ 就是zabbix创建的模版的宏变量 check_app.sh脚本就是定义的监控项 四、自定义key cat userparameter_app.conf UserParameter=app.status[*],/bin/bash /etc/zabbix/zabbix_agentd.d/libexec/check_app.sh -n $1 UserParameter=app.discover,python /etc/zabbix/zabbix_agentd.d/libexec/check_app.py 五、验证在被发现的主机上关联app discover 模版就可以了。过会，就能看到相关的低级发现项目。]]></content>
      <categories>
        <category>Server</category>
      </categories>
      <tags>
        <tag>zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[zabbix_agent主动模式]]></title>
    <url>%2F2017%2F02%2F23%2Fzabbix_agent%E4%B8%BB%E5%8A%A8%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[概述当zabbix-server监控主机过多时候，由于server端去搜集信息，zabbix会出现严重的性能问题，比如: 当监控端到一个量级的时候，web操作界面很卡，容易出现502； 图层断裂； 开启的进程太多，即使item数量减少，以后加一定量的机器也会出现问题。 所以主要往2个优化方面考虑： 添加proxy节点或者node模式做分布式监控； 调整agentd为主动模式。 由于第一个方案需要物理节点，所以尝试第二个方案。 主动模式： 主动模式一定要记得设置ServerActive=ServerIP Agent向Server建立一个TCP连接 Agent请求需要检测的数据列表 Server响应Agent，发送一个Items列表 Agent允许响应 TCP连接完成本次会话关闭 Agent开始周期性地收集数据 一、 被监控端zabbix_agentd.conf的配置调整1vim /etc/zabbix/zabbix_agentd.conf StartAgents=0 #客户端的anent的模式，0表示关闭被动模式，zabbix-agentd不监控本地端口，所以看不到zabbix_agentd进程 #Server=172.16.100.84 #如果设置纯被动模式，应该注释掉这行 ServerActive=172.16.100.84 #主动模式的serverip地址 Hostname=172.16.100.47 #客户端的hostname，不配置则使用主机名 RefreshActiveChecks=120 #被监控端到服务器获取监控项的周期，默认120S BufferSize=200 #被监控端存储监控信息的空间大小 Timeout=3 #超时时间 纯主动监控模式下的zabbix agent，只能支持zabbix agent (active)类型的监控项 二、 调整监控模版 克隆一个temple os linux模版来修改 全选 找到最下方的批量更新 类型打勾，选择主动式，然后更新 主机修改 添加完成之后，你会发现zabbix的Z灯不亮，因为服务器是基于被动模式的 这时候就有相关数据，如果硬盘或网卡监控没有数据 模板&gt;&gt;主动监控模板名称&gt;&gt;自动发现规则 选择监控项原型-进去之后一个个点击，修改成主动式监控，在模版修改只，主动就会自动应用 过会，网卡和硬盘的监控情况就出来了。]]></content>
      <categories>
        <category>Server</category>
      </categories>
      <tags>
        <tag>zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[zabbix_proxy]]></title>
    <url>%2F2017%2F02%2F23%2Fzabbix_proxy%2F</url>
    <content type="text"><![CDATA[概述zabbix proxy可以代替zabbix server收集性能和可用性数据，然后把数据汇报给zabbix server，并且在一定程度上分担zabbix server的压力，具体可见官方文档。 样例 服务列表 | 名称 | IP | |——–|:——–:| | zabbix server | 10.18.12.98 | | zabbix proxy | 10.18.12.93 | | zabbix agent | 10.18.12.63 | zabbix agent配置文件 cat /etc/zabbix_agentd.conf LogFile=/log/zabbix/zabbix_agentd.log PidFile=/log/zabbix/zabbix_agentd.pid StartAgents=0 ServerActive=10.18.12.93 RefreshActiveChecks=120 BufferSend=5 BufferSize=100 Hostname=10.18.12.63 DebugLevel=3 Timeout=20 MaxLinesPerSecond=100 AllowRoot=1 Include=/etc/zabbix/zabbix_agentd.d/*.conf ServerActive: 代理节点IP zabbix proxy配置文件 cat /etc/zabbix/zabbix_proxy.conf Server=10.18.12.98 Hostname=Zabbix_proxy_18 LogFile=/log/zabbix/zabbix_proxy.log DebugLevel=3 DBName=zabbix DBUser=zabbix DBPassword=zabbix ProxyLocalBuffer=0 ProxyOfflineBuffer=1 ConfigFrequency=30 DataSenderFrequency=30 StartPollers=100 StartPollersUnreachable=1 StartTrappers=200 StartPingers=1 CacheSize=64M TrapperTimeout=30 Timeout=10 LogSlowQueries=3000 Server: zabbix server IP Hostname: 代理节点IP DB* 由于代理节点要暂存agent传来的数据，所以，要先把数据缓存在本地(proxy)数据库中，再定时和zabbix server进行数据交互； zabbix server配置文件 无 web端配置 1) 添加代理节点 管理&gt;&gt;agent代理程序&gt;&gt;创建代理 样例中配置的名称是zabbix_proxy_18 2) 在agent主机的最下方选择zabbix_proxy_18 完成配置后生效 过会在zabbix proxy服务端查看相关日志，如果里面有zabbix agent的数据展示信息，证明zabbix proxy配置成功。]]></content>
      <categories>
        <category>Server</category>
      </categories>
      <tags>
        <tag>zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[监控网络设备]]></title>
    <url>%2F2017%2F02%2F23%2Fzabbix_monito%2F</url>
    <content type="text"><![CDATA[一、zabbix-server端安装snmp工具1yum -y install net-snmp-utils snmp-libs snmp-devel snmp 二、检测与路由器的连通性测试之前工作 路由上要开启snmp功能 本地snmp服务器的snmp的密码和路由上的密码一致 1vim /etc/snmp/snmpd.conf 测试连通性 1snmpwalk -v 2c -c 19e#! 10.18.221.4 - 2c：协议版本 - 19e#!：密码与路由一致， - 10.18.221.4：路由IP 注意selinux、iptables 如果出现上面信息说明成功 三、zabbix-server添加路由监控主机 –&gt; 创建主机 由于添加了密钥认证，须在zabbix-server中添加密钥管理–&gt;一般–&gt;选择宏，进行设置 过几分钟就能出相关监控项了！]]></content>
      <categories>
        <category>Server</category>
      </categories>
      <tags>
        <tag>zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[zabbix报警]]></title>
    <url>%2F2017%2F02%2F23%2Fzabbix%E6%8A%A5%E8%AD%A6%2F</url>
    <content type="text"><![CDATA[概述当zabbix server预定义或自定义的触发器生效后，就要通过告警邮件、短信、微信等接口通知相关人员，并且zabbix server还设置了报警升级，可根据自身情况进行设置。 ##配置 一、 zabbix-server脚本指定位置1vim zabbix_server.conf AlertScriptsPath=/etc/zabbix/alertscripts 二、 报警类型（这里主要讲邮件和短信，后期会补上微信） 邮件 邮件报警需要提供三个参数（收件人、主题、内容）,邮件需要安装sendemail可见安装sendemail 1cat /etc/zabbix/alertscripts/sendEmail.sh #!/bin/bash to=$1 subject=$2 body=$3 /usr/local/bin/sendEmail -f ex@uu.com -t "$to" -u "$subject" -o message-content-type=html -o message-charset=utf8 -xu ex@uu.com -xp xxxx -m "$body" ############ /usr/local/bin/sendEmail 命令主程序 -f from@163.com 发件人邮箱 -t to@163.com 收件人邮箱 -s smtp.163.com 发件人邮箱的smtp服务器 -u "我是邮件主题" 邮件的标题 -o message-content-type=html 邮件内容的格式,html表示它是html格式 -o message-charset=utf8 邮件内容编码 -xu from@163.com 发件人邮箱的用户名 -xp 123456 发件人邮箱密码 -m "我是邮件内容" 邮件的具体内容 -l /var/log/sendMyEmail.log 非必输项，邮件发送日志记录到日志文件 web配置 管理 &gt;&gt; 报警媒介类型 &gt;&gt; 创建媒体类型 名称： 自定义 类型： 脚本 脚本参数： {ALERT.SENDTO} {ALERT.SUBJECT} {ALERT.MESSAGE} 管理 &gt;&gt; 用户 &gt;&gt; 报警媒介 配置 &gt;&gt; 动作 &gt;&gt; 触发器类型下新建动作 名称：Zabbix-Server告警邮件 默认接收人：主机： {HOSTNAME1} 状态：{TRIGGER.STATUS} 默认信息： 告警主机:&nbsp;{HOSTNAME1} 告警时间:&nbsp;{EVENT.DATE}{EVENT.TIME} 告警等级:&nbsp;{TRIGGER.SEVERITY} 告警信息:&nbsp;{TRIGGER.NAME} 告警项目:&nbsp;{TRIGGER.KEY1} 问题详情:&nbsp;{ITEM.NAME}:&nbsp;{ITEM.VALUE} 当前状态:&nbsp;{TRIGGER.STATUS}:&nbsp;{ITEM.VALUE1} 事件ID:&nbsp;{EVENT.ID} 恢复主题：主机： {HOSTNAME1} 状态：{TRIGGER.STATUS}！！ 恢复信息：同上 - 条件 ![](https://raw.githubusercontent.com/sundshinerj/img/master/zabbix_%E6%8A%A5%E8%AD%A6_%E9%82%AE%E4%BB%B6%E6%8A%A5%E8%AD%A6_%E5%8A%A8%E4%BD%9C%E6%9D%A1%E4%BB%B6.png) - 操作 ![](https://raw.githubusercontent.com/sundshinerj/img/master/zabbix_%E6%8A%A5%E8%AD%A6_%E9%82%AE%E4%BB%B6%E6%8A%A5%E8%AD%A6_%E5%8A%A8%E4%BD%9C%E6%93%8D%E4%BD%9C.png) 步骤：可以指定报警升级 至此，邮件报警配置完成！ 短信 短信就是调用短息商提供的短信接口，参数里需要填写两个（收件人、内容） 名称： 自定义 类型： 脚本 脚本参数： {ALERT.SENDTO} {ALERT.MESSAGE} 代码 1cat sendSms.py #! /usr/bin/python #encoding:utf-8 import requests import json import urllib import hashlib import os import sys import subprocess import datetime reload(sys) #设置字符集，否则再输出重定向时出编码错误 sys.setdefaultencoding('utf-8') #请求主题参数 def phonelist(plist): phonelist=plist.split(",") return phonelist def requestinterface(strp): url="http://test.com?sname=接口用户名&spwd=接口密码" #定义一个字典，值为请求的参数 param={} param['sdst']=strp param['smsg']=sys.argv[2] str3=url+'sdst='+param['sdst']+'&smsg='+urllib.quote(param['smsg']+'【标题】') r = requests.get(str3,verify=False) if __name__ == '__main__': #now=datetime.datetime.now().strftime('%Y-%m-%d-%H') #os.system("touch sendsms.`date +\'%F-%H\'`") #print fname #f = open('sendsms.'+str(now),'a') #f.write(sys.argv[1]+' -- '+sys.argv[2]+' '+str(now)+'\n') plist=phonelist(sys.argv[1]) for i,value in enumerate(plist): sms=requestinterface(value) 至此，短信报警配置完成。]]></content>
      <categories>
        <category>Server</category>
      </categories>
      <tags>
        <tag>zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[zabbix问题汇总]]></title>
    <url>%2F2017%2F02%2F23%2Fzabbix%E9%97%AE%E9%A2%98%E6%B1%87%E6%80%BB%2F</url>
    <content type="text"><![CDATA[一、agent连接正常，server端报agent.ping问题由来zabbix-server迁移到server2上，zabbix架构为zabbix-agent –&gt; zabbix_proxy –&gt; zabbix_server； zabbix-server迁移进行时，zabbix_proxy没做停止，zabbix-server迁移完成后，zabbix_proxy指定的还是server1。这时，zabbix-server2收不到所有zabbix_proxy的数据，因此产生大量报警，当zabbix_proxy的Server字段改为zabbix-server2后，数据同步了，但是极有可能造成zabbix-server下的部分agent节点的触发器agent.ping还没有得到响应，而迁移后的数据也能在新的server上展示。 解决办法把有问题的agent节点关闭，等待server端重新出发一次agent.ping（相当于更新下之前的状态）,当server收到新的报警后，再把问题agent启动。这样就能覆盖掉问题agent.ping。 二、报警风暴由来当大量zabbix_agent单位时间内连接超时，故障修复后，会产生大量的报警信息（比如：邮件、短信）。这些人为已经预知的情况下，其实不想在收到通知！ 解决办法比如zabbix_server调用的邮件通知，把邮件脚本改成： 1echo `date` &gt;&gt; /tmp/sms.txt 这样的操作很明显能弯路思想改善接受大量报警信息。]]></content>
      <categories>
        <category>Server</category>
      </categories>
      <tags>
        <tag>zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ansible问题汇总]]></title>
    <url>%2F2017%2F02%2F23%2Fansible%E9%97%AE%E9%A2%98%E6%B1%87%E6%80%BB%2F</url>
    <content type="text"><![CDATA[一、通过ssh代理传输文件超时hosts配置文件 12[TestServer]172.16.0.129 ansible_ssh_port=12345 ansible_ssh_common_args=&apos;-o ProxyCommand=&quot;ssh -q -p33115 root@111.222.333.444 nc %h %p&quot;&apos; 应用synchronize模块时提示类似如下信息： 123456789[root@xyzl-test3 ansible]# ansible TestServer -i /opt/App/ansible/TestServerHosts -m synchronize -a &quot;src=/opt/JenkinsCache/TestServer/TestServer.tar.gz dest=/opt/JenkinsCache/TestServer/&quot; [WARNING]: Invalid characters were found in group names but not replaced, use -vvvv to see details172.16.0.129 | FAILED! =&gt; &#123; &quot;changed&quot;: false, &quot;cmd&quot;: &quot;/bin/rsync --delay-updates -F --compress --archive --rsh=/bin/ssh -S none -o Port=33115 -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null --out-format=&lt;&lt;CHANGED&gt;&gt;%i %n%L /opt/JenkinsCache/TestServer/TestServer.tar.gz 172.16.0.129:/opt/JenkinsCache/TestServer/TestServer/&quot;, &quot;msg&quot;: &quot;ssh: connect to host 172.16.0.129 port 12345: Connection timed out\r\nrsync: connection unexpectedly closed (0 bytes received so far) [sender]\nrsync error: unexplained error (code 255) at io.c(226) [sender=3.1.2]\n&quot;, &quot;rc&quot;: 255&#125; 因改成copy模块： 1234567891011121314151617181920[root@xyzl-test3 ansible]# ansible TestServer -i /opt/JenkinsCache/TestServer/TestServerHosts -m copy -a &quot;src=/opt/JenkinsCache/TestServer/TestServer.tar.gz dest=/opt/JenkinsCache/TestServer/TestServer/&quot; [WARNING]: Invalid characters were found in group names but not replaced, use -vvvv to see details172.16.0.129 | CHANGED =&gt; &#123; &quot;ansible_facts&quot;: &#123; &quot;discovered_interpreter_python&quot;: &quot;/usr/bin/python&quot; &#125;, &quot;changed&quot;: true, &quot;checksum&quot;: &quot;f91ea3c7d14223d73cd5ac667112388b13f8b8f4&quot;, &quot;dest&quot;: &quot;/opt/JenkinsCache/TestServer/TestServer.tar.gz&quot;, &quot;gid&quot;: 0, &quot;group&quot;: &quot;root&quot;, &quot;md5sum&quot;: &quot;76cf7a69de2786d77327ab59f803fe1c&quot;, &quot;mode&quot;: &quot;0644&quot;, &quot;owner&quot;: &quot;root&quot;, &quot;size&quot;: 40923749, &quot;src&quot;: &quot;/root/.ansible/tmp/ansible-tmp-1570589569.14-59930443509260/source&quot;, &quot;state&quot;: &quot;file&quot;, &quot;uid&quot;: 0&#125;]]></content>
      <categories>
        <category>Server</category>
      </categories>
      <tags>
        <tag>Ansible</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[字段和方法]]></title>
    <url>%2F2016%2F10%2F23%2F%E5%AD%97%E6%AE%B5%E5%92%8C%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[首先，要知道Python类中两个概念：字段和方法“字段”和“方法”都有“动态”和“静态”之分，即： 字段 静态字段 动态字段 方法 静态方法 动态方法 以下事例标明了：“静态字段”，“动态字段”以及“动态方法”是什么样子的，因为显而易见，就不用语言进行过多描述： #coding:utf-8 class Car: # 下面是静态字段 memo = u'车辆具有出厂合格证' def __init__(self, brand, model, speed, price, engine): # 下面是动态字段 self.Brand = brand self.Model = model self.Speed = speed self.Price = price self.__EngineType = engine # 下面是动态方法 def Turnleft(self): print self.Brand + u'开始向右转向。' 上述事例中，并没有展现“静态方法”，那么“静态方法”长什么样子？如何生成？其实“静态方法”只需要执行两步操作，就可以转换成“静态方法” 在方法前加上 @staticmethod 把“动态方法”括号中的“self”去掉 如： @staticmethod def Forward(): print u'开始向前进' 那么关于这四种类型，有什么特点？以下进行总结： 四种类型，均可以被“对象”进行调用，但不建议使用“对象”调用“静态方法”和“静态字段”，而建议使用“类”对其进行调用 “动态方法”和“动态字段”只能由“对象”进行调用，而无法使用“类”进行调用]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>python随笔</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx笔记]]></title>
    <url>%2F2016%2F05%2F11%2Fnginx%2F</url>
    <content type="text"><![CDATA[初探nginx在启动后，会以daemon的形式在后台运行，后台进程包括一个master和多个worker进程，而master主要管理worker，包含： 接收来自外界的信号； 向各worker进程发送信号； 监控worker进程的运行状态（如果worker挂掉，会自动重新创建新的worker）。 worker之间是对等关系，他们同等竞争来自客户端的请求，各进程互相之间是独立的。一个请求只可能在一个worker进程中处理，一个worker进程，不可能处理其它进程的请求。worker进程的个数是可以设置的，一般我们会设置与机器cpu核数一致，这里面的原因与nginx的进程模型以及事件处理模型是分不开的。nginx的进程模型，可以由下图来表示： 图中可以看到master为主进程，我们只需要控制master就可以了，比如： kill -HUP pid,从容地重启nginx，他们会首先创建一个新的worker，并向老的worker发送关闭的信号，这样新老交替，就能完成平滑重启了。 当所有worker都处于listen时，当一个请求过来时，所有worker都有可能处理这个请求，nginx怎么处理呢？ worker之间的信息处理前面提到，每个worker是平等的，首先，在master进程里，先建立好需要的listen的socket（listenfd）之后，然后再fork出多个worker进程，此时worker的listenfd在连接到来时是只读的。为保证只有一个进程处理该连接，所有worker进程在注册listenfd读事件前抢accept_mutex（互斥锁），在抢到accept_mutex后就注册listenfd读事件，在该读事件里调用accept接受该连接，一切完成后就读取、解析、处理请求并返回给客户端了，可以看到，一个请求只有一个worker来处理，并只在一个worker中处理。 一个woker处理一个请求，那高并发是怎么做的呢？ 高并发处理原理nginx采用异步非阻塞方式来处理请求，那异步非阻塞是什么意思呢？先看下完整的请求过程：请求到来 –&gt; 建立连接 –&gt; 接受数据 –&gt; 发送数据，具体到系统底层就是读写事件。那阻塞与非阻塞是什么意思呢？ 阻塞 事件没有准备好，那就只能等了，等事件准备好了，才可以继续。 此时，阻塞调用会进入内核等待。 非阻塞 事件没有准备好，马上返回EAGAIN，让你先去干别的，过会再来看是否OK，等准备好了再继续。 虽然不阻塞了，但你时不时地过来检查事件状态，带来的开销也是很大的。所以，才会用到异步处理，具体到系统调用就是像select/poll/epoll/kqueue这样的系统调用。它们提供了一种机制，让你可以同时监控多个事件，调用他们是阻塞的，但可以设置超时时间，在超时时间之内，如果有事件准备好了，就返回。这种机制正好解决了我们上面的两个问题。拿epoll来说： 1. 当事件没准备好时，放到epoll里； 2. 事件准备好了，就去读写； 3. 如果返回EAGAIN时，再次放到epoll里； 4. 当所有事件都没准备好时，才在epoll里等待。 这样，就能接受持续不断的请求了–&gt;高并发。当然，这里的并发请求，是指未处理完的请求，线程只有一个，所以同时能处理的请求当然只有一个了，只是在请求间进行不断地切换而已，切换也是因为异步事件未准备好，而主动让出的。这里的切换是没有任何代价，你可以理解为循环处理多个准备好的事件，事实上就是这样的。与多线程相比，这种事件处理方式是有很大的优势的，不需要创建线程，每个请求占用的内存也很少，没有上下文切换，事件处理非常的轻量级。并发数再多也不会导致无谓的资源浪费（上下文切换）。更多的并发数，只是会占用更多的内存而已。 对于web服务器，事件通常有三种类型：网络事件、信号和定时器： 网络事件 通过异步非阻塞能解决问题 信号 nginx正在等待事件（epoll_wait）时，如果程序收到信号，在信号处理函数处理完后，epoll_wait会返回错误，然后程序可再次进入epoll_wait调用。 定时器 由于epoll_wait等函数在调用的时候可以设置一个超时时间，nginx借用这个超时时间来实现定时器。 connectionconnection是对TCP的封装，包括连接的socket，读/写事件。利用connection来处理与连接相关的事情，比如，建立连接，发送与接收数据等。而且nginx中的http请求的处理就是建立在connection之上。 所以，nginx不仅可以做webServer,还能做sendMail。 request在nginx中则是http请求，结构体为：ngx_http_request_t。ngx_http_request_t是对一个http请求的封装。一个http请求包含：请求行、请求头、请求体、响应行、响应头、响应体。 Nginx作为web服务器时使用的配置]]></content>
      <categories>
        <category>Service</category>
      </categories>
      <tags>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx笔记1]]></title>
    <url>%2F2016%2F05%2F11%2Fnginx_http%E5%8D%8F%E8%AE%AE%E5%9F%BA%E7%A1%80%E5%8F%8AIO%E6%A8%A1%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[Nginx通常作为两种应用，既： Web Server Web Reverse Proxy 做为web服务器最核心的是http协议（全称：HyperText Transfer Procotol）–超文本传输协议，主要用于传输超文本（超文本又称html(HyperText Mark Language)语言开发的文本或者html语言标记的文本）。而HTTP协议默认工作在80端口上。在http1.0之前只支持超文本传输，但是从1.0以后由于引入了MIME（Multipurpost Internet Mail Extension）机制（接受非文本，但能转换城文本格式进行传输，而到客户端时又能还原成原有协议的编码方案）。 互联网上访问一个资源是根据URL标记定义的，其基本语法是：scheme(协议)://server[:port]/path/to/source。 http事务由两部分组成： request 格式： &lt;body&gt; response 格式： &lt;HEADERS&gt; &lt;body&gt; method包括： GET HEADE POST PUT DELETE TRACE OPTIONS status: 1xx: 信息类 2xx: 成功类 3xx: 重定向 301 302 304 4xx: 客户端错误 404 401 5xx: 502 504 HEADE: 通用首部 请求首部 If-Modified-Since、IF-None-Match 响应首部 实体首部 扩展首部]]></content>
      <categories>
        <category>Service</category>
      </categories>
      <tags>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[书籍]]></title>
    <url>%2F2016%2F03%2F05%2Fbooks%2F</url>
    <content type="text"><![CDATA[《自控力》]]></content>
      <categories>
        <category>books</category>
      </categories>
      <tags>
        <tag>书籍</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux非root用户文件描述符限制]]></title>
    <url>%2F2015%2F02%2F27%2FLinux%E9%9D%9Eroot%E7%94%A8%E6%88%B7%E6%96%87%E4%BB%B6%E6%8F%8F%E8%BF%B0%E7%AC%A6%E9%99%90%E5%88%B6%2F</url>
    <content type="text"><![CDATA[描述在一次生产环境下切换非root用户，导致如下错误等待： 123456[root@xy_Tomcat_1 exam-service]# su - java-bash: fork: retry: Resource temporarily unavailable-bash: fork: retry: Resource temporarily unavailable-bash: fork: retry: Resource temporarily unavailable-bash: fork: retry: Resource temporarily unavailable-bash: fork: retry: Resource temporarily unavailable 通常上述问题发现是由于非root用户默认打开文件描述符为1024： 12345678cat /etc/security/limits.d/90-nproc.conf# Default limit for number of user&apos;s processes to prevent# accidental fork bombs.# See rhbz #432903 for reasoning.* soft nproc 1024root soft nproc unlimited 解决只要把非root用户值改为合适本身环境即可]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
</search>
