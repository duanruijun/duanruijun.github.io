<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[elk-kibana视图-maps]]></title>
    <url>%2F2020%2F05%2F13%2Felk-kibana%E8%A7%86%E5%9B%BE-maps%2F</url>
    <content type="text"><![CDATA[maps介绍最有效的还得看官网介绍，这里简单说明下： 创建具有多个图层和索引的地图。 将GeoJSON文件上传到Elasticsearch中。 可把地图嵌入到仪表板中。 绘制单个文档或使用聚合来绘制任何数据集，无论大小如何。 创建Choropleth贴图。 使用数据驱动的样式从属性值中符号化要素。 通过搜索集中显示要显示的数据。 工作原理maps插件是利用GeoIP获取地图上的详细信息并展示，所以，我们需要在elasticsearch中存储IP对应的geoip.location字段geo_point的类型。然后在kibana的maps上可以配置图层展示了。 准备工作####ELKF版本介绍 Name Version filebeat 7.2.0 ibana 7.6.2 elasticsearch 7.6.2 logstash 7.6.2 数据传输流程 服务日志我这里测试用的是NGINX日志作为示例： 12345nginx &#123; ... log_format ... $remote_addr ... # nginx获取客户端IP的采集函数$remote_addr ...&#125; 请求日志信息： 123xx.xx.com 202.12.22.151 - [14/May/2020:14:03:14 +0800] "POST /getArea?requestId=123 HTTP/1.1" 200# 这里 202.12.22.151就是我们获取到的客户端IP地址 GeoIP数据库下载可以通过上面GeoIP链接下载或则自行百度下载数据包，我这里存放至/opt/App/GeoIP目录下 logstash配置通过filebeat工具传输至logstash，再由logstash进行过滤存储至elasticsearch，logstash过滤信息： 12345678910111213141516171819202122232425262728293031323334353637input &#123; beats &#123; port =&gt; FILEBEAT_PORT &#125;&#125;filter &#123; grok &#123; match =&gt; [ "message", '...%&#123;IPV4:user_ip&#125;...' # 匹配NGINX的IP规则 ] &#125; geoip &#123; source =&gt; "user_ip" # grok中定义的获取客户端IP变量user_ip target =&gt; "geoip" # 标记为geoip模块 database =&gt; "/opt/App/GeoIP/GeoLite2-City.mmdb" # GeoIP数据 add_field =&gt; [ "[geoip][coordinates]", "%&#123;[geoip][longitude]&#125;" ] add_field =&gt; [ "[geoip][coordinates]", "%&#123;[geoip][latitude]&#125;" ] &#125; mutate &#123; convert =&gt; [ "[geoip][coordinates]", "float"] convert =&gt; [ "responsetime", "float"] &#125; date &#123; match =&gt; [ "timestamp" , "dd/MMM/YYYY:HH:mm:ss Z" ] &#125;&#125;output &#123; elasticsearch &#123; hosts =&gt; ["http://ELASTICSEARCH_IP:ELASTICSEARCH_PORT"] index =&gt; "logstash-nginx-%&#123;[@metadata][beat]&#125;-%&#123;[@metadata][version]&#125;-%&#123;+YYYY.MM.dd&#125;" &#125; # 索引文件必须以logstash开头&#125; maps展示由于kibana自带默认地图加载起来非常耗时，这里用的是高德地图，在kibana的配置文件末尾引入高德地图插件即可： 1echo "map.tilemap.url: 'http://webrd02.is.autonavi.com/appmaptile?lang=zh_cn&amp;size=1&amp;scale=1&amp;style=7&amp;x=&#123;x&#125;&amp;y=&#123;y&#125;&amp;z=&#123;z&#125;'" &gt;&gt; kibana.yml 完成后重启kibana服务 添加索引请求下NGINX页面，并在kibana的配置管理中添加上述配置的索引 地图配置依次选择maps菜单-&gt;创建地图-&gt;添加图层-&gt;文档-&gt;索引模式列表中选择你添加的索引即可： 最后效果]]></content>
      <categories>
        <category>elk</category>
      </categories>
      <tags>
        <tag>elk maps</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker基本使用（三）-- Dockerfile]]></title>
    <url>%2F2020%2F04%2F19%2Fdocker%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8%EF%BC%88%E4%B8%89%EF%BC%89--%20Dockerfile%2F</url>
    <content type="text"><![CDATA[Dockerfile制作docker镜像分为两种类型：从已有的docker image中导出新的镜像，还有就是通过编写Dockerfile文件制作镜像，一般推荐后者，简单、快速、易维护。 注意事项 在制作Dockerfile时，必须要在特有的一个工作目录(一个空目录)中，比如: /opt/docker(以下简称顶级目录)； 这个目录中有一个Dockerfile文件，文件首字母必须大写； 如果我们在制作过程中需要很多打包好的文件，你必须把这些文件放在此目录中，比如：/opt/docker/nginx-libs.tar.gz、/opt/docker/zip/unzip.tar.gz，说白就是以当前目录作为顶级目录； 制作镜像中如有不需要的文件或目录，可在顶级目录下创建一个.dockeringore，把不需要的文件写在这里； 常用命令FROM 指定当前做的镜像是基于哪个已有镜像为基础，也是最重要的一个且是Dockerfile文件中的第一个非注释行，用于为镜像文件构建过程中指定的基础镜像，后续命令运行基于此基准镜像提供的运行环境。 1234FROM &lt;repository&gt;[:&lt;tag&gt;]或FROM &lt;repository&gt;@&lt;digest&gt; - &lt;repository&gt;: 指定作为base image的名称； - &lt;tag&gt;: base image标签，为可选项，忽略时默认为latest; 示例 1FROM busybox:latest LABLE 之前docker版本使用MAINTANIER（用于让Dockerfile制作者提供更详细的本人信息），现在已被LABLE标签替换，在这里指定Dockerfile的元数据 1LABLE &lt;key&gt;=&lt;value&gt; &lt;key&gt;=&lt;value&gt; &lt;key&gt;=&lt;value&gt;... 示例 1LABLE maintainer="duanruijun &lt;duanruijun.github.io&gt;" COPY 用于从Docker主机复制文件至新创建的镜像文件 123456789101112COPY &lt;src&gt;...&lt;dec&gt; 或COPY [&lt;src&gt;,..&lt;dec&gt;] - &lt;src&gt;: 要复制的源文件或目录，支持使用通配符; - &lt;dec&gt;: 目标路径，即正在创建的image的文件系统路径；建议&lt;dec&gt;使用绝对路径，否则，COPY指定则以WORKDIR为起始路径; 注意：在路径中有空白字符时，通常使用第二种格式文件复制准则： - &lt;src&gt;必须是build上下文中的路径，不能是其父目录中的文件 - 如果&lt;src&gt;是目录，则其内部文件或子目录会被递归复制，但&lt;src&gt;自身目录不会被复制 - 如果指定了多个&lt;src&gt;，或者&lt;src&gt;中使用了通配符，则&lt;dec&gt;必须是一个目录，且必须以/结尾 - 如果&lt;dec&gt;事先不存在，它将会被自动创建，这包括其父目录路径 示例 1COPY index.html /data/web/html/ 制作一个简单镜像通过以上三个命令就可以简单的制作一个docker镜像了： 12345[root@192 docker]# cat /opt/docker/Dockerfile # Description: test imageFROM busybox:latestLABEL maintainer="duanruijun &lt;duanruijun.github.io&gt;"COPY index.html /data/web/html/ 由于这里是有了COPY命令，我们需要在/opt/docker目录下新建一个index.html的测试文件，创建一个简单的内容： 12[root@192 docker]# cat /opt/docker/index.html &lt;h1&gt;Busybox http server.&lt;/h1&gt; 运行命令docker build完成一个镜像的制作 123456789101112131415161718192021[root@192 tmp1]# docker build ./ -t tinyhttp:v0.1-1Sending build context to Docker daemon 3.072kBError response from daemon: Dockerfile parse error line 3: unknown instruction: LABLE[root@192 tmp1]# vim index.html^C[root@192 tmp1]# vim Dockerfile [root@192 tmp1]# docker build ./ -t tinyhttp:v0.1-1Sending build context to Docker daemon 3.072kBStep 1/3 : FROM busybox:latestlatest: Pulling from library/busyboxe2334dd9fee4: Pull complete Digest: sha256:a8cf7ff6367c2afa2a90acd081b484cbded349a7076e7bdf37a05279f276bc12Status: Downloaded newer image for busybox:latest ---&gt; be5888e67be6Step 2/3 : LABEL maintainer="duanruijun &lt;drj8588@126.com&gt;" ---&gt; Running in 6099746c50a0Removing intermediate container 6099746c50a0 ---&gt; 246515611329Step 3/3 : COPY index.html /data/web/html/ ---&gt; 0d605439655cSuccessfully built 0d605439655cSuccessfully tagged tinyhttp:v0.1-1 命令参数说明： build: 构建命令 ./: 生成路径，这里是当前路径 -t: 参数，给生成的镜像打个tag 通过docker image查看镜像 123[root@192 docker]# docker image lsREPOSITORY TAG IMAGE ID CREATED SIZEtinyhttp v0.1-1 0d605439655c 7 minutes ago 1.22MB 最后运行一个容器指定这个镜像查看是否有index.html这个文件 123[root@192 docker]# docker run --name tinyweb1 --rm tinyhttp:v0.1-1 cat /data/web/html/index.html&lt;h1&gt;Busybox http server.&lt;/h1&gt; 说明文件已经打包到镜像里了 ADD 类似于COPY指令，ADD支持使用TAR文件或URL路径 12345678ADD &lt;src&gt;...&lt;dec&gt; 或ADD ["&lt;src&gt;",.."&lt;dec&gt;"]操作准则 - 同COPY命令 - 如果&lt;src&gt;为URL且不为/结尾，则&lt;src&gt;指定的文件将被下载并直接被创建为&lt;dec&gt;；如果&lt;dec&gt;以/结尾，则文件名URL指定的文件将被直接下载并保存为&lt;dec&gt;/&lt;filename&gt; - 如果&lt;src&gt;是一个本地操作系统上的一个压缩格式的tar文件，它将被展开为一个目录，其行为类似于“tar -x”命令；然而通过URL获取的tar文件将不会自动展开 - 如果&lt;src&gt;有多个，或其间接或直接使用了通配符，则&lt;dec&gt;必须是一个以/结尾的目录路径；如果&lt;dec&gt;不以/结尾，则其被视作为一个普通文件，&lt;src&gt;的内容将被直接写入到&lt;dec&gt; 示例 1ADD http://nginx.org/download/nginx-1.15.2.tar.gz /usr/local/src/ WORKDIR 用于为Dockerfile中所有的RUN、CMD、ENTRYPOINT、COPY和ADD指定设定工作目录 123WORKDIR &lt;dirpath&gt; - 在Dockerfile中，WORKDIR指定可出现多次，其路径也可以为相对路径，不过，其是相对此前一个WORKDIR指令指定的路径 - 另外，WORKDIR也可以调用ENV指定定义的变量 示例 12WORKDIR /usr/local/ADD http://nginx.org/download/nginx-1.15.2.tar.gz ./src/ VOLUME 用于在一个image中创建一个挂载点目录，以挂载Docker host上的卷或其他容器上的卷 1234VOLUME &lt;mountpoint&gt; 或VOLUME ["&lt;mountpoint&gt;"]如果挂载点目录路径下此前文件已存在，docker run命令会在卷挂载完成后将此前的所有文件复制到新挂载的卷中 示例 1VOLUME /data/mysql/ 通过docker build命令构建镜像后查看是否挂载成功: 1234[root@192 docker]# docker run --name tinyweb1 --rm tinyhttp:v0.1-3 mount.../dev/sda5 on /data/mysql type xfs (rw,relatime,attr2,inode64,noquota)... 也可以通过docker inspect命令查看是否挂载： 123456789101112131415[root@192 docker]# docker run --name tinyweb1 --rm tinyhttp:v0.1-3 sleep 60..."Mounts": [ &#123; "Type": "volume", "Name": "708aa2b16d3183d1f68dc8244d8a76f8d91e52cc4934946be544f84e01034b07", "Source": "/var/lib/docker/volumes/708aa2b16d3183d1f68dc8244d8a76f8d91e52cc4934946be544f84e01034b07/_data", "Destination": "/data/mysql", "Driver": "local", "Mode": "", "RW": true, "Propagation": "" &#125; ],... EXPOSE 用于为容器打开指定的监听端口以实现与外部通信 12345EXPOSE &lt;port&gt;[/&lt;protolcol&gt;] [&lt;port&gt;[/&lt;protolcol&gt;]...] &lt;protolcol&gt;: 用于指定传输层协议，可为tcp和udp二者之一，默认使用tcp协议 EXPOSE指令可一次指定多个端口： EXPOSE 11211/tcp 11211/tdp 示例 1EXPOSE 80/tcp 通过docker build构建后测试 1docker run --name tinyweb1 --rm tinyhttp:v0.1-4 /bin/httpd -f -h /data/web/html -f: httpd服务运行在前台 -h: 指定httpd的web目录 通过docker inspect tinyweb1获取到容器tinyweb1对外IP地址，就可以访问测试了: 1234567891011[root@192 docker]# docker inspect tinyweb1... "Networks": &#123; ... "Gateway": "172.17.0.1", "IPAddress": "172.17.0.2", "IPPrefixLen": 16,...[root@192 ~]# curl 172.17.0.2&lt;h1&gt;Busybox http server.&lt;/h1&gt; 此时，只是通过curl命令能够正常访问，但是通过docker port tinyweb1查看暴露的端口为空： 12[root@192 docker]# docker port tinyweb1[root@192 docker]# 这里需要在运行容器时添加-P(大写)就可以查看了: 1234[root@192 docker]# docker run --name tinyweb1 --rm -P tinyhttp:v0.1-4 /bin/httpd -f -h /data/web/html[root@192 docker]# docker port tinyweb180/tcp -&gt; 0.0.0.0:5000 这样在局域网中访问docker host的5000端口就可以访问容器中的http服务信息了 ENV 用于为镜像定义所需要的环境变量，并可被Dockerfile文件中位于其后的其他指令（如ENV、ADD、COPY等）所调用 调用格式为\$variable_name或\${variable_name} 12345ENV &lt;key&gt; &lt;value&gt; 或ENV &lt;key&gt;=&lt;value&gt;... - 第一种格式中，&lt;key&gt;之后的所有内容均会被视作为&lt;value&gt;中的组成部分，因此，一次只能设置一个变量 - 第二种格式中，可以设置多个变量，每个变量为“&lt;key&gt;=&lt;value&gt;”的键值对，如果&lt;value&gt;中报班空格，可以以(\)反斜线进行转义，也可通过&lt;value&gt;加引号进行标识，另外，反斜线也可用于续行 - 定义多个变量时，建议使用第二种方式，以便在同一层中完成所有功能 示例 1234ENV DOC_ROOT=/data/web/html/ \ WEB_SERVER_PACKAGE="nginx-1.15.2"COPY index.html $&#123;DOC_ROOT-/data/web/html/&#125; # $&#123;variable_name:-...&#125; 默认值 通过docker build…完成后进行run操作查看传到容器中的变量信息: 123456[root@192 docker]# docker run --name tinyweb1 --rm tinyhttp:v0.1-5 printenvPATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/binHOSTNAME=5c9821659155DOC_ROOT=/data/web/html/WEB_SERVER_PACKAGE=nginx-1.15.2HOME=/root 也可以在run的时候通过-e选项给容器中传参达到另一种效果: 1234567[root@192 docker]# docker run --name tinyweb1 --rm -e WEB_SERVER_PACKAGE="nginx-1.15.1" tinyhttp:v0.1-5 printenvPATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/binHOSTNAME=d6ec808401dcWEB_SERVER_PACKAGE=nginx-1.15.1DOC_ROOT=/data/web/html/HOME=/root RUN 用于指定docker build过程中运行的程序，其可以是任何命令 123456RUN &lt;command&gt; 或RUN ["&lt;executable&gt;","&lt;param1&gt;","&lt;param2&gt;"]第一种格式中，&lt;command&gt;通常是一个shell命令，且以"/bin/sh -c"来运行它，这意味着此进程的Pid不为1，不能接受Unix信号，因此，当使用docker stop &lt;container&gt;命令停止容器时，此进程接收不到SIGTERM信号；第二种语法格式中的参数是一个JSON格式的数组，其中&lt;executable&gt;为要运行的命令，后面的&lt;paramN&gt;是传递给命令的选项或参数；然而，此种格式指定的命令不会以"/bin/sh -c"来发起，因此常见的shell操作如替换以及通配符(*?)替换将不会进行；不过，如果要运行的命令依赖于此shell的话，可以将其替换为类似下面的格式：RUN ["/bin/bash", "-c", "&lt;executable&gt;", "&lt;param1&gt;"] 示例 12RUN cd /usr/local/src &amp;&amp; \ tar -x nginx.1.15.2.tar.gz CMD 类似于RUN指令，CMD也可用于运行任何命令或应用程序，不过，二者运行的时间点不同 RUN指令运行于镜像文件的构建过程中，而CMD运行于基于Dockerfile构建出的新镜像文件启动的一个容器时 CMD指令的首要目的在于为启动的容器指定默认要运行的程序，且其运行结束后，容器也将终止；不过，CMD指定的命令其可以被docker run命令行选项所覆盖 在Dockerfile中可以存在多个CMD指令，但仅最后一个生效 123456CMD &lt;command&gt; 或CMD ["&lt;executable&gt;", "&lt;param1&gt;","&lt;param2&gt;"] 或CMD ["&lt;param1&gt;","&lt;param2&gt;"]前两种语法格式意义同RUN第三种则用于为ENTRYPOINT指令提供默认参数 示例 1CMD /bin/httpd -f -h ... ENTRYPOINT 类似于CMD指令的功能，用于为容器指定默认的运行程序，从而使得容器像一个单独的可执行程序 与CMD不同的是，由ENTRYPOINT启动的程序不会被docker run命令行指定的参数所覆盖，而且，这些命令行参数会被当成参数传递给ENTRYPOINT指定的程序 不过，docker run命令指定的–entrypoint选项的参数可覆盖ENTRYPOINT指令指定的程序 12345ENTRYPOINT &lt;command&gt;ENTRYPOINT ["&lt;executable&gt;", "&lt;param1&gt;","&lt;param2&gt;"]docker run命令传入的命令参数会覆盖CMD指令的内容并且附加到ENTRYPOINT命令最后作为其参数使用Dockerfile中也可以指定多个ENTRYPOINT,但是只有最后一个指令生效 示例 1ENTRYPOINT /bin/httpd -f -h ... USER 用于指定运行image时的或运行Dockerfile中的任何RUN、CMD或ENTRYPOINT指令指定的程序时的用户名或UID 默认情况下，container运行身份为root 123USER &lt;UID&gt;|&lt;UserName&gt;需要主要的是，&lt;UID&gt;可以为任意数字，但实践中必须为/etc/passwd中某用户的有效UID，否则，docker run将运行失败 示例 1USER nginx HEALCHECK 检查CMD command指令健康状态 示例 1HEALTHCHECK --start-period=3s CMD wget -O - -q http://0.0.0.0/ SHELL 运行程序默认的shell程序，比如：Linux的[“/bin/sh”, “-c”]，Windows的[“cmd”, “/s”] ARG 在docker build中传递参数 1ARG auth="sunshine" 示例 1docker build --build-arg auth="duanruijun" -t IMAGE_NAME ./ ONBUILD 用于在Dockerfile中定义一个触发器 Dockerfile用于build镜像文件，此镜像文件亦可作为base image被另一个Dockerfile用作FROM指令的参数，并以之构建新的镜像文件 在后面的这个Dockerfile中的FROM指令在build过程中被执行时，将会“触发”创建其base image的Dockerfile文件中的ONBUILD指令定义的触发器 12345ONBUILD &lt;INSTRUCTION&gt;尽管任何指令都可注册成为触发器指令，但ONBUILD不能自我嵌套，且不会触发FROM指令使用包含ONBUILD的Dockerfile构建的镜像应该使用特殊标签，例如：ruby:2.0-onbuild在ONBUILD指令中使用ADD或COPY时应该格外小心，因为新构建过程的上下文在缺少指定的源文件时会失败 示例 1ONBUILD ADD http://nginx.org/download/nginx.1.15.2.tar.gz /usr/local/src/ 好的，以上就是Dockerfile中用到的所有常用指令。]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker基本使用（二）-- 镜像管理基础]]></title>
    <url>%2F2020%2F04%2F06%2Fdocker%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8%EF%BC%88%E4%BA%8C%EF%BC%89%2F</url>
    <content type="text"><![CDATA[docker镜像管理基础docker镜像说明 docker镜像含有启动容器所需要的文件系统及其内容，因此，其用于创建并启动docker容器 特点 采用分层构建机制，最底层为bootfs，其之为rootfs Bootfs: 用于系统引导的文件系统，包括bootloader和kernel，容器启动完成后会被卸载以节约内存资源； Rootfs: 为与bootfs之上，表现为docker容器的根文件系统； 传统模式中，系统启动之时，内核挂载rootfs时会首先将其挂载为“只读模式”]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker基本使用（一）-- 基础环境安装]]></title>
    <url>%2F2020%2F04%2F06%2F--%20%E5%9F%BA%E7%A1%80%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[docker基本使用docker安装 安装镜像 通常安装docker-ce，镜像源可以从国内清华或者阿里云下载[https://developer.aliyun.com/mirror/docker-ce?spm=a2c6h.13651102.0.0.3e221b11BVVoBl] 安装必备工具 1yum install -y yum-utils device-mapper-persistent-data lvm2 添加源信息 1yum-config-manager --add-repo https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo 更新并安装docker-ce 12yum makecache fastyum -y install docker-ce 配置镜像加速(docker镜像加速：可以选择docker cn,但很慢，通常可以选择国内的其他厂商加速，比如：阿里云)，注意: 阿里云的镜像加速需要个人注册并登陆阿里云，在个人开发者中选择镜像加速，之后会生产个人加速镜像源路径。 1234567docker镜像配置文件位置: /etc/docker/daemon.json # 默认没有docker目录，需要创建和编辑daemon.json1. mkdir /etc/docker2. [root@192 yum.repos.d]# cat /etc/docker/daemon.json&#123; "registry-mirrors": ["https://vwvv5i9f.mirror.aliyuncs.com"]&#125; 启动docker服务，以对镜像的加载使用：systemctl start docker.service 通过命令docker info就能查看当前docker的信息： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849[root@192 yum.repos.d]# docker infoClient: Debug Mode: falseServer: Containers: 0 Running: 0 Paused: 0 Stopped: 0 Images: 0 Server Version: 19.03.8 Storage Driver: overlay2 Backing Filesystem: &lt;unknown&gt; Supports d_type: true Native Overlay Diff: true Logging Driver: json-file Cgroup Driver: cgroupfs Plugins: Volume: local Network: bridge host ipvlan macvlan null overlay Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog Swarm: inactive Runtimes: runc Default Runtime: runc Init Binary: docker-init containerd version: 7ad184331fa3e55e52b890ea95e65ba581ae3429 runc version: dc9208a3303feef5b3839f4323d9beb36df0a9dd init version: fec3683 Security Options: seccomp Profile: default Kernel Version: 3.10.0-1062.el7.x86_64 Operating System: CentOS Linux 7 (Core) OSType: linux Architecture: x86_64 CPUs: 1 Total Memory: 4.659GiB Name: 192.168.100.31 ID: NVAM:QZ2E:VKJY:HRO5:5CHF:L557:E224:AKD5:6XEZ:BWZC:66GT:6NKD Docker Root Dir: /var/lib/docker Debug Mode: false Registry: https://index.docker.io/v1/ Labels: Experimental: false Insecure Registries: 127.0.0.0/8 Registry Mirrors: https://vwvv5i9f.mirror.aliyuncs.com/ # 这里就是配置的镜像加速源 Live Restore Enabled: false docker基本使用docker pull下载镜像 下载一个nginx镜像，命令：docker image pull或者docker pull 123456789[root@192 yum.repos.d]# docker image pull nginx:1.14-alpine1.14-alpine: Pulling from library/nginxbdf0201b3a05: Pull complete 3d0a573c81ed: Pull complete 8129faeb2eb6: Pull complete 3dc99f571daf: Pull complete Digest: sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7Status: Downloaded newer image for nginx:1.14-alpinedocker.io/library/nginx:1.14-alpine 注意： 版本中带有alpine字样的是基本最小单元的版本，比如：一个完整的nginx镜像资源为50M左右大小，而alping则仅为10M左右，alpine版本一般用于测试使用，在生产环境中不建议使用。 通过 docker image ls 命令就能查看本地镜像情况： 123[root@192 yum.repos.d]# docker image lsREPOSITORY TAG IMAGE ID CREATED SIZEnginx 1.14-alpine 8a2fb25a19f5 12 months ago 16MB 显示完整信息 : –no-trunc 123[root@192 yum.repos.d]# docker image ls --no-truncREPOSITORY TAG IMAGE ID CREATED SIZEnginx 1.14-alpine sha256:8a2fb25a19f5dc1528b7a3fabe8b3145ff57fe10e4f1edac6c718a3cf4aa4b73 12 months ago 16MB 常用命令可参考如下关系图： 基本原理图大致如下： 说明： Docker client通过https/https协议调用docker服务端； docker daemon为服务端主程序，docker daemon运行着container中如果本地没有相关镜像就从远端registries拉取； registries（仓库）上存储着基本的应用，并以tag作为标记。]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[通过一件小事就能看出你的管理能力和处事逻辑]]></title>
    <url>%2F2020%2F02%2F12%2F%E9%80%9A%E8%BF%87%E4%B8%80%E4%BB%B6%E5%B0%8F%E4%BA%8B%E5%B0%B1%E8%83%BD%E7%9C%8B%E5%87%BA%E4%BD%A0%E7%9A%84%E7%AE%A1%E7%90%86%E8%83%BD%E5%8A%9B%E5%92%8C%E5%A4%84%E4%BA%8B%E9%80%BB%E8%BE%91%2F</url>
    <content type="text"><![CDATA[故事背景公司宣布要处理一件紧急事件，要求相关部门的员工做视频剪辑并将结果转存至一台存储资源（这里我们称为：control）上，这里运维部门要做好协调工作（为防止外泄，视频资源需要运维人员进行传输），具体为： 在指定的电脑上（这里我们称为agent1、agent2…）安装相关软件; 为防止源视频泄漏，运维需要在agent端做好策略(禁止连接公网；禁止U盘等外设拷贝)； agent要与control能够进行网络连接； 源视频资源特殊加密，所以agent端要配置视频解密功能； 大致需求已经整理完成，看起来工作量也不大，在接到通知后，我们大致过了下实施方案，觉得没什么技术难点就通过了，方案基本实施步骤分为5部分： 准备电脑； 调试网络； 调试电脑； 准备源视频服务器（这里我们称为：dataCenter）。 这里说下大致思路：源视频资源–&gt; dataCenter –&gt; agent–&gt;control，这里的资源传输基本都是内网完成，所以不考虑公网延时问题。基本思路搞定！ 准备工作接下来，运维同学们开始准备机器，配配置策略，调试网络，优化配置(agent、dataCener、contorl都为windows电脑)，运维同学们忙的不亦乐乎，应为工作内容简单。 出现意外源视频资源在几个磁盘阵列中存放，首先需要发送者确认相关操作人员需要的视频资源（这里需要在几个阵列中检索），然后由运维人员按照上述流程进行资源传输。起初，当我们拿到视频资源的时候，进行网络copy时，发现视频资源量很多，每个资源文件又很大，导致传输时间太长，工作流程在开始之初已经把瓶颈挤压在我们身上，而下游的agent端只能等待，由于时间紧急，员工开始抱怨和不满，为了应对这种突发事件，我们只能抱着磁盘阵列挨个电脑上进行拷贝数据，这样的场景可想而知：效率低下、运维很吃力，影响整个工作流的进度，完全没有按照我们相像的流程去工作。。。 思考通过一段时间的低效工作方式后，发现问题的严重性和对整个流程的疏忽大意导致这个事故发生，瓶颈怎么会出现在我们这里？到底哪里出错了？内网传输虽然有些局限性，但是不可能因为传输引起的瓶颈啊？思来想去，必须要采取措施才行。 优化方案所以必须要把工作流程优化： 既然网络传输不能达到理想状态，只能按照优先级处理（沟通）； 资源必须从dataCenter中传输，这样能大大缓解运维的工作负载； 资源传输可以分批执行，因为剪辑工作不能批量操作（沟通）； agent端处理完成后可以分批或者把紧急视频优先传输给control（这个操作员工可以通过飞鸽之类的工具操作，简单，易上手）（沟通）。 总结通过优化方案实施后，发现效率提升了很高，差不多接近80%。也从优化方案中几点可以看出大部分工作只要提前做好沟通确认，工作效率也就自然而然的提升了。所以，在做一件事情前一定要沟通确认每个环节，把沟通做好了能节省很大的工作量。在做事情前，在设计方案时，应该按照策略进行模拟实践，俗话说的好实践是检验真理的唯一标准。]]></content>
      <categories>
        <category>工作杂谈</category>
      </categories>
      <tags>
        <tag>工作总结</tag>
        <tag>杂谈</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[zabbix监控项目接口]]></title>
    <url>%2F2019%2F10%2F10%2Fzabbix%E7%9B%91%E6%8E%A7%E9%A1%B9%E7%9B%AE%E6%8E%A5%E5%8F%A3%2F</url>
    <content type="text"><![CDATA[## 背景国庆期间出现项目访问异常，zabbix也没报警。通过线上日志排查，初步判断是由于内存溢出导致，在项目接口方面由于没做监控，导致不能及时发现和响应问题。急需监控处理 解决方案考虑到后续域名动态更新及维护效率，把所有域名放置gitlab中，每次监控程序自动刷新配置，有问题则直接报警，代码如下： 1234567891011121314151617181920212223242526272829303132333435363738394041[root@support zabbix]# cat checkDomainApi.py # -*- coding: UTF-8 -*-# @File : checkDomainApi.py# @Time : 2019/10/10# @Author : Duan.rj&apos;&apos;&apos;说明； git中获取最新接口文件(domainApiList)，判断文件内所有接口是否异常(正常为True，其他都为异常) \ 如有异常则发送异常api&apos;&apos;&apos;import urllib2domainFileDir = &apos;/opt/Script&apos;domainFile = domainFileDir + &apos;/domainApiList&apos;domainErrorList = []# 获取最新文件with open(domainFile) as f: domainUrls = f.readlines() # readlines读取时会带 &quot;\n&quot;换行符，需要二次过滤 domainUrlsList = &apos;&apos;.join(domainUrls).strip(&apos;\n&apos;).splitlines() for domainUrl in domainUrlsList: try: getValue = urllib2.urlopen(&apos;http://&apos; + domainUrl + &apos;/monit/heartbeat&apos;) if getValue.read() != &apos;true&apos;: domainErrorList.append(domainUrl) except Exception: domainErrorList.append(domainUrl)if domainErrorList != []: for domainUrl in domainErrorList: print(&apos;GET &quot;&apos; + domainUrl + &apos;&quot; API Error!&apos;)else: print(0) 要想避免脚本或者监控的域名文件(这里是domainApiList)每次不能实时更新，推荐使用crontab定时更新： 123[root@support zabbix]# crontab -l# check domain script and domain file00 */1 * * * cd /opt/Script/ops/zabbix;git pull 2&gt;&amp;1 &gt;&gt; /var/log/messages 这样，本地有任何改动，当push到git server后，服务端就会定期更新。 zabbix配置新建模板，并定义监控项和触发器，由于异常返回为字符串，注意在监控项中信息类型要配置正确 触发器配置 当域名有问题时，收到报警如下： 完。]]></content>
      <categories>
        <category>zabbix</category>
      </categories>
      <tags>
        <tag>zabbix</tag>
        <tag>监控项目接口</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker学习笔记]]></title>
    <url>%2F2019%2F09%2F27%2Fdocker%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[docker学习笔记镜像操作搜索镜像docker search 镜像名称 123456789[root@bogon ~]# docker search centosINDEX NAME DESCRIPTION STARS OFFICIAL AUTOMATEDdocker.io docker.io/centos The official build of CentOS. 5571 [OK] docker.io docker.io/ansible/centos7-ansible Ansible on Centos7 123 [OK]docker.io docker.io/jdeathe/centos-ssh OpenSSH / Supervisor / EPEL/IUS/SCL Repos ... 112 [OK]docker.io docker.io/consol/centos-xfce-vnc Centos container with &quot;headless&quot; VNC sessi... 99 [OK]docker.io docker.io/centos/mysql-57-centos7 MySQL 5.7 SQL database server 63 docker.io docker.io/imagine10255/centos6-lnmp-php56 centos6-lnmp-php56 57 [OK].... 获取镜像docker pull 镜像名称 12345678# 示例[root@bogon ~]# docker pull docker.io/centosUsing default tag: latestTrying to pull repository docker.io/library/centos ... latest: Pulling from docker.io/library/centosd8d02d457314: Pull complete Digest: sha256:307835c385f656ec2e2fec602cf093224173c51119bbebd602c53c3653a3d6ebStatus: Downloaded newer image for docker.io/centos:latest 查看镜像信息docker images 12345# 示例[root@bogon ~]# docker imagesREPOSITORY TAG IMAGE ID CREATED SIZEtest latest adca3d04a9c3 9 minutes ago 202 MBdocker.io/centos latest 67fa590cfc1c 4 weeks ago 202 MB 删除镜像docker rmi 镜像名称 1234# 示例[root@bogon ~]# docker rmi centosUntagged: centos:latestUntagged: docker.io/centos@sha256:307835c385f656ec2e2fec602cf093224173c51119bbebd602c53c3653a3d6eb 创建镜像基于已有镜像的容器创建docker commit … 123-a, --author=&quot;&quot; 作者信息-m, --message=&quot;&quot; 提交信息-p, --pause==true 提交时暂停容器运行 123456789101112131415161718# 示例[root@bogon ~]# docker imagesREPOSITORY TAG IMAGE ID CREATED SIZEdocker.io/centos latest 67fa590cfc1c 4 weeks ago 202 MB[root@bogon ~]# docker run -ti docker.io/centos /bin/bash[root@507ae2970ce5 /]# touch test[root@507ae2970ce5 /]# exit[root@bogon ~]# docker commit -m &quot;add a new file&quot; -a &quot;Duan.rj&quot; 507ae2970ce5 testsha256:adca3d04a9c3857e0debf1814ebf68c639bb013630910adcbcb2463b05044f12# 成功后会返回新创建的镜像ID，如上图# 查看新创建的镜像：[root@bogon ~]# docker imagesREPOSITORY TAG IMAGE ID CREATED SIZEtest latest adca3d04a9c3 56 seconds ago 202 MBdocker.io/centos latest 67fa590cfc1c 4 weeks ago 202 MB 容器操作新建容器docker create -it … 123456# 示例[root@bogon ~]# docker create -it centos:latest3f1b6af49bb02c329b1cd9ad9414797978963a3909477e0b2dfce125860d571c[root@bogon ~]# docker ps -aCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES3f1b6af49bb0 centos:latest &quot;/bin/bash&quot; 17 seconds ago Created flamboyant_easley 上述为新建一个容器，但是处于停止状态，可以使用docker start命令启动它。 123456# 示例[root@bogon ~]# docker start 3f1b6af49bb03f1b6af49bb0[root@bogon ~]# docker ps -aCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES3f1b6af49bb0 centos:latest &quot;/bin/bash&quot; 3 minutes ago Up 4 seconds flamboyant_easley 新建并启动容器启动容器有两种方式，一种是基于镜像新建一个容器并启动，另外一种是将在终止状态的容器重新启动。所需命令为docker run，等价于先执行docker create命令，再执行docker start命令。 1234567# 示例[root@bogon ~]# docker run centos /bin/echo &quot;Hello world&quot;Hello world[root@bogon ~]# docker ps -aCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMESc2ded0c4a577 centos &quot;/bin/echo &apos;Hello ...&quot; 4 seconds ago Exited (0) 3 seconds ago silly_hoover3f1b6af49bb0 centos:latest &quot;/bin/bash&quot; 9 minutes ago Up 5 minutes flamboyant_easley 启动一个bash终端，允许用户进行交互：123456789101112# 示例[root@bogon ~]# docker run -t -i centos /bin/bash[root@a61f9ada2179 /]# pwd/[root@a61f9ada2179 /]# lsanaconda-post.log bin dev etc home lib lib64 media mnt opt proc root run sbin srv sys tmp usr var[root@a61f9ada2179 /]# ps PID TTY TIME CMD 1 ? 00:00:00 bash 15 ? 00:00:00 ps[root@a61f9ada2179 /]# exitexit 守护状态运行通过“-d”参数实现 1234567891011# 示例[root@bogon ~]# docker run -d centos /bin/sh -c &quot;while true;do echo hello world; sleep 1;done&quot;4ef71250e5e534176e7b3ff59f238b26b771612707a415786d0433ee3eea9859[root@bogon ~]# docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES4ef71250e5e5 centos &quot;/bin/sh -c &apos;while...&quot; 6 seconds ago Up 5 seconds vibrant_wiles3f1b6af49bb0 centos:latest &quot;/bin/bash&quot; 14 minutes ago Up 10 minutes flamboyant_easley[root@bogon ~]# docker logs 4ef7hello worldhello world... 终止容器可以通过docker stop终止运行中的容器，命令格式为docker stop [-t|—time[=10]]。它会首先向容器发送SIGTERM信号，等待一段时间后（默认为10秒），再发送SIGKILL信号终止容器 12345678910# 示例[root@bogon ~]# docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES4ef71250e5e5 centos &quot;/bin/sh -c &apos;while...&quot; 7 minutes ago Up 7 minutes vibrant_wiles3f1b6af49bb0 centos:latest &quot;/bin/bash&quot; 21 minutes ago Up 18 minutes flamboyant_easley[root@bogon ~]# docker stop 4ef71250e5e54ef71250e5e5[root@bogon ~]# docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES3f1b6af49bb0 centos:latest &quot;/bin/bash&quot; 22 minutes ago Up 18 minutes flamboyant_easley 进入容器在使用-d进入后台后，如果需要进入容器进行操作，可以使用docker attach、docker exec、nsenter工具等。 docker attach1234567# 示例[root@bogon ~]# docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES3f1b6af49bb0 centos:latest &quot;/bin/bash&quot; 32 minutes ago Up 28 minutes flamboyant_easley[root@bogon ~]# docker exec -ti 3f1b6af49bb0 /bin/bash[root@3f1b6af49bb0 /]# lsanaconda-post.log bin dev etc home lib lib64 media mnt opt proc root run sbin srv sys tmp usr var 删除容器docker rm删除一个处于停止状态的容器 123-f, --force=false 强行终止并删除一个运行中的容器。-l, --link=false 删除容器的连接，但保留容器。-v, --volumes=false 删除容器挂载的数据卷。 12345678910111213141516171819202122# 示例[root@bogon ~]# docker ps -aCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES4482fc316c14 centos &quot;/bin/bash&quot; 6 minutes ago Exited (0) 4 minutes ago nifty_jennings4ef71250e5e5 centos &quot;/bin/sh -c &apos;while...&quot; 22 minutes ago Exited (137) 14 minutes ago vibrant_wilesa61f9ada2179 centos &quot;/bin/bash&quot; 25 minutes ago Exited (0) 25 minutes ago vibrant_brattainc2ded0c4a577 centos &quot;/bin/echo &apos;Hello ...&quot; 27 minutes ago Exited (0) 27 minutes ago silly_hoover3f1b6af49bb0 centos:latest &quot;/bin/bash&quot; 36 minutes ago Up 32 minutes flamboyant_easley1fa5a642a73d test &quot;/bin/bash&quot; 58 minutes ago Exited (0) 58 minutes ago brave_meitner507ae2970ce5 docker.io/centos &quot;/bin/bash&quot; About an hour ago Exited (0) About an hour ago xenodochial_wiles[root@bogon ~]# docker rm 4482fc316c144482fc316c14[root@bogon ~]# docker ps -aCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES4ef71250e5e5 centos &quot;/bin/sh -c &apos;while...&quot; 23 minutes ago Exited (137) 14 minutes ago vibrant_wilesa61f9ada2179 centos &quot;/bin/bash&quot; 26 minutes ago Exited (0) 26 minutes ago vibrant_brattainc2ded0c4a577 centos &quot;/bin/echo &apos;Hello ...&quot; 28 minutes ago Exited (0) 28 minutes ago silly_hoover3f1b6af49bb0 centos:latest &quot;/bin/bash&quot; 37 minutes ago Up 33 minutes flamboyant_easley1fa5a642a73d test &quot;/bin/bash&quot; 58 minutes ago Exited (0) 58 minutes ago brave_meitner507ae2970ce5 docker.io/centos &quot;/bin/bash&quot; About an hour ago Exited (0) About an hour ago xenodochial_wiles 仓库registry镜像方式搭建本地私有仓库12# 示例docker run -d -p 5000:5000 registry 此时，这将下载并启动一个监听5000端口的registry容器，创建本地私有仓库服务。默认情况下，会将仓库创建在容器的/tmp/registry目录下，可以通过-v参数来将镜像文件存放在本地其他指定路径下： 12# 示例docker run -d -p 5000:5000 -v /opt/data/registry:/tmp/registry registry 上传镜像 1234567# 查看镜像[root@bogon tmp]# docker imagesREPOSITORY TAG IMAGE ID CREATED SIZEdocker.io/centos latest 67fa590cfc1c 5 weeks ago 202 MB# docker tag命令将要上传的镜像(docker.io/centos)标记为仓库地址(格式为：docker tag IMAGES[:TAG] [REGISTRYHOST/][USERNAME/]NAME[:TAG]):[root@bogon tmp]# docker tag centos:latest 192.168.1.187:5000/test 192.168.1.187为仓库地址，接下来上传至仓库 1234# 示例[root@bogon tmp]# docker push 192.168.1.187:5000/testThe push refers to a repository [192.168.1.187:5000/test]Get https://192.168.1.187:5000/v1/_ping: http: server gave HTTP response to HTTPS client 这里出错，提示不是HTTPS协议，docker官方强烈推荐https协议，如果没有，可在docker配置文件中添加“insecure-registries”:[“192.168.1.187:5000”]指定： 123# 示例[root@bogon tmp]# cat /etc/docker/daemon.json &#123; &quot;insecure-registries&quot;:[&quot;192.168.1.187:5000&quot;] &#125; 重启docker并再次push操作 123456# 示例[root@bogon tmp]# systemctl restart docker[root@bogon tmp]# docker push 192.168.1.187:5000/testThe push refers to a repository [192.168.1.187:5000/test]877b494a9f30: Pushed latest: digest: sha256:a36b9e68613d07eec4ef553da84d0012a5ca5ae4a830cf825bb68b929475c869 size: 529 这样，就能push上去了，可在其他docker客户端配置中下载： 123456789101112# 示例[root@localhost ~]# docker pull 192.168.1.187:5000/testUsing default tag: latestTrying to pull repository 192.168.1.187:5000/test ... latest: Pulling from 192.168.1.187:5000/testd8d02d457314: Pull complete Digest: sha256:a36b9e68613d07eec4ef553da84d0012a5ca5ae4a830cf825bb68b929475c869Status: Downloaded newer image for 192.168.1.187:5000/test:latest[root@localhost ~]# docker imagesREPOSITORY TAG IMAGE ID CREATED SIZE192.168.1.187:5000/test latest 67fa590cfc1c 5 weeks ago 202 MB 数据管理数据卷(volume)配置与本地host主机挂载，配置选项-v: 123456789101112131415161718192021# 示例[root@bogon ~]# docker run --name b2 -it -v /data centos[root@fa04a6cb63cf /]# #宿主机上查看b2容器的挂载情况[root@bogon ~]# docker inspect b2...&quot;Mounts&quot;: [ &#123; &quot;Type&quot;: &quot;volume&quot;, &quot;Name&quot;: &quot;d40f1da12c8409119d25d847b9e17242d3ae2fe4bca7936764c04446b87cee44&quot;, &quot;Source&quot;: &quot;/var/lib/docker/volumes/d40f1da12c8409119d25d847b9e17242d3ae2fe4bca7936764c04446b87cee44/_data&quot;, ... &#125; ],&quot;Config&quot;: &#123; ... &quot;Volumes&quot;: &#123; &quot;/data&quot;: &#123;&#125; &#125;, ... 上述配置信息看到b2相关的volume存储位置在/data目录中，而挂载的宿主机的位置为：/var/lib/docker/volumes/d40f1da12c8409119d25d847b9e17242d3ae2fe4bca7936764c04446b87cee44/_data，我们可以在宿主机的这个目录中和b2的volume中分别测试验证挂载： 12345678# 示例# 宿主机执行[root@bogon ~]# cd /var/lib/docker/volumes/d40f1da12c8409119d25d847b9e17242d3ae2fe4bca7936764c04446b87cee44/_data/[root@bogon _data]# echo &quot;hello container&quot; &gt;&gt; test.html# b2容器执行[root@fa04a6cb63cf /]# cat data/test.html hello container 可以看到挂载成功，如果我们要指定宿主机的挂载位置只要在选项参数-v后添加相关位置即可，格式为：-v 宿主机位置:容器位置（例如：-v /data/volume/b2:/data），这种别称为绑定挂载卷 12# 示例[root@bogon ~]# docker run --name b2 -it -v /data/volume/b2:/data centos 把容器b2的/data目录挂载至宿主机的/data/volume/b2目录下，这样访问容器b2的/data目录中的数据实际是访问的宿主机的/data/volume/b2目录下的数据资源。 12345678910111213141516# 示例[root@bogon _data]# docker inspect b2[ ... &quot;Mounts&quot;: [ &#123; &quot;Type&quot;: &quot;bind&quot;, &quot;Source&quot;: &quot;/data/volume/b2&quot;, &quot;Destination&quot;: &quot;/data&quot;, &quot;Mode&quot;: &quot;&quot;, &quot;RW&quot;: true, &quot;Propagation&quot;: &quot;rprivate&quot; &#125; ], ...] docker容器网络容器虚拟化网络大家知道Linux内核支持六中名称空间： UTS 管理主机名和域名 User 用户管理 Mount 挂载管理 IPC 管理进程间通信 Pid 进程id Net 网络管理 所谓网络名称空间是为了协议栈的隔离 未完待续。。。]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>docker学习笔记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[常用函数]]></title>
    <url>%2F2019%2F07%2F28%2Fpython%20paramiko%2F</url>
    <content type="text"><![CDATA[介绍paramiko是一个基于SSH用于连接远程服务器并执行相关操作（SSHClient和SFTPClinet,即一个是远程连接，一个是上传下载服务），使用该模块可以对远程服务器进行命令或文件操作，值得一说的是，fabric和ansible内部的远程管理就是使用的paramiko来现实。可参考:https://www.cnblogs.com/lzc978/p/10978688.html 安装123# 由于 paramiko 模块内部依赖pycrypto，所以先下载安装pycryptopip3 install pycryptopip3 install paramiko 在安装过程中有可能报错: 12345678ERROR:root:code for hash md5 was not found....... File "/usr/local/lib/python2.7/site-packages/pip/_vendor/urllib3/util/__init__.py", line 7, in &lt;module&gt; from .ssl_ import ( File "/usr/local/lib/python2.7/site-packages/pip/_vendor/urllib3/util/ssl_.py", line 8, in &lt;module&gt; from hashlib import md5, sha1, sha256ImportError: cannot import name md5 需要安装openssl 12# Mac需要brew unlink openssl和安装python@2，参考：https://stackoverflow.com/questions/59123154/importerror-cannot-import-name-md5brew unlink openssl &amp;&amp; brew reinstall python@2]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>paramiko模块</tag>
        <tag>python ssh</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[jenkinsfile声明式流水线配置说明]]></title>
    <url>%2F2019%2F05%2F15%2Fjenkinsfile%E5%A3%B0%E6%98%8E%E5%BC%8F%E6%B5%81%E6%B0%B4%E7%BA%BF%E9%85%8D%E7%BD%AE%E8%AF%B4%E6%98%8E%2F</url>
    <content type="text"><![CDATA[jenkinsfile声明式流水线配置说明声明式流水线结构说明 主要模块介绍 pipeline pipeline模块是Jenkins声明式流水线中必须的，它是最外面的部分，同时也是一个流水线项目的标志，其语法为pipeline {},其他的代码都放在这个闭包里 123pipeline &#123; // 流水线代码区域&#125; agent 指定整个流水线或者一个特定阶段在哪运行，在pipeline代码块中，必须要有一个agent指令用来指定默认的执行节点。然而在单个阶段的开始也可以可选地使用一个agent指令，用来指定该阶段应该在哪执行 123456agent any 可运行在任何一个定义好的代理节点上agent none 需要为单个阶段指定代理节点agent &#123; label &quot;&lt;label&gt;&quot;&#125; 流水线可以运行任意一个具有&lt;lable&gt;标签的代理节点上 environment 可选指令，设置环境变量 123456pipeline &#123; agent any environment &#123; TIMEZONE = 'Shanghai' &#125;&#125; 上述代码为定义一个TIMEZONE的变量，稍后会在后续例子中介绍调用。 options 可选参数，指定在jenkins配置选项中的一些配置值，例如输出带时间戳，构建历史保留次数等等 1234options &#123; // 操作台输出日志(需要安装timestamps插件) timestamps() &#125; timestamps需要额外安装Timestamper插件才能使用。 后续待更新。。。]]></content>
      <categories>
        <category>jenkins</category>
      </categories>
      <tags>
        <tag>jenkins</tag>
        <tag>pipline</tag>
        <tag>流水线配置</tag>
        <tag>jenkinsfile</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis数据持久化]]></title>
    <url>%2F2019%2F03%2F05%2Fredis%E6%95%B0%E6%8D%AE%E6%8C%81%E4%B9%85%E5%8C%96%2F</url>
    <content type="text"><![CDATA[持久化概念介绍通常数据持久化简单可理解为存储在内存当中的数据二次存储至本地磁盘中，达到内存丢失的情况下数据依然有留存。而Redis则提供了两种持久化方案：RDB（Redis DataBase） 和 AOF（Append Only File）。 RDB方式RDB方式是一种快照式的持久化方法，将某一时刻的数据持久化到磁盘中。 redis在进行数据持久化的过程中，会先将数据写入到一个临时文件中，待持久化过程都结束了，才会用这个临时文件替换上次持久化好的文件。正是这种特性，让我们可以随时来进行备份，因为快照文件总是完整可用的。 对于RDB方式，redis会单独创建（fork）一个子进程来进行持久化，而主进程是不会进行任何IO操作的，这样就确保了redis极高的性能。 如果需要进行大规模数据的恢复，且对于数据恢复的完整性不是非常敏感，那RDB方式要比AOF方式更加的高效。 AOF方式AOF方式是将执行过的写指令记录下来，在数据恢复时按照丛前到后的顺序再将指令执行一遍。 AOF命令以redis协议追加保存每次写的操作到文件末尾.Redis还能对AOF文件进行后台重写,使得AOF文件的体积不至于过大.默认的AOF持久化策略是每秒钟fsync一次（fsync是指把缓存中的写指令记录到磁盘中），因为在这种情况下，redis仍然可以保持很好的处理性能，即使redis故障，也只会丢失最近1秒钟的数据。 如果在追加日志时，恰好遇到磁盘空间满、inode满或断电等情况导致日志写入不完整，也没有关系，redis提供了redis-check-aof工具，可以用来进行日志修复。 因为采用了追加方式，如果不做任何处理的话，AOF文件会变得越来越大，为此，redis提供了AOF文件重写（rewrite）机制，即当AOF文件的大小超过所设定的阈值时，redis就会启动AOF文件的内容压缩，只保留可以恢复数据的最小指令集。举个例子或许更形象，假如我们调用了100次INCR指令，在AOF文件中就要存储100条指令，但这明显是很低效的，完全可以把这100条指令合并成一条SET指令，这就是重写机制的原理。 在进行AOF重写时，仍然是采用先写临时文件，全部完成后再替换的流程，所以断电、磁盘满等问题都不会影响AOF文件的可用性。 两种持久化方式对比 RDB AOF 备份 全量备份，一次保存整个数据库 增量备份，一次保存一个修改数据库的命令 保存间隔 较长 默认1秒 还原速度 快 一般 阻塞 save会阻塞，但bgsave或者自动不会阻塞 无论是平时还是AOF重写，都不会阻塞 场景 适合数据备份，默认开启 适合保存数据，和一般sql持久化方式一样，默认关闭 启动优先级 底 高 体积 小 大 恢复速度 快 慢 安全性 易丢数据 根据策略决定 轻重 重 轻 配置方式RDB配置方式默认情况下，是快照rdb的持久化方式，将内存中的数据以快照的方式写入二进制文件中，默认的文件名是dump.rdbredis.conf 默认配置： 123save 900 1 # 900秒之内，如果超过1个key被修改，则发起快照保存；save 300 10 # 300秒内，如果超过10个key被修改，则发起快照保存；save 60 10000 # 1分钟之内，如果1万个key被修改，则发起快照保存; 这种方式不能完全保证数据持久化，因为是定时保存，所以当redis服务down掉，就会丢失一部分数据，而且数据量大，写操作多的情况下，会引起大量的磁盘IO操作，会影响性能。 所以，如果这两种方式同时开启，如果对数据进行恢复，不应该用rdb持久化方式对数据库进行恢复。 AOF配置方式使用aof做持久化，每一个写命令都通过write函数追加到appendonly.aof中。 配置方式：启动aof持久化的方式： 123456vim redis.conf...dir ./appendonly yes # 默认是no，开启后，会在dir对应的目录中生成一个appendonly.aof... 使用AOF做持久化，每一个命令以 Redis 协议的格式来保存，新命令会被追加到文件的末尾。 Redis 还可以在后台对 AOF 文件进行重写，使得 AOF文件的体积不会超出保存数据集状态所需的实际大小。实际上，AOF持久化并不会立即将命令写入到硬盘文件中，而是写入到硬盘缓存，在接下来的策略中，配置多久来从硬盘缓存写入到硬盘文件。所以在一定程度一定条件下，还是会有数据丢失，不过你可以大大减少数据损失 123# appendfsync alwaysappendfsync everysec# appendfsync no 配置说明： always: 每次操作都会立即写入aof文件中 everysec: 每秒持久化一次(默认配置) no: 不主动进行同步操作，默认30s一次 可以看出，always效率最低。建议使用everysec，数据安全性高。Redis允许我们同时使用两种模式 数据持久化测试RDB 模式在redis.conf配置文件中修改配置（默认配置不方便测试，可将频率设置大一点），在redis.conf添加一条进行测试： 12345save 900 1save 300 10save 60 10000save 5 1 # 测试使用 保存后，重启Redis服务，客户端连接测试（-a 连接Redis服务的密码，这里是redis；-p 端口号，默认可不设置）： 1# redis-cli -a redis -p 6381 12345678127.0.0.1:6381&gt; set name sdfOK127.0.0.1:6381&gt; set age 12OK127.0.0.1:6381&gt; set n 123OK127.0.0.1:6381&gt; set m 23OK 这时，发现dump.rdb文件的修改日期变了，并且redis服务端增加了保存日志： 123456789101112131415161718[root@localhost ~]# tail -f redis-service.log 1429:M 09 Apr 13:15:11.891 * 1 changes in 5 seconds. Saving...1429:M 09 Apr 13:15:11.892 * Background saving started by pid 16041604:C 09 Apr 13:15:11.897 * DB saved on disk1604:C 09 Apr 13:15:11.898 * RDB: 6 MB of memory used by copy-on-write1429:M 09 Apr 13:15:11.993 * Background saving terminated with success1429:M 09 Apr 13:15:17.477 * 1 changes in 5 seconds. Saving...1429:M 09 Apr 13:15:17.478 * Background saving started by pid 16051605:C 09 Apr 13:15:17.481 * DB saved on disk1605:C 09 Apr 13:15:17.482 * RDB: 6 MB of memory used by copy-on-write1429:M 09 Apr 13:15:17.579 * Background saving terminated with success1429:M 09 Apr 13:15:40.821 * 1 changes in 5 seconds. Saving...1429:M 09 Apr 13:15:40.823 * Background saving started by pid 16301630:C 09 Apr 13:15:40.829 * DB saved on disk1630:C 09 Apr 13:15:40.830 * RDB: 6 MB of memory used by copy-on-write1429:M 09 Apr 13:15:40.923 * Background saving terminated with success 接下来，重启redis服务端和客户端，看数据是否真的持久化了： 1234567891011121314127.0.0.1:6381&gt; keys *1) "age"2) "n"3) "m"4) "ns"5) "name"127.0.0.1:6381&gt; get name"sdf"127.0.0.1:6381&gt; get age"12"127.0.0.1:6381&gt; get n"123"127.0.0.1:6381&gt; get m"23" 有数据，说明RDB快照持久化成功。 AOF 模式redis.conf默认配置： 1appendonly no 需要把配置文件的appendonly修改为yes，开启持久化。开启后，重启redis服务，会在配置文件”dir “（强烈建议：dir 要指定具体目录，如果使用默认的./目录的话，会根据你执行启动Redis服务的路径生成数据文件，这样即便做了持久化，在不同的路径下启动Redis服务会生成不同的路径，这样数据就很乱套了）开头的指定数据存放目录下生成一个appendonly.aof的文件，就是前文提到的内容。连接Redis服务进行操作验证，这里借着前文的数据进行验证，最后执行flushall清空数据 1234567891011121314127.0.0.1:6381&gt; keys *1) "age"2) "n"3) "m"4) "ns"5) "name"127.0.0.1:6381&gt; get m"23"127.0.0.1:6381&gt; get ns"112"127.0.0.1:6381&gt; flushallOK127.0.0.1:6381&gt; keys *(empty list or set) 打开appendonly.aof,可以看到： 12345678910111213141516171819202122set$3age$212*3$3set$1n$3123*3$3set$1m$223*1$8flushall 把最后的flushall删除掉，重启Redis服务，连接再次查看： 12345678910127.0.0.1:6381&gt; keys *1) "ns"2) "m"3) "name"4) "n"5) "age"127.0.0.1:6381&gt; get ns"112"127.0.0.1:6381&gt; get m"23" 有数据了，说明AOF持久化也成功了，至此，两种模式都已验证数据的持久化。]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[django笔记]]></title>
    <url>%2F2019%2F02%2F27%2Fdjango%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[概述官网很多相关文档，省略。。。 一些文档是整理的网上资源，可以参考Yuan先生 的技术博客。 环境 python： 3.6 pip： 9.0.1 django： 1.11.7 安装Django 根据自己环境安装pip pip install Django 新建django工程 创建Django工程（根据自己环境配置修改） c:\Python36\Scripts\django-admin.exe startproject mysite mysite：django工程名称 cd mysite目录下 python manage.py startapp blog blog：应用名称 启动 python manage.py runserver 8090 目录结构mysite目录 manage.py #入口文件 mysite __init__.py #初始化文件 settings.py #项目主配置文件 urls.py #路由分配配置文件 wsgi.py #Django web server(封装socket,解析APP) blog目录 __init__.py admin.py apps.py models.py #数据库相关配置(orm) tests.py #检测、测试 views.py #视图函数 settings.py文件配置定义templates位置修改TEMPLATES中的DIRS: 'DIRS': [os.path.join(BASE_DIR, 'templates')], 最后效果为 TEMPLATES = [ { 'BACKEND': 'django.template.backends.django.DjangoTemplates', 'DIRS': [os.path.join(BASE_DIR, 'templates')], 'APP_DIRS': True, 'OPTIONS': { 'context_processors': [ 'django.template.context_processors.debug', 'django.template.context_processors.request', 'django.contrib.auth.context_processors.auth', 'django.contrib.messages.context_processors.messages', ], }, }, ] 创建APP后要在 INSTALLED_APPS 添加相应名称比如，我这里创建的是blog应用 INSTALLED_APPS = [ 'django.contrib.admin', 'django.contrib.auth', 'django.contrib.contenttypes', 'django.contrib.sessions', 'django.contrib.messages', 'django.contrib.staticfiles', 'blog', ] 添加mysql数据库连接DATABASES 中修改 DATABASES = { 'default': { # 'ENGINE': 'django.db.backends.sqlite3', # 'NAME': os.path.join(BASE_DIR, 'db.sqlite3'), 'ENGINE': 'django.db.backends.mysql', 'NAME': 'DBNAME', 'USER': 'username', 'PASSWORD': 'password', 'HOST': 'db_host', 'PORT': 'port', } } 注释掉错误警告 MIDDLEWARE = [ 'django.middleware.security.SecurityMiddleware', 'django.contrib.sessions.middleware.SessionMiddleware', 'django.middleware.common.CommonMiddleware', # 'django.middleware.csrf.CsrfViewMiddleware', 'django.contrib.auth.middleware.AuthenticationMiddleware', 'django.contrib.messages.middleware.MessageMiddleware', 'django.middleware.clickjacking.XFrameOptionsMiddleware', ] 指定静态文件位置（如：js、css、jpg等） STATICFILES_DIRS = ( os.path.join(BASE_DIR, 'statics') ) 开启配置之旅第一个页面 blog APP下views.py文件添加一个展示数据的函数 from django.shortcuts import render, HttpResponse # Create your views here. def cur_time(request): return HttpResponse('hello world!') request： 请求，参数可以自定义，但必须有 HttpResponse： 返回（当请求成功后要返回的信息） mysite下的urls.py添加相关路由信息 from blog import views #导入blog下的views模块 urlpatterns = [ url(r'^admin/', admin.site.urls), url(r'^cur_time', views.cur_time), ] 运行启动命令 python manage.py runserver 8090 浏览器打开 localhost:8090/cur_time 就能看到 hello world!信息了。 添加html文件之前在 settings.py 配置文件中指定了html文件的路径。所以，django会在 templates 目录下获取html文件，在mysite工程下新建一个 templates 目录，最后整个工程目录机构为： mysite +mysite +blog +templates 在templates目录下新键一个cur_time.html的html文件并进行编辑，最后代码为 cat views.py from django.shortcuts import render, HttpResponse # Create your views here. import datetime def cur_time(request): times = datetime.datetime.now() return render(request, 'cur_time.html', {'abc': times}) cat cur_time.html &lt;!DOCTYPE html&gt; &lt;html lang="en"&gt; &lt;body&gt; 当前时间： &lt;/body&gt; &lt;/html&gt; 解释 render： 模版渲染,第一个是请求参数&lt;request&gt;,第二个参数是跳转的url名称，第三个是传递变量 abc cur_time.html中的｛｛｝｝是jinja2的模版语言，abc 则是render传过来的变量名，注意两边有空格 再次访问浏览器，应该就能看到当前时间了。 HttpResponse与render的区别 HttpResponse： 一个类，后面跟一个字符串，是实例化的一个对象，直接返回给客户端浏览器，django所有返回给客户端浏览器都是通过这个类实现的 render 渲染工作，首先指定一个html文件，解析完成后调用HttpResponse类返回给客户端浏览器，html文件中的变量、｛｝都不会显示在客户端浏览器上 数据库连接做一个userInfo信息表单，当用户填入相关信息提交后，数据存入数据库中，并展示信息功能 如前面settings.py中的配置文件指定的数据库userInfo信息有三个字段：username、sex、email,所以需要在blog中的models.py进行初始化数据库操作 from django.db import models # Create your models here. class UserInfo(models.Model): username = models.CharField(max_length=64) sex = models.CharField(max_length=64) email = models.CharField(max_length=64) 运行初始化数据命令 python manage.py makemigrations 如果报类似如下错误 File "C:\Python36\lib\site-packages\django\db\__init__.py", line 33, in __getattr__ return getattr(connections[DEFAULT_DB_ALIAS], item) File "C:\Python36\lib\site-packages\django\db\utils.py", line 211, in __getitem__ backend = load_backend(db['ENGINE']) File "C:\Python36\lib\site-packages\django\db\utils.py", line 115, in load_backend return import_module('%s.base' % backend_name) File "C:\Python36\lib\importlib\__init__.py", line 126, in import_module return _bootstrap._gcd_import(name[level:], package, level) File "C:\Python36\lib\site-packages\django\db\backends\mysql\base.py", line 30, in 'Did you install mysqlclient or MySQL-python?' % e django.core.exceptions.ImproperlyConfigured: Error loading MySQLdb module: No module named 'MySQLdb'. Did you install mysqlclient or MySQL-python? 原因：python3不支持MySQLdb，需要在工程mysite下的init.py文件中添加如下内容 import pymysql pymysql.install_as_MySQLdb() 切记 settings.py里的INSTALLED_APPS添加应用名称，否则报错： File "C:\Python36\lib\site-packages\django\db\models\base.py", line 118, in __new__ "INSTALLED_APPS." % (module, name) RuntimeError: Model class blog.models.UserInfo doesn't declare an explicit app_label and isn't in an application in INSTALLED_APPS. django不会创建数据库，所以要提前手动创建。 mysite下的urls.py添加路由指向 from django.conf.urls import url from django.contrib import admin from blog import views urlpatterns = [ url(r'^admin/', admin.site.urls), url(r'^cur_time', views.cur_time), url(r'^userInfo', views.userInfo), #添加userInfo路由指向 ] views.py更新后的内容为： from django.shortcuts import render, HttpResponse from blog import models #导入models模块，用于数据库操作 # Create your views here. import datetime def cur_time(request): times = datetime.datetime.now() # return HttpResponse('hello world!') return render(request, 'cur_time.html', {'abc': times}) def userInfo(req): if req.method == "POST": u = req.POST.get('username', None) s = req.POST.get('sex', None) e = req.POST.get('email', None) # user={'username':username,"sex": sex, "email": email} models.UserInfo.objects.create( #插入数据 username=u, sex=s, email=e ) user_list = models.UserInfo.objects.all() #从数据库中获取所有数据 return render(req, "index.html", {"user_list": user_list}) index.html文件内容 &lt;!DOCTYPE html&gt; &lt;html lang="en"&gt; &lt;body&gt; &lt;form action="/userInfo/" method="post"&gt; &lt;p&gt;姓名&lt;input type="text" name="username"&gt;&lt;/p&gt; &lt;p&gt;性别&lt;input type="text" name="sex"&gt;&lt;/p&gt; &lt;p&gt;邮箱&lt;input type="text" name="email"&gt;&lt;/p&gt; &lt;p&gt;&lt;input type="submit" value="submit"&gt;&lt;/p&gt; &lt;/form&gt; &lt;table border="1px"&gt; &lt;tr&gt; &lt;td&gt;姓名&lt;/td&gt; &lt;td&gt;性别&lt;/td&gt; &lt;td&gt;邮箱&lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;/body&gt; &lt;/html&gt; 表单以 post 提交后跳转到 userInfo 页面。 Django URL(路由系统)URL配置(URLconf)就像Django 所支撑网站的目录。它的本质是URL模式以及要为该URL模式调用的视图函数之间的映射表；你就是以这种方式告诉Django，对于这个URL调用这段代码，对于那个URL调用那段代码。 urlpatterns = [ url(正则表达式, views视图函数，参数，别名), ] 参数： 一个正则表达式字符串 一个可调用对象，通常为一个视图函数或一个指定视图函数路径的字符串 可选的要传递给视图函数的默认参数（字典形式） 一个可选的name参数 示例 from django.conf.urls import url from django.contrib import admin from blog import views urlpatterns = [ url(r'^admin/', admin.site.urls), url(r'^cur_time', views.cur_time), url(r'^userInfo', views.userInfo), url(r'^articles/2003/$', views.special_case_2003), #url(r'^articles/[0-9]{4}/$', views.year_archive), url(r'^articles/([0-9]{4})/$', views.year_archive), #no_named group url(r'^articles/([0-9]{4})/([0-9]{2})/$', views.month_archive), url(r'^articles/([0-9]{4})/([0-9]{2})/([0-9]+)/$', views.article_detail), ] URL匹配规则是由上到下，比如url(r’^articles/2003/$’, views.special_case_2003)和url(r’^articles/([0-9]{4})/$’, views.year_archive) 这两条，都是匹配四个数字。如果URL是articles/2003，虽然也属于^articles/([0-9]{4})，但是会优先匹配url(r’^articles/2003/$’, views.special_case_2003)。 正则表达式添加（）后，指定的views的视图函数也要增加一个自定义的形参，如上面的url(r’^articles/([0-9]{4})/$’, views.year_archive)，在views.year_archive中的year_archive视图函数定义时也要添加一个形参： def year_archive(req,year): return HttpResponse(year) 浏览器访问时就会返回year值 多个()，year_archive要设定多个形参 正则分组（Named groups）有时候URL传参需要指定值，这里就会用到Python正则表达式的?Ppattern， named groups ret=re.search('(?P\d{3})/(?P\w{3})','weeew34ttt123/ooo') print(ret.group()) print(ret.group('id')) print(ret.group('name')) from django.conf.urls import url from . import views urlpatterns = [ url(r'^articles/2003/$', views.special_case_2003), url(r'^articles/(?P[0-9]{4})/$', views.year_archive), url(r'^articles/(?P[0-9]{4})/(?P[0-9]{2})/$', views.month_archive), url(r'^articles/(?P[0-9]{4})/(?P[0-9]{2})/(?P[0-9]{2})/$', views.article_detail), ] 参数名称（name param） urlpatterns = [ url(r'^index',views.index,name='bieming'), ] def index(req): if req.method=='POST': username=req.POST.get('username') password=req.POST.get('password') if username=='alex' and password=='123': return HttpResponse("登陆成功") return render(req,'index.html') &lt;!DOCTYPE html&gt; &lt;html lang="en"&gt; &lt;body&gt; &lt;form action="｛% url 'bieming' %｝" method="post"&gt; 用户名:&lt;input type="text" name="username"&gt; 密码:&lt;input type="password" name="password"&gt; &lt;input type="submit" value="submit"&gt; &lt;/form&gt; &lt;/body&gt; &lt;/html&gt; 导入其他URLconfs #At any point, your urlpatterns can “include” other URLconf modules. This #essentially “roots” a set of URLs below other ones. #For example, here’s an excerpt of the URLconf for the Django website itself. #It includes a number of other URLconfs: from django.conf.urls import include, url urlpatterns = [ url(r'^admin/', admin.site.urls), url(r'^blog/', include('blog.urls')), ] Django Views(视图函数)浏览器 –(Rquest)–&gt; WebServer 浏览器 &lt;–(Response)– WebServer http请求中产生两个核心对象： - http请求： HttpRequest对象 - http响应： HttpResponse对象 HttpRequest对象的属性和方法： # path： 请求页面的全路径，不包括域名 # # method： 请求中使用的HTTP方法的字符串表示。全大写表示。例如 # # if req.method=="GET": # # do_something() # # elseif req.method=="POST": # # do_something_else() # # GET: 包含所有HTTP GET参数的类字典对象 # # POST： 包含所有HTTP POST参数的类字典对象 # # 服务器收到空的POST请求的情况也是可能发生的，也就是说，表单form通过 # HTTP POST方法提交请求，但是表单中可能没有数据，因此不能使用 # if req.POST来判断是否使用了HTTP POST 方法；应该使用 if req.method=="POST" # # # # COOKIES: 包含所有cookies的标准Python字典对象；keys和values都是字符串。 # # FILES： 包含所有上传文件的类字典对象；FILES中的每一个Key都是标签中 name属性的值，FILES中的每一个value同时也是一个标准的python字典对象，包含下面三个Keys： # # filename： 上传文件名，用字符串表示 # content_type: 上传文件的Content Type # content： 上传文件的原始内容 # # # user： 是一个django.contrib.auth.models.User对象，代表当前登陆的用户。如果访问用户当前 # 没有登陆，user将被初始化为django.contrib.auth.models.AnonymousUser的实例。你 # 可以通过user的is_authenticated()方法来辨别用户是否登陆： # if req.user.is_authenticated();只有激活Django中的AuthenticationMiddleware # 时该属性才可用 # # session： 唯一可读写的属性，代表当前会话的字典对象；自己有激活Django中的session支持时该属性才可用。 #方法 get_full_path(), 比如：http://127.0.0.1:8000/index33/?name=123 ,req.get_full_path()得到的结果就是/index33/?name=123 req.path:/index33 注意一个常用方法：request.POST.getlist(‘’) HttpResponse对象： 对于HttpRequest对象来说，是由django自动创建的，但是，HttpResponse对象就必须我们自己创建。每个view请求处理方法必须返回一个HttpResponse对象。 HttpResponse类在django.http.HttpResponse 在HttpResponse对象上扩展的常用方法： 页面渲染： render()（推荐） render_to_response(), 页面跳转： redirect("路径") locals()： 可以直接将函数中所有的变量传给模板 url.py url(r"login", views.login), url(r"yuan_back", views.yuan_back), views.py def login(req): if req.method=="POST": if 1: # return redirect("/yuan_back/") name="yuanhao" return render(req,"my backend.html",locals()) return render(req,"login.html",locals()) def yuan_back(req): name="duanruijun" return render(req,"my backend.html",locals()) login.html &lt;form action="/login/" method="post"&gt; &lt;p&gt;姓名&lt;input type="text" name="username"&gt;&lt;/p&gt; &lt;p&gt;性别&lt;input type="text" name="sex"&gt;&lt;/p&gt; &lt;p&gt;邮箱&lt;input type="text" name="email"&gt;&lt;/p&gt; &lt;p&gt;&lt;input type="submit" value="submit"&gt;&lt;/p&gt; &lt;/form&gt; my backend.html &lt;h1&gt;用户｛｛ name ｝｝你好&lt;/h1&gt; #总结: render和redirect的区别: # 1 if render的页面需要模板语言渲染,需要的将数据库的数据加载到html,那么所有的这一部分 # 除了写在yuan_back的视图函数中,必须还要写在login中,代码重复,没有解耦. # 2 the most important: url没有跳转到/yuan_back/,而是还在/login/,所以当刷新后 # 又得重新登录. 模版什么是模版语言简单说就是html+逻辑控制语句。 模版常用用例 – 万能的句号点（.）urls.py from django.conf.urls import url from django.contrib import admin from app01 import views urlpatterns = [ url(r'^admin/', admin.site.urls), url(r'^index/', views.index), views.py from django.shortcuts import render import datetime # Create your views here. def index(req): class profile(object): def __init__(self, name, age): self.name = name self.age = age s1 = [1,22,333] s2 = {'username': 'duanrj', 'email': '123@qq.com'} s3 = datetime.datetime.now() s4 = profile("Bob", "20") s5 = 'hello' s6 = 6 s7 = [] s8 = "跳转" return render(req, 'index.html', { 'value1': s1, 'value2': s2, 'value3': s3, 'value4': s4, 'value5': s5, 'value6': s6, 'value7': s7, 'value8': s8, }) index.html &lt;!DOCTYPE html&gt; &lt;html lang="en"&gt; &lt;body&gt; ====打印列表第n个值==== ｛｛ value1.2 ｝｝ ====打印dict的username值==== ｛｛ value2.username ｝｝ 打印对象的属性 ｛｛ value3.year ｝｝ ====打印对象的属性2==== ｛｛ value4 ｝｝ ｛｛ value4.name ｝｝ ｛｛ value4.age ｝｝ ====模版语言中的遍历==== ｛% for i in obj %｝ ｛｛ forloop.counter ｝｝:｛｛ i ｝｝ //索引从1开始 ｛｛ forloop.counter0 ｝｝:｛｛ i ｝｝ //索引从0开始 ｛% endfor %｝ ====filter:小写转为大写==== ｛｛ value5 | upper ｝｝ ｛｛ value5 | lower ｝｝ ｛｛ value5 | capfirst ｝｝ ｛｛ value5 | first ｝｝ ====算数运算==== ｛｛ value6 | add:5 ｝｝ ====为空时提示信息==== ｛｛ value7 | default:'空的' ｝｝ ====当成普通字符串处理==== ｛｛ value8 ｝｝ 如果想把类似于html 标签的都渲染出来可以这样 ｛% autoescape off %} ｛｛ value8 ｝｝ ｛% endautoescape %} 也可以用safe ｛｛ obj|safe ｝｝ ====禁止render==== ｛% verbatim %｝ ｛｛ name ｝｝ ｛% endverbatim %｝ &lt;/body&gt; &lt;/html&gt; filter作用于简单操作，简化前后端开发重复性工作]]></content>
      <categories>
        <category>django</category>
      </categories>
      <tags>
        <tag>django</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[jenkins基本使用]]></title>
    <url>%2F2019%2F02%2F15%2Fjenkins%E8%87%AA%E5%AE%9A%E4%B9%89tag%2F</url>
    <content type="text"><![CDATA[创建证书步骤证书存放目录123cd /home/gitsource/mkdir &lt;item_name&gt;cd &lt;item_name&gt; 创建全局存储证书1git config --global credential.helper store 获取版本(账号|密码)1git clone &lt;Gitlab_url&gt; 获取tag列表1git ls-remote -h -t &lt;Gitlab_url&gt; refs/tags/* Jenkins配置添加动态选择变量12345678910111213141516171819202122232425262728# 创建变量参数Dynamic Choice ParameterName =&gt;select_tagChoices =&gt;proc1 = [&apos;/bin/bash&apos;, &apos;-c&apos;, &quot;git ls-remote -h -t http://git.epailive.com/epailive/phpweb.git refs/tags/v* &quot;].execute()proc2 = [&apos;/bin/bash&apos;, &apos;-c&apos;, &quot;awk &apos;&#123;print \$2&#125;&apos;&quot;].execute()proc3 = [&apos;/bin/bash&apos;, &apos;-c&apos;, &quot;sed s%^refs/heads%origin%&quot;].execute()proc4 = [&apos;/bin/bash&apos;, &apos;-c&apos;, &quot;sort -nr&quot;].execute()proc5 = [&apos;/bin/bash&apos;, &apos;-c&apos;, &quot;grep -v &#123;&#125;&quot;].execute()all = proc1 | proc2 | proc3 | proc4 |proc5String result = all.textresult.tokenize()=&gt; 更改后，获取的字符串确实不用sed替换proc1 = [&apos;/bin/bash&apos;, &apos;-c&apos;, &quot;git ls-remote -h -t http://git.epailive.com/epailive/phpweb.git refs/tags/v* &quot;].execute()proc2 = [&apos;/bin/bash&apos;, &apos;-c&apos;, &quot;awk &apos;&#123;print \$2&#125;&apos;&quot;].execute()proc3 = [&apos;/bin/bash&apos;, &apos;-c&apos;, &quot;sort -nr&quot;].execute()proc4 = [&apos;/bin/bash&apos;, &apos;-c&apos;, &quot;grep -v &#123;&#125;&quot;].execute()all = proc1 | proc2 | proc3 | proc4String result = all.textresult.tokenize() 修改gitlab拉取规则123456789101112131415# 资源管理Git# Repository URL&lt;gitlab url&gt;# Credentials账号密码# Branch Specifier (blank for &apos;any&apos;)$&#123;select_tag&#125;# Additional Behaviours## check out to a sub-directory$&#123;BUILD_TAG&#125; //内置变量]]></content>
      <categories>
        <category>jenkins</category>
      </categories>
      <tags>
        <tag>jenkins</tag>
        <tag>jenkins基本使用</tag>
        <tag>自定义tag</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[centos7.5 内核崩溃]]></title>
    <url>%2F2018%2F03%2F13%2Fcentos7.5%20%E5%86%85%E6%A0%B8%E5%B4%A9%E6%BA%83%2F</url>
    <content type="text"><![CDATA[问题描述公司一台dell服务器(dell 2950)在正常运行后突然出现系统内容崩溃，开机启动加载centos7.5后出现如下图： 思考出现此类问题后，第一时间马上整理宕机后的问题： 业务影响范围？ 什么原因导致的？ 如何修复系统？ 带着问题去解决 业务影响范围 根据第一时间的了解和公司业务信息查阅，此服务器只影响公司人员正常使用文档库，系统宕机在周五晚上，公司人员在休息中使用较少，所以影响范围不大，但是里面数据集成了公司日常的工作内容，需要加急处理。 什么原因导致的 服务器在此前迁移时有一次意外停机，通过人工启动后一直运行正常，但是最近有出现SSH服务连接异常(ICMP测试没问题)，对外提供的服务也正常运行，通过宿主机连接查看系统日志无异常行为，所以修复优先级排后，后来发现问题原因基本是因此次意外宕机造成的。 如何修复系统 在修复前准备工作中，考虑了几个修复方案：光盘修复工具、raid修复系统、系统盘挂载至其他服务器上修复并copy数据、U盘可读写方式进入系统挂载并copy数据，如果修复比较困难，应立即做好数据迁移准备：准备新环境（由于文档库的附件资料存在服务器中，内容信息存在数据库中(数据和附件不在同一台服务器上)，所以重点考虑附件的恢复）。 光盘镜像修复工具 通过光盘镜像挂载选择系统急救模式进入系统后发现init丢失，lib库及命令也同样丢失，通过自行尝试修复及网上资料查阅也无济于事。可见问题已经难以解决，所以，应当采取第二个措施，数据的copy及新环境的准备(光盘镜像中挂载U盘需要安装驱动，安装失败，放弃)。 raid修复系统 此服务器做的是raid1，在raid配置中尝试修复，没有成功，放弃。 挂载至其他服务器上 系统盘挂载其他服务器上，不识别，放弃。 U盘启动COPY数据 通过U盘启动并进入系统急救模式，参照提示切换至系统(chroot /mnt/images)，查看源数据无损坏，并挂载U盘(成功)，进行数据的copy并迁移至新环境中，成功。 总结前前后后折腾了一天时间，好歹问题出在放假途中，对员工使用影响很少，有大量的时间去查阅问题资料，造成这种问题的主要原因有几个： 系统单点没做好冗余； 数据的存储没做好备份或者进行分布式存储策略； 当问题已经开始有不好的预兆时应及时处理。]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>Attempted to kill init</tag>
        <tag>centos内核崩溃</tag>
        <tag>centos7</tag>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[jenkins maven项目实战]]></title>
    <url>%2F2018%2F03%2F07%2Fjenkins_maven%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%981%2F</url>
    <content type="text"><![CDATA[环境 gitlab: http://192.168.62.206 jenkins: http://192.168.62.210:8080 depserver: 192.168.63.116 实例说明 gitlab工程地址：git@192.168.62.206:Mall/eureka.git jenkins构建完成后本地存放位置：/target depserver工程目录：/home/jiagouzu/tingyun/target/ 流程 jenkins通过gitlab pull工程代码 jenkins通过本地maven工具构建、打包工程代码 jenkins把完成的.jar推送到服务器相应目录下 注意事项 jenkins pull代码时，gitlab要确保有jenkins的Deploy key key信息 gitlab的项目“Mall/eureka”启用deploy key(settings–&gt; Repository–&gt;Deploy Keys)： jenkins配置说明jenkins配置depServer节点 添加depserver服务器节点（系统管理–&gt;系统设置–&gt;SSH Servers） 新建一个Server,完成后选择高级配置相关信息： 其他保持默认，最后选择Test Configuration可测试下 配置拉取gitlab地址私钥信息这里就不多讲了，具体步骤可见jenkins基本使用 创建项目 新建一个项目，类型为自由风格的（maven类型有很多限制），这里我的名称为“商城” 配置“商城”，在General标签里配置相关信息，注意点开“高级”选择“使用自定义的工作空间” 源码管理 构建触发器 手动还是自动构建，这里也可以看之前的文章jenkins基本使用 构建环境 构建（mvn命令执行构建） 这里注意mvn命令的位置，jenkins默认安装选择在 /home/apache-maven-3.5.2/bin/mvn 可通过（系统管理–&gt;全局工具配置）进行相应的更改，但要给予jenkins执行的权限，这里我把命令ln到/usr/local/bin目录下，chmod +x mvn 如果没有设置会报类似错误： [/target] $ /bin/sh -xe /tmp/jenkins6497126245319590786.sh + mvn clean package /tmp/jenkins6497126245319590786.sh: line 2: mvn: command not found Build step 'Execute shell' marked build as failure SSH: Current build result is [FAILURE], not going to run. 构建后操作（完成构建后的部署工作） 选择“Send build artifacts over SSH”,注意要安装 over ssh插件 注意： 这里的Remote directory指的就是前面配置depserver的工程目录地址“/home/jiagouzu/tingyun” 点击完成后就可以测试了，默认maven构建的配置文件直接找的官方地址，在构建日志当中会出现如下信息 https://repo.maven.apache.org/maven2/org/hibernate/hibernate-validator/5.3.6.Final/hibernate-validator-5.3.6.Final.jar (727 kB at 2.4 kB/s) Downloading from central: https://repo.maven.apache.org/maven2/org/springframework/boot/spring-boot-starter-actuator/1.5.9.RELEASE/spring-boot-starter-actuator-1.5.9.RELEASE.jar 这里需要注意： 第一次构建时，maven需要下载部署工程所需要的jar包； 改善办法之一是同开发要一份maven构建工具的settings.xml 配置文件替换你的maven工具里的settings.xml（一般开发会有自己的内部仓库），在这里是我的jenkins服务器中的“/home/apache-maven-3.5.2/conf/settings.xml”，注意修改里面的“/MavenRepository”这是指你存放maven工具所需jar包的目录，别忘了给jenkins能执行的权限。 最后测试输出类似信息证明配置成功： [INFO] BUILD SUCCESS [INFO] ------------------------------------------------------------------------ [INFO] Total time: 4.246 s [INFO] Finished at: 2018-03-07T14:54:53+08:00 [INFO] Final Memory: 36M/203M [INFO] ------------------------------------------------------------------------ SSH: Failed to get hostname [192v168v62v210: 192v168v62v210: 未知的名称或服务] SSH: Connecting with configuration [192.168.63.116] ... SSH: EXEC: STDOUT/STDERR from command [/bin/bash /home/mall_start.sh start] ... SSH: EXEC: completed after 200 ms SSH: Disconnecting configuration [192.168.63.116] ... SSH: Transferred 1 file(s) Finished: SUCCESS]]></content>
      <categories>
        <category>jenkins</category>
      </categories>
      <tags>
        <tag>maven构建</tag>
        <tag>jenkins</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一次数据表损坏的修复过程]]></title>
    <url>%2F2017%2F12%2F15%2FMySQL_%E4%B8%80%E6%AC%A1%E6%95%B0%E6%8D%AE%E8%A1%A8%E6%8D%9F%E5%9D%8F%E8%AE%B0%E5%BD%95%E4%BF%AE%E5%A4%8D%2F</url>
    <content type="text"><![CDATA[一、数据库表损坏现象mysql数据库非正常停止，导致所有数据库（除自身数据库信息）信息表名正常显示，但打开表提示：表不存在，数据库数据存放路径信息显示占用大小正常，证明数据没有丢失，数据库启动报错如下信息： 123456789101112131415161718192021222324252019-01-25 13:46:19 13621 [Note] Server socket created on IP: '::'.2019-01-25 13:46:19 13621 [Warning] InnoDB: Cannot open table mysql/slave_master_info from the internal data dictionary of InnoDB though the .frm file for the table exists. See http://dev.mysql.com/doc/refman/5.6/en/innodb-troubleshooting.html for how you can resolve the problem.2019-01-25 13:46:19 13621 [Warning] Info table is not ready to be used. Table 'mysql.slave_master_info' cannot be opened.2019-01-25 13:46:19 13621 [Warning] InnoDB: Cannot open table mysql/slave_worker_info from the internal data dictionary of InnoDB though the .frm file for the table exists. See http://dev.mysql.com/doc/refman/5.6/en/innodb-troubleshooting.html for how you can resolve the problem.2019-01-25 13:46:19 13621 [Warning] InnoDB: Cannot open table mysql/slave_relay_log_info from the internal data dictionary of InnoDB though the .frm file for the table exists. See http://dev.mysql.com/doc/refman/5.6/en/innodb-troubleshooting.html for how you can resolve the problem.2019-01-25 13:46:19 13621 [Warning] Info table is not ready to be used. Table 'mysql.slave_relay_log_info' cannot be opened.2019-01-25 13:46:19 13621 [Note] Event Scheduler: Loaded 0 events2019-01-25 13:46:19 13621 [Note] /usr/local/mysql/bin/mysqld: ready for connections.Version: '5.6.29-log' socket: '/usr/local/mysql/mysqld.sock' port: 3306 Source distribution2019-01-25 13:47:23 13621 [Note] /usr/local/mysql/bin/mysqld: Normal shutdown 上述日志获取到： InnoDB: Cannot open table mysql/slave_worker_info from the internal data dictionary of InnoDB though the .frm file for the table exists. 尽管表“slave_worker_info”已经存在，但是获取不到信息。而且报大量类似表的错误信息 解决 根据错误提示及尝试打开表操作证明数据没有丢失，只是表丢失而已，把表删除，新建表结构，重新挂在数据节点即可： 备份原始表数据（例如：这里操作auth_user表） 12345ls dataDir auth_user.frm auth_user.ibd 删除表 1DROP TABLE IF EXISTS `auth_user 删除ibd文件 1rm -rf push_user_question_record.ibd 重新创建表 1CREATE TABLE `auth_user 丢弃新建表的表空间 1ALTER TABLE auth_user DISCARD TABLESPACE; 复制备份的数据信息 1\cp /BACKUPDIR/auth_user.* MYSQLDATA/DATABASES/ 授权 1chown -R mysql.mysql base_area.* 挂载数据 1ALTER TABLE auth_user IMPORT TABLESPACE; 二、用户添加索引权限mysql给用户添加索引权限： 1grant index on *.* to username@'%' 注意： 这里只是给用户赋予了添加和删除索引的权限，如果想要修改的话，用户\&lt;username>还需要有alter权限，否则会报如下错误： 11142 - ALTER command denied to user 'xxxx'@'xx.xx.xx.xx' tor table 'TABLE_NAME' 添加alter权限： 1grant alter on xx.xx to username@'xx' 三、停止执行过长的sql1234mysql&gt; show processlist;此时可以看到MySQL中正在运行的进程：mysql&gt; kill [Id NAME]]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
        <tag>mysql表损坏</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[shell文件对比]]></title>
    <url>%2F2017%2F10%2F10%2Fshell%E6%96%87%E4%BB%B6%E5%AF%B9%E6%AF%94%2F</url>
    <content type="text"><![CDATA[#!/bin/bash #----判断给定的文件是否存在---- if [ -d $1 ] && [ -d $2 ];then echo -e "俩个文件夹都存在,开始对俩个文件夹进行比对." else if [ -d $1 ];then echo "不存在文件夹:$2" exit else echo "不存在文件夹:$1" exit fi fi #----判断俩个文件中改动过的文件有哪些---- #判断俩个文件的文件和文件夹的个数 echo -e "\e[1;32m######查询每个文件总共有多少个文件和文件夹######\e[0m" fnum1=`ls -Rl $1|grep -e "^-"|wc -l` fnum2=`ls -Rl $2|grep -e "^-"|wc -l` dnum1=`ls -Rl $1|grep -e "^d"|wc -l` dnum2=`ls -Rl $2|grep -e "^d"|wc -l` echo -e "$1:下总共有\e[1;31m$dnum1\e[0m个文件夹,\e[1;31m$fnum1\e[0m个文件." echo -e "$2:下总共有\e[1;31m$dnum2\e[0m个文件夹,\e[1;31m$fnum2\e[0m个文件." #判断$2中新增或者减少的文件夹和文件有哪些 echo -e "\e[1;32m######查看$2中新增或者减少的文件或文件夹########\e[0m" only1=`diff -rq $1 $2|grep "^Only"|awk '{print $3,$4}'|grep -v "WEB\-INF"` only2=`diff -rq $1 $2|grep "^Only"|awk '{print $3,$4}'|grep "WEB\-INF"` echo -e "$only1" echo -e "\e[1;31m$only2\e[0m" #判断$2中改变的文件有哪些 echo -e "\e[1;32m############查看$2中改变的文件有哪些############\e[0m" change1=`diff -rq $1 $2|grep "^File"|awk '{print $2,"------",$4}'|grep -v "WEB\-INF"` change2=`diff -rq $1 $2|grep "^File"|awk '{print $2,"------",$4}'|grep "WEB\-INF"` echo -e "$change1" echo -e "\e[1;31m$change2\e[0m" #查看版本号是否已经更改 echo -e "\e[1;32m######---------查看是否更改版本号---------######\e[0m" cd $1 if [ -f version.html ];then version1=`cat version.html` else echo -e "\e[1;31m$1没有版本号信息.\e[0m" exit fi cd $2 if [ -f version.html ];then version2=`cat version.html` else echo -e "\e[1;31m$2没有版本号信息.\e[0m" exit fi if [ $version1 == $version2 ];then echo -e "\e[1;31m版本号未改动,$1和$2的版本号为$version1\e[0m" else echo -e "\e[1;31;1m版本号已经改动过\e[0m,$1的版本号为\e[1;31;1m$version1\e[0m,$2的版本号为\e[1;31;1m$version2\e[0m." fi]]></content>
      <categories>
        <category>shell</category>
      </categories>
      <tags>
        <tag>shell文件对比</tag>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ping包检测]]></title>
    <url>%2F2017%2F10%2F10%2Fpython_ping%E5%8C%85%E6%A3%80%E6%B5%8B%2F</url>
    <content type="text"><![CDATA[ping包检测 #!/usr/bin/env python #-*- coding: utf-8 -*- import re import subprocess def check_alive(ip,count=1,timeout=1): ''' ping网络测试,通过调用ping命令,发送一个icmp包，从结果中通过正则匹配是否有100%关键字，有则表示丢包，无则表示正常 ''' cmd = 'ping -c %d -w %d %s' % (count,timeout,ip) p = subprocess.Popen(cmd, stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.PIPE, shell=True ) result = p.stdout.read() regex = re.findall('100% packet loss',result) if len(regex) == 0: print "\033[31m%s UP\033[0m" % (ip) else: print "\033[32m%s DOWN\033[0m" % (ip) if __name__ == "__main__": with file('/root/ip.txt','r') as f: for line in f.readlines(): ip = line.strip() check_alive(ip)]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>ping包检测</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[http请求方法介绍]]></title>
    <url>%2F2017%2F08%2F23%2Fhttp_%E8%AF%B7%E6%B1%82%E6%96%B9%E6%B3%95%E4%BB%8B%E7%BB%8D%2F</url>
    <content type="text"><![CDATA[HTTP方法（通常也被称为“动作”）告诉服务器一个页面请求要 做 什么。以下是常见 的方法 GET浏览器告诉服务器只要 得到 页面上的信息并发送这些信息。这可能是最常见的 方法。 HEAD浏览器告诉服务器想要得到信息，但是只要得到 信息头 就行了，页面内容不要。 一个应用应该像接受到一个 GET 请求一样运行，但是不传递实际的内容。在 Flask 中，你根本不必理会这个，下层的 Werkzeug 库会为你处理好。 POST浏览器告诉服务器想要向 URL 发表 一些新的信息，服务器必须确保数据被保存好 且只保存了一次。 HTML 表单实际上就是使用这个访求向服务器传送数据的。 PUT与 POST 方法类似，不同的是服务器可能触发多次储存过程而把旧的值覆盖掉。你 可能会问这样做有什么用？这样做是有原因的。假设在传输过程中连接丢失的情况 下，一个处于浏览器和服务器之间的系统可以在不中断的情况下安全地接收第二次 请求。在这种情况下，使用 POST 方法就无法做到了，因为它只被触发一次。 DELETE删除给定位置的信息。 OPTIONS为客户端提供一个查询 URL 支持哪些方法的捷径。从 Flask 0.6 开始，自动为你 实现了这个方法。有趣的是在 HTML4 和 XHTML1 中，表单只能使用 GET 和 POST 方法。但是 JavaScript 和未来的 HTML 标准中可以使用其他的方法。此外， HTTP 近来已经变得相当 流行，浏览器不再只是唯一使用 HTTP 的客户端。比如许多版本控制系统也使用 HTTP 。]]></content>
      <categories>
        <category>http协议</category>
      </categories>
      <tags>
        <tag>http请求方法简介</tag>
        <tag>http协议</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[记录linux用户操作]]></title>
    <url>%2F2017%2F08%2F23%2Flinux%E8%AE%B0%E5%BD%95%E7%94%A8%E6%88%B7%E6%93%8D%E4%BD%9C%2F</url>
    <content type="text"><![CDATA[记录用户操作追加在 /etc/profilePS1=”whoami@hostname:”‘[$PWD]’historyUSER_IP=who -u am i 2&gt;/dev/null| awk &#39;{print $NF}&#39;|sed -e &#39;s/[()]//g&#39;if [ “$USER_IP” = “” ]thenUSER_IP=hostnamefiif [ ! -d /tmp/dbasky ]thenmkdir /tmp/dbaskychmod 777 /tmp/dbaskyfiif [ ! -d /tmp/dbasky/${LOGNAME} ]thenmkdir /tmp/dbasky/${LOGNAME}chmod 300 /tmp/dbasky/${LOGNAME}fiexport HISTSIZE=4096DT=date &quot;+%Y-%m-%d_%H:%M:%S&quot;export HISTFILE=”/tmp/dbasky/${LOGNAME}/${USER_IP} dbasky.$DT”chmod 600 /tmp/dbasky/${LOGNAME}/dbasky 2&gt;/dev/nullPS1=”whoami@hostname:”‘[$PWD]’historyUSER_IP=who -u am i 2&gt;/dev/null| awk &#39;{print $NF}&#39;|sed -e &#39;s/[()]//g&#39;if [ “$USER_IP” = “” ]thenUSER_IP=hostnamefiif [ ! -d /tmp/dbasky ]thenmkdir /tmp/dbaskychmod 777 /tmp/dbaskyfiif [ ! -d /tmp/dbasky/${LOGNAME} ]thenmkdir /tmp/dbasky/${LOGNAME}chmod 300 /tmp/dbasky/${LOGNAME}fiexport HISTSIZE=4096DT=date &quot;+%Y-%m-%d_%H:%M:%S&quot;export HISTFILE=”/tmp/dbasky/${LOGNAME}/${USER_IP} dbasky.$DT”chmod 600 /tmp/dbasky/${LOGNAME}/dbasky 2&gt;/dev/nullPS1=”whoami@hostname:”‘[$PWD]’historyUSER_IP=who -u am i 2&gt;/dev/null| awk &#39;{print $NF}&#39;|sed -e &#39;s/[()]//g&#39;if [ “$USER_IP” = “” ]thenUSER_IP=hostnamefiif [ ! -d /tmp/dbasky ]thenmkdir /tmp/dbaskychmod 777 /tmp/dbaskyfiif [ ! -d /tmp/dbasky/${LOGNAME} ]thenmkdir /tmp/dbasky/${LOGNAME}chmod 300 /tmp/dbasky/${LOGNAME}fiexport HISTSIZE=4096DT=date &quot;+%Y-%m-%d_%H:%M:%S&quot;export HISTFILE=”/tmp/dbasky/${LOGNAME}/${USER_IP} dbasky.$DT”chmod 600 /tmp/dbasky/${LOGNAME}/dbasky 2&gt;/dev/nullPS1=”whoami@hostname:”‘[$PWD]’historyUSER_IP=who -u am i 2&gt;/dev/null| awk &#39;{print $NF}&#39;|sed -e &#39;s/[()]//g&#39;if [ “$USER_IP” = “” ]thenUSER_IP=hostnamefiif [ ! -d /tmp/dbasky ]thenmkdir /tmp/dbaskychmod 777 /tmp/dbaskyfiif [ ! -d /tmp/dbasky/${LOGNAME} ]thenmkdir /tmp/dbasky/${LOGNAME}chmod 300 /tmp/dbasky/${LOGNAME}fiexport HISTSIZE=4096DT=date &quot;+%Y-%m-%d_%H:%M:%S&quot;export HISTFILE=”/tmp/dbasky/${LOGNAME}/${USER_IP} dbasky.$DT”chmod 600 /tmp/dbasky/${LOGNAME}/dbasky 2&gt;/dev/nullPS1=”whoami@hostname:”‘[$PWD]’historyUSER_IP=who -u am i 2&gt;/dev/null| awk &#39;{print $NF}&#39;|sed -e &#39;s/[()]//g&#39;if [ “$USER_IP” = “” ]thenUSER_IP=hostnamefiif [ ! -d /tmp/dbasky ]thenmkdir /tmp/dbaskychmod 777 /tmp/dbaskyfiif [ ! -d /tmp/dbasky/${LOGNAME} ]thenmkdir /tmp/dbasky/${LOGNAME}chmod 300 /tmp/dbasky/${LOGNAME}fiexport HISTSIZE=4096DT=date &quot;+%Y-%m-%d_%H:%M:%S&quot;export HISTFILE=”/tmp/dbasky/${LOGNAME}/${USER_IP} dbasky.$DT”chmod 600 /tmp/dbasky/${LOGNAME}/dbasky 2&gt;/dev/nullPS1=”whoami@hostname:”‘[$PWD]’historyUSER_IP=who -u am i 2&gt;/dev/null| awk &#39;{print $NF}&#39;|sed -e &#39;s/[()]//g&#39;if [ “$USER_IP” = “” ]thenUSER_IP=hostnamefiif [ ! -d /tmp/dbasky ]thenmkdir /tmp/dbaskychmod 777 /tmp/dbaskyfiif [ ! -d /tmp/dbasky/${LOGNAME} ]thenmkdir /tmp/dbasky/${LOGNAME}chmod 300 /tmp/dbasky/${LOGNAME}fiexport HISTSIZE=4096DT=date &quot;+%Y-%m-%d_%H:%M:%S&quot;export HISTFILE=”/tmp/dbasky/${LOGNAME}/${USER_IP} dbasky.$DT”chmod 600 /tmp/dbasky/${LOGNAME}/dbasky 2&gt;/dev/nullPS1=”whoami@hostname:”‘[$PWD]’historyUSER_IP=who -u am i 2&gt;/dev/null| awk &#39;{print $NF}&#39;|sed -e &#39;s/[()]//g&#39;if [ “$USER_IP” = “” ]thenUSER_IP=hostnamefiif [ ! -d /tmp/dbasky ]thenmkdir /tmp/dbaskychmod 777 /tmp/dbaskyfiif [ ! -d /tmp/dbasky/${LOGNAME} ]thenmkdir /tmp/dbasky/${LOGNAME}chmod 300 /tmp/dbasky/${LOGNAME}fiexport HISTSIZE=4096DT=date &quot;+%Y-%m-%d_%H:%M:%S&quot;export HISTFILE=”/tmp/dbasky/${LOGNAME}/${USER_IP} dbasky.$DT”chmod 600 /tmp/dbasky/${LOGNAME}/dbasky 2&gt;/dev/null]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>linux记录用户操作</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[常用函数]]></title>
    <url>%2F2017%2F07%2F28%2Fpython_%E5%B8%B8%E7%94%A8%E5%87%BD%E6%95%B0%2F</url>
    <content type="text"><![CDATA[isinstance判断一个对象是否是一个已知的类型，类似 type()isinstance() 与 type() 区别： type() 不会认为子类是一种父类类型，不考虑继承关系。 isinstance() 会认为子类是一种父类类型，考虑继承关系。 例如 class A: pass class B: pass isinstance(A(), A) # reutrn True type(A()) == A # return True isinstance(B(), A) # return True type(B()) == A # return False Iterable判断一个对象是否可迭代 例如 >>> from collections import Iterable >>> isinstance('abc', Iterable) # str是否可迭代 True >>> isinstance([1,2,3], Iterable) # # list是否可迭代 True >>> isinstance(123, Iterable) # 整数是否可迭代 False enumerate把一个list变成索引-元素对，这样就可以在for循环中同时迭代索引和元素本身 例如 >>> for i, value in enumerate(['a', 'b', 'c']): ... print(i, value) ... (0, 'a') (1, 'b') (2, 'c')]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>python常用函数整理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[正则]]></title>
    <url>%2F2017%2F07%2F20%2Fpython_%E6%AD%A3%E5%88%99%2F</url>
    <content type="text"><![CDATA[正则表达式字符 \d： 数字 \w： 字母 \t： 制表符 . ： 除回车外所有字符 次数 *： 大于等于0 +： 大于等1 {m}： 次数 {m,n}： {3,5}从3到5 re.match和re.searchre.match: 给出的字符串起始位置去匹配 re.search: 整个字符串去匹配 例子 import re result1 = re.match(&apos;\d+&apos;, &apos;a123fdsa234f4532&apos;) result2 = re.search(&apos;\d+&apos;, &apos;a123fdsa234f4532&apos;) print(result1) print(result2) 结果 None &lt;_sre.SRE_Match object; span=(1, 4), match=&apos;123&apos;&gt; 上面可看到，如果没有返回None，否则返回一个对象，如果要取到值则为print(result2.group())。 re.findall一直找到所有相关匹配项（适合一次，100次需要编译一百次）。 例子 result3 = re.findall(&apos;\d+&apos;,&apos;a123fdsa234f4532&apos;) print(result3) 结果 [&apos;123&apos;, &apos;234&apos;, &apos;4532&apos;] re.compile返回一个对象需要用findall函数获取字符串来匹配（适合多次）。 例子 com = re.compile(&apos;\d+&apos;) print(com.findall(&apos;a123fdsa234f4532&apos;)) 结果 [&apos;123&apos;, &apos;234&apos;, &apos;4532&apos;] re.group和re.groups re.group： 获取所有 re.groups：（只获取组里面（括号里）的匹配值） 例子 result3 = re.search(&apos;(\d+)fdsa(\d+)&apos;, &apos;a123fdsa234f4532&apos;) print(result3.group()) print(result3.groups()) 结果 123fdsa234 (&apos;123&apos;, &apos;234&apos;) 查找IP 例子 ip = &apos;12.32.123.432.23432fdsa+fds;fdsa192.23.32.44_fdsa#@9ds&apos; print(re.findall(&apos;(?:\d{1,3}\.){3}\d{1,3}&apos;, ip)) 结果 [&apos;12.32.123.432&apos;, &apos;192.23.32.44&apos;]]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>python正则</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[rpm安装报错：]]></title>
    <url>%2F2017%2F06%2F15%2Funtitled%2F</url>
    <content type="text"></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[zabbix 监控cpu load]]></title>
    <url>%2F2017%2F03%2F12%2Fzabbix_%E7%9B%91%E6%8E%A7CPUload%2F</url>
    <content type="text"><![CDATA[场景 zabbix的cpu load要与系统（linux）上的对应（top）； 服务器的CPU核数不一致； 监控CPU核数总数/2触发报警； 思路 要动态获取zabbix-agent的core； 两个监控项目对比的差异（cpu_load&gt;cpu_num/2）并触发相关报警。 解决办法方法一 在各agent端配置自定义key，并在zabbix-server上设置相关触发器； 方法二 zabbix-server从触发器入手，直接动态获取； 方法一固然可行，但是在服务器数量庞大的基础下，虽然通过ansible等之类的工具把自定义key推送过去后再配置触发器，这样是不是有点“笨拙”？能不能从zabbix-server现有的key中寻找另一条路呢？答案当然是可以的！ 关键的两个key system.cpu.load[all,avg1] #1分钟的所有核数负载值 system.cpu.num 系统总核数 自定义触发器可参考触发器表达式,通过对自定义触发器的了解，就可以进行配置相关操作！ 展示效果{Template OS Linux-18:system.cpu.load[all,avg1].min(5m)}&gt;{Template OS Linux-18:system.cpu.num.last()}/2 最近5分钟的负载大于一半的核数就触发报警]]></content>
      <categories>
        <category>zabbix</category>
      </categories>
      <tags>
        <tag>zabbix</tag>
        <tag>监控cpu load</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[书籍]]></title>
    <url>%2F2017%2F03%2F05%2F%E4%B9%A6%E7%B1%8D%2F</url>
    <content type="text"><![CDATA[书籍收藏 《自控力》]]></content>
      <categories>
        <category>书籍</category>
      </categories>
      <tags>
        <tag>Devops书籍</tag>
        <tag>书籍</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[zabbix低级发现]]></title>
    <url>%2F2017%2F02%2F24%2Fzabbix_%E4%BD%8E%E7%BA%A7%E5%8F%91%E7%8E%B0%2F</url>
    <content type="text"><![CDATA[一、(low level discover)概述 什么是lld ？即低水平自动发现，使用它可以自动创建项目、触发器及被监控主机上的实体图。如zabbix 可以自动监控主机上的文件系统和网络拉口，而不需要为每个监控项创建items 。此处，其也可以实现被监控项目的自动删除 。上面的话不是我的总结，是我从官方文档上翻译过来的话。 二、创建模版 由于创建模板不是本篇的重点，就不提创建模板的过程了 。这里重点提下如何在模板中创建自动发现规则。 1. 创建自动发现规则 步骤为：配置 –&gt; 模版 –&gt; 选中之前创建好的模版(这里我用 app discover) –&gt; 自动发现规则 –&gt; 创建发现规则 2. 选择监控项原型并创建监控项 名称：｛#DISCOVER} 自定义的宏变量（后续脚本会提到)； 类型：根据自身主动/被动模式选择； 键值：后续监控的自定义Key会提到。 3. 触发器类型 可根据自身情况做定义 三、客户端配置脚本（在配置发现的主机上配置，比如zabbix-server的agentd） 配置发现规则 这里发现规则是找的/app目录下的所有目录名（公司的所有项目都创建在/app目录下） cat check_app.py #!/usr/bin/env python #-*- coding:utf-8 -*- #@author: sundsinerj #@date: 2017/9/28 import os import json import getopt import sys #list app name app_list = os.listdir(os.path.expanduser("/app")) if 'lost+found' in app_list: del app_list[app_list.index('lost+found')] elif 'zabbix' in app_list: del app_list[app_list.index('lost+found')] elif 'tomcat-6.0.48_wp' in app_list: del app_list[app_list.index('lost+found')] opts, arge = getopt.getopt(sys.argv[1:],[]) #print appname for json pool_list = [] for appname in app_list: #def json data pool_list += [｛'｛#DISCOVER｝': appname｝] print json.dumps({'data': pool_list},sort_keys=True,indent=4,separators=(',',':')) 配置监控项规则 cat check_app.sh #! /bin/bash help() { echo "USAGE:`basename $0` [-n] the name of app" exit -1 } while getopts ":n" opt do case $opt in n) appname=$OPTARG ;; h) help ;; *) unkown=$OPTARG echo "error,plase check for help,USAGE:./`basename $0` -h" exit $STAT_UNKNOWN ;; esac done apppid=`ps aux | grep "$appname" | grep -v grep | wc -c` if [ $apppid -eq 0 ] then echo 0 exit 0 else echo 1 exit 1 fi 发现规则必需是json格式的 *｛#DISCOVER｝ 就是zabbix创建的模版的宏变量 check_app.sh脚本就是定义的监控项 四、自定义key cat userparameter_app.conf UserParameter=app.status[*],/bin/bash /etc/zabbix/zabbix_agentd.d/libexec/check_app.sh -n $1 UserParameter=app.discover,python /etc/zabbix/zabbix_agentd.d/libexec/check_app.py 五、验证在被发现的主机上关联app discover 模版就可以了。过会，就能看到相关的低级发现项目。]]></content>
      <categories>
        <category>zabbix</category>
      </categories>
      <tags>
        <tag>zabbix</tag>
        <tag>低级发现</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[zabbix报警]]></title>
    <url>%2F2017%2F02%2F23%2Fzabbix%E6%8A%A5%E8%AD%A6%2F</url>
    <content type="text"><![CDATA[概述当zabbix server预定义或自定义的触发器生效后，就要通过告警邮件、短信、微信等接口通知相关人员，并且zabbix server还设置了报警升级，可根据自身情况进行设置。 ##配置 一、 zabbix-server脚本指定位置1vim zabbix_server.conf AlertScriptsPath=/etc/zabbix/alertscripts 二、 报警类型（这里主要讲邮件和短信，后期会补上微信） 邮件 邮件报警需要提供三个参数（收件人、主题、内容）,邮件需要安装sendemail可见安装sendemail 1cat /etc/zabbix/alertscripts/sendEmail.sh #!/bin/bash to=$1 subject=$2 body=$3 /usr/local/bin/sendEmail -f ex@uu.com -t "$to" -u "$subject" -o message-content-type=html -o message-charset=utf8 -xu ex@uu.com -xp xxxx -m "$body" ############ /usr/local/bin/sendEmail 命令主程序 -f from@163.com 发件人邮箱 -t to@163.com 收件人邮箱 -s smtp.163.com 发件人邮箱的smtp服务器 -u "我是邮件主题" 邮件的标题 -o message-content-type=html 邮件内容的格式,html表示它是html格式 -o message-charset=utf8 邮件内容编码 -xu from@163.com 发件人邮箱的用户名 -xp 123456 发件人邮箱密码 -m "我是邮件内容" 邮件的具体内容 -l /var/log/sendMyEmail.log 非必输项，邮件发送日志记录到日志文件 web配置 管理 &gt;&gt; 报警媒介类型 &gt;&gt; 创建媒体类型 名称： 自定义 类型： 脚本 脚本参数： {ALERT.SENDTO} {ALERT.SUBJECT} {ALERT.MESSAGE} 管理 &gt;&gt; 用户 &gt;&gt; 报警媒介 配置 &gt;&gt; 动作 &gt;&gt; 触发器类型下新建动作 名称：Zabbix-Server告警邮件 默认接收人：主机： {HOSTNAME1} 状态：{TRIGGER.STATUS} 默认信息： 告警主机:&nbsp;{HOSTNAME1} 告警时间:&nbsp;{EVENT.DATE}{EVENT.TIME} 告警等级:&nbsp;{TRIGGER.SEVERITY} 告警信息:&nbsp;{TRIGGER.NAME} 告警项目:&nbsp;{TRIGGER.KEY1} 问题详情:&nbsp;{ITEM.NAME}:&nbsp;{ITEM.VALUE} 当前状态:&nbsp;{TRIGGER.STATUS}:&nbsp;{ITEM.VALUE1} 事件ID:&nbsp;{EVENT.ID} 恢复主题：主机： {HOSTNAME1} 状态：{TRIGGER.STATUS}！！ 恢复信息：同上 - 条件 ![](https://raw.githubusercontent.com/sundshinerj/img/master/zabbix_%E6%8A%A5%E8%AD%A6_%E9%82%AE%E4%BB%B6%E6%8A%A5%E8%AD%A6_%E5%8A%A8%E4%BD%9C%E6%9D%A1%E4%BB%B6.png) - 操作 ![](https://raw.githubusercontent.com/sundshinerj/img/master/zabbix_%E6%8A%A5%E8%AD%A6_%E9%82%AE%E4%BB%B6%E6%8A%A5%E8%AD%A6_%E5%8A%A8%E4%BD%9C%E6%93%8D%E4%BD%9C.png) 步骤：可以指定报警升级 至此，邮件报警配置完成！ 短信 短信就是调用短息商提供的短信接口，参数里需要填写两个（收件人、内容） 名称： 自定义 类型： 脚本 脚本参数： {ALERT.SENDTO} {ALERT.MESSAGE} 代码 1cat sendSms.py #! /usr/bin/python #encoding:utf-8 import requests import json import urllib import hashlib import os import sys import subprocess import datetime reload(sys) #设置字符集，否则再输出重定向时出编码错误 sys.setdefaultencoding('utf-8') #请求主题参数 def phonelist(plist): phonelist=plist.split(",") return phonelist def requestinterface(strp): url="http://test.com?sname=接口用户名&spwd=接口密码" #定义一个字典，值为请求的参数 param={} param['sdst']=strp param['smsg']=sys.argv[2] str3=url+'sdst='+param['sdst']+'&smsg='+urllib.quote(param['smsg']+'【标题】') r = requests.get(str3,verify=False) if __name__ == '__main__': #now=datetime.datetime.now().strftime('%Y-%m-%d-%H') #os.system("touch sendsms.`date +\'%F-%H\'`") #print fname #f = open('sendsms.'+str(now),'a') #f.write(sys.argv[1]+' -- '+sys.argv[2]+' '+str(now)+'\n') plist=phonelist(sys.argv[1]) for i,value in enumerate(plist): sms=requestinterface(value) 至此，短信报警配置完成。]]></content>
      <categories>
        <category>zabbix</category>
      </categories>
      <tags>
        <tag>zabbix</tag>
        <tag>zabbix 报警配置</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[zabbix_agent主动模式]]></title>
    <url>%2F2017%2F02%2F23%2Fzabbix_agent%E4%B8%BB%E5%8A%A8%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[概述当zabbix-server监控主机过多时候，由于server端去搜集信息，zabbix会出现严重的性能问题，比如: 当监控端到一个量级的时候，web操作界面很卡，容易出现502； 图层断裂； 开启的进程太多，即使item数量减少，以后加一定量的机器也会出现问题。 所以主要往2个优化方面考虑： 添加proxy节点或者node模式做分布式监控； 调整agentd为主动模式。 由于第一个方案需要物理节点，所以尝试第二个方案。 主动模式： 主动模式一定要记得设置ServerActive=ServerIP Agent向Server建立一个TCP连接 Agent请求需要检测的数据列表 Server响应Agent，发送一个Items列表 Agent允许响应 TCP连接完成本次会话关闭 Agent开始周期性地收集数据 一、 被监控端zabbix_agentd.conf的配置调整1vim /etc/zabbix/zabbix_agentd.conf StartAgents=0 #客户端的anent的模式，0表示关闭被动模式，zabbix-agentd不监控本地端口，所以看不到zabbix_agentd进程 #Server=172.16.100.84 #如果设置纯被动模式，应该注释掉这行 ServerActive=172.16.100.84 #主动模式的serverip地址 Hostname=172.16.100.47 #客户端的hostname，不配置则使用主机名 RefreshActiveChecks=120 #被监控端到服务器获取监控项的周期，默认120S BufferSize=200 #被监控端存储监控信息的空间大小 Timeout=3 #超时时间 纯主动监控模式下的zabbix agent，只能支持zabbix agent (active)类型的监控项 二、 调整监控模版 克隆一个temple os linux模版来修改 全选 找到最下方的批量更新 类型打勾，选择主动式，然后更新 主机修改 添加完成之后，你会发现zabbix的Z灯不亮，因为服务器是基于被动模式的 这时候就有相关数据，如果硬盘或网卡监控没有数据 模板&gt;&gt;主动监控模板名称&gt;&gt;自动发现规则 选择监控项原型-进去之后一个个点击，修改成主动式监控，在模版修改只，主动就会自动应用 过会，网卡和硬盘的监控情况就出来了。]]></content>
      <categories>
        <category>zabbix</category>
      </categories>
      <tags>
        <tag>zabbix</tag>
        <tag>主动模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[zabbix问题汇总]]></title>
    <url>%2F2017%2F02%2F23%2Fzabbix%E9%97%AE%E9%A2%98%E6%B1%87%E6%80%BB%2F</url>
    <content type="text"><![CDATA[一、agent连接正常，server端报agent.ping问题由来zabbix-server迁移到server2上，zabbix架构为zabbix-agent –&gt; zabbix_proxy –&gt; zabbix_server； zabbix-server迁移进行时，zabbix_proxy没做停止，zabbix-server迁移完成后，zabbix_proxy指定的还是server1。这时，zabbix-server2收不到所有zabbix_proxy的数据，因此产生大量报警，当zabbix_proxy的Server字段改为zabbix-server2后，数据同步了，但是极有可能造成zabbix-server下的部分agent节点的触发器agent.ping还没有得到响应，而迁移后的数据也能在新的server上展示。 解决办法把有问题的agent节点关闭，等待server端重新出发一次agent.ping（相当于更新下之前的状态）,当server收到新的报警后，再把问题agent启动。这样就能覆盖掉问题agent.ping。 二、报警风暴由来当大量zabbix_agent单位时间内连接超时，故障修复后，会产生大量的报警信息（比如：邮件、短信）。这些人为已经预知的情况下，其实不想在收到通知！ 解决办法比如zabbix_server调用的邮件通知，把邮件脚本改成： 1echo `date` &gt;&gt; /tmp/sms.txt 这样的操作很明显能弯路思想改善接受大量报警信息。]]></content>
      <categories>
        <category>zabbix</category>
      </categories>
      <tags>
        <tag>zabbix</tag>
        <tag>监控问题汇总</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ansible问题汇总，不断更新中...]]></title>
    <url>%2F2017%2F02%2F23%2Fansible%E9%97%AE%E9%A2%98%E6%B1%87%E6%80%BB%2F</url>
    <content type="text"><![CDATA[一、通过ssh代理传输文件超时hosts配置文件 12[TestServer]172.16.0.129 ansible_ssh_port=12345 ansible_ssh_common_args=&apos;-o ProxyCommand=&quot;ssh -q -p33115 root@111.222.333.444 nc %h %p&quot;&apos; 应用synchronize模块时提示类似如下信息： 123456789[root@xyzl-test3 ansible]# ansible TestServer -i /opt/App/ansible/TestServerHosts -m synchronize -a &quot;src=/opt/JenkinsCache/TestServer/TestServer.tar.gz dest=/opt/JenkinsCache/TestServer/&quot; [WARNING]: Invalid characters were found in group names but not replaced, use -vvvv to see details172.16.0.129 | FAILED! =&gt; &#123; &quot;changed&quot;: false, &quot;cmd&quot;: &quot;/bin/rsync --delay-updates -F --compress --archive --rsh=/bin/ssh -S none -o Port=33115 -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null --out-format=&lt;&lt;CHANGED&gt;&gt;%i %n%L /opt/JenkinsCache/TestServer/TestServer.tar.gz 172.16.0.129:/opt/JenkinsCache/TestServer/TestServer/&quot;, &quot;msg&quot;: &quot;ssh: connect to host 172.16.0.129 port 12345: Connection timed out\r\nrsync: connection unexpectedly closed (0 bytes received so far) [sender]\nrsync error: unexplained error (code 255) at io.c(226) [sender=3.1.2]\n&quot;, &quot;rc&quot;: 255&#125; 因改成copy模块： 1234567891011121314151617181920[root@xyzl-test3 ansible]# ansible TestServer -i /opt/JenkinsCache/TestServer/TestServerHosts -m copy -a &quot;src=/opt/JenkinsCache/TestServer/TestServer.tar.gz dest=/opt/JenkinsCache/TestServer/TestServer/&quot; [WARNING]: Invalid characters were found in group names but not replaced, use -vvvv to see details172.16.0.129 | CHANGED =&gt; &#123; &quot;ansible_facts&quot;: &#123; &quot;discovered_interpreter_python&quot;: &quot;/usr/bin/python&quot; &#125;, &quot;changed&quot;: true, &quot;checksum&quot;: &quot;f91ea3c7d14223d73cd5ac667112388b13f8b8f4&quot;, &quot;dest&quot;: &quot;/opt/JenkinsCache/TestServer/TestServer.tar.gz&quot;, &quot;gid&quot;: 0, &quot;group&quot;: &quot;root&quot;, &quot;md5sum&quot;: &quot;76cf7a69de2786d77327ab59f803fe1c&quot;, &quot;mode&quot;: &quot;0644&quot;, &quot;owner&quot;: &quot;root&quot;, &quot;size&quot;: 40923749, &quot;src&quot;: &quot;/root/.ansible/tmp/ansible-tmp-1570589569.14-59930443509260/source&quot;, &quot;state&quot;: &quot;file&quot;, &quot;uid&quot;: 0&#125;]]></content>
      <categories>
        <category>ansible</category>
      </categories>
      <tags>
        <tag>ansible</tag>
        <tag>ansible问题汇总</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[监控网络设备]]></title>
    <url>%2F2017%2F02%2F23%2Fzabbix_monito%2F</url>
    <content type="text"><![CDATA[一、zabbix-server端安装snmp工具1yum -y install net-snmp-utils snmp-libs snmp-devel snmp 二、检测与路由器的连通性测试之前工作 路由上要开启snmp功能 本地snmp服务器的snmp的密码和路由上的密码一致 1vim /etc/snmp/snmpd.conf 测试连通性 1snmpwalk -v 2c -c 19e#! 10.18.221.4 - 2c：协议版本 - 19e#!：密码与路由一致， - 10.18.221.4：路由IP 注意selinux、iptables 如果出现上面信息说明成功 三、zabbix-server添加路由监控主机 –&gt; 创建主机 由于添加了密钥认证，须在zabbix-server中添加密钥管理–&gt;一般–&gt;选择宏，进行设置 过几分钟就能出相关监控项了！]]></content>
      <categories>
        <category>zabbix</category>
      </categories>
      <tags>
        <tag>zabbix</tag>
        <tag>监控网络设备</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[zabbix代理(proxy)]]></title>
    <url>%2F2017%2F02%2F23%2Fzabbix_proxy%2F</url>
    <content type="text"><![CDATA[概述zabbix proxy可以代替zabbix server收集性能和可用性数据，然后把数据汇报给zabbix server，并且在一定程度上分担zabbix server的压力，具体可见官方文档。 样例 服务列表 | 名称 | IP | |——–|:——–:| | zabbix server | 10.18.12.98 | | zabbix proxy | 10.18.12.93 | | zabbix agent | 10.18.12.63 | zabbix agent配置文件 cat /etc/zabbix_agentd.conf LogFile=/log/zabbix/zabbix_agentd.log PidFile=/log/zabbix/zabbix_agentd.pid StartAgents=0 ServerActive=10.18.12.93 RefreshActiveChecks=120 BufferSend=5 BufferSize=100 Hostname=10.18.12.63 DebugLevel=3 Timeout=20 MaxLinesPerSecond=100 AllowRoot=1 Include=/etc/zabbix/zabbix_agentd.d/*.conf ServerActive: 代理节点IP zabbix proxy配置文件 cat /etc/zabbix/zabbix_proxy.conf Server=10.18.12.98 Hostname=Zabbix_proxy_18 LogFile=/log/zabbix/zabbix_proxy.log DebugLevel=3 DBName=zabbix DBUser=zabbix DBPassword=zabbix ProxyLocalBuffer=0 ProxyOfflineBuffer=1 ConfigFrequency=30 DataSenderFrequency=30 StartPollers=100 StartPollersUnreachable=1 StartTrappers=200 StartPingers=1 CacheSize=64M TrapperTimeout=30 Timeout=10 LogSlowQueries=3000 Server: zabbix server IP Hostname: 代理节点IP DB* 由于代理节点要暂存agent传来的数据，所以，要先把数据缓存在本地(proxy)数据库中，再定时和zabbix server进行数据交互； zabbix server配置文件 无 web端配置 1) 添加代理节点 管理&gt;&gt;agent代理程序&gt;&gt;创建代理 样例中配置的名称是zabbix_proxy_18 2) 在agent主机的最下方选择zabbix_proxy_18 完成配置后生效 过会在zabbix proxy服务端查看相关日志，如果里面有zabbix agent的数据展示信息，证明zabbix proxy配置成功。]]></content>
      <categories>
        <category>zabbix</category>
      </categories>
      <tags>
        <tag>zabbix</tag>
        <tag>zabbix-proxy</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[字段和方法]]></title>
    <url>%2F2016%2F10%2F23%2F%E5%AD%97%E6%AE%B5%E5%92%8C%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[首先，要知道Python类中两个概念：字段和方法“字段”和“方法”都有“动态”和“静态”之分，即： 字段 静态字段 动态字段 方法 静态方法 动态方法 以下事例标明了：“静态字段”，“动态字段”以及“动态方法”是什么样子的，因为显而易见，就不用语言进行过多描述： #coding:utf-8 class Car: # 下面是静态字段 memo = u'车辆具有出厂合格证' def __init__(self, brand, model, speed, price, engine): # 下面是动态字段 self.Brand = brand self.Model = model self.Speed = speed self.Price = price self.__EngineType = engine # 下面是动态方法 def Turnleft(self): print self.Brand + u'开始向右转向。' 上述事例中，并没有展现“静态方法”，那么“静态方法”长什么样子？如何生成？其实“静态方法”只需要执行两步操作，就可以转换成“静态方法” 在方法前加上 @staticmethod 把“动态方法”括号中的“self”去掉 如： @staticmethod def Forward(): print u'开始向前进' 那么关于这四种类型，有什么特点？以下进行总结： 四种类型，均可以被“对象”进行调用，但不建议使用“对象”调用“静态方法”和“静态字段”，而建议使用“类”对其进行调用 “动态方法”和“动态字段”只能由“对象”进行调用，而无法使用“类”进行调用]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>字段和方法说明</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx http协议基础及IO模型]]></title>
    <url>%2F2016%2F05%2F11%2Fnginx_http%E5%8D%8F%E8%AE%AE%E5%9F%BA%E7%A1%80%E5%8F%8AIO%E6%A8%A1%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[Nginx通常作为两种应用，既： Web Server Web Reverse Proxy 做为web服务器最核心的是http协议（全称：HyperText Transfer Procotol）–超文本传输协议，主要用于传输超文本（超文本又称html(HyperText Mark Language)语言开发的文本或者html语言标记的文本）。而HTTP协议默认工作在80端口上。在http1.0之前只支持超文本传输，但是从1.0以后由于引入了MIME（Multipurpost Internet Mail Extension）机制（接受非文本，但能转换城文本格式进行传输，而到客户端时又能还原成原有协议的编码方案）。 互联网上访问一个资源是根据URL标记定义的，其基本语法是：scheme(协议)://server[:port]/path/to/source。 http事务由两部分组成： request 格式： &lt;body&gt; response 格式： &lt;HEADERS&gt; &lt;body&gt; method包括： GET HEADE POST PUT DELETE TRACE OPTIONS status: 1xx: 信息类 2xx: 成功类 3xx: 重定向 301 302 304 4xx: 客户端错误 404 401 5xx: 502 504 HEADE: 通用首部 请求首部 If-Modified-Since、IF-None-Match 响应首部 实体首部 扩展首部]]></content>
      <categories>
        <category>nginx</category>
      </categories>
      <tags>
        <tag>nginx</tag>
        <tag>http协议及IO模型</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[工作原理整理中...]]></title>
    <url>%2F2016%2F05%2F11%2Fnginx%2F</url>
    <content type="text"><![CDATA[初探nginx在启动后，会以daemon的形式在后台运行，后台进程包括一个master和多个worker进程，而master主要管理worker，包含： 接收来自外界的信号； 向各worker进程发送信号； 监控worker进程的运行状态（如果worker挂掉，会自动重新创建新的worker）。 worker之间是对等关系，他们同等竞争来自客户端的请求，各进程互相之间是独立的。一个请求只可能在一个worker进程中处理，一个worker进程，不可能处理其它进程的请求。worker进程的个数是可以设置的，一般我们会设置与机器cpu核数一致，这里面的原因与nginx的进程模型以及事件处理模型是分不开的。nginx的进程模型，可以由下图来表示： 图中可以看到master为主进程，我们只需要控制master就可以了，比如： kill -HUP pid,从容地重启nginx，他们会首先创建一个新的worker，并向老的worker发送关闭的信号，这样新老交替，就能完成平滑重启了。 当所有worker都处于listen时，当一个请求过来时，所有worker都有可能处理这个请求，nginx怎么处理呢？ worker之间的信息处理前面提到，每个worker是平等的，首先，在master进程里，先建立好需要的listen的socket（listenfd）之后，然后再fork出多个worker进程，此时worker的listenfd在连接到来时是只读的。为保证只有一个进程处理该连接，所有worker进程在注册listenfd读事件前抢accept_mutex（互斥锁），在抢到accept_mutex后就注册listenfd读事件，在该读事件里调用accept接受该连接，一切完成后就读取、解析、处理请求并返回给客户端了，可以看到，一个请求只有一个worker来处理，并只在一个worker中处理。 一个woker处理一个请求，那高并发是怎么做的呢？ 高并发处理原理nginx采用异步非阻塞方式来处理请求，那异步非阻塞是什么意思呢？先看下完整的请求过程：请求到来 –&gt; 建立连接 –&gt; 接受数据 –&gt; 发送数据，具体到系统底层就是读写事件。那阻塞与非阻塞是什么意思呢？ 阻塞 事件没有准备好，那就只能等了，等事件准备好了，才可以继续。 此时，阻塞调用会进入内核等待。 非阻塞 事件没有准备好，马上返回EAGAIN，让你先去干别的，过会再来看是否OK，等准备好了再继续。 虽然不阻塞了，但你时不时地过来检查事件状态，带来的开销也是很大的。所以，才会用到异步处理，具体到系统调用就是像select/poll/epoll/kqueue这样的系统调用。它们提供了一种机制，让你可以同时监控多个事件，调用他们是阻塞的，但可以设置超时时间，在超时时间之内，如果有事件准备好了，就返回。这种机制正好解决了我们上面的两个问题。拿epoll来说： 1. 当事件没准备好时，放到epoll里； 2. 事件准备好了，就去读写； 3. 如果返回EAGAIN时，再次放到epoll里； 4. 当所有事件都没准备好时，才在epoll里等待。 这样，就能接受持续不断的请求了–&gt;高并发。当然，这里的并发请求，是指未处理完的请求，线程只有一个，所以同时能处理的请求当然只有一个了，只是在请求间进行不断地切换而已，切换也是因为异步事件未准备好，而主动让出的。这里的切换是没有任何代价，你可以理解为循环处理多个准备好的事件，事实上就是这样的。与多线程相比，这种事件处理方式是有很大的优势的，不需要创建线程，每个请求占用的内存也很少，没有上下文切换，事件处理非常的轻量级。并发数再多也不会导致无谓的资源浪费（上下文切换）。更多的并发数，只是会占用更多的内存而已。 对于web服务器，事件通常有三种类型：网络事件、信号和定时器： 网络事件 通过异步非阻塞能解决问题 信号 nginx正在等待事件（epoll_wait）时，如果程序收到信号，在信号处理函数处理完后，epoll_wait会返回错误，然后程序可再次进入epoll_wait调用。 定时器 由于epoll_wait等函数在调用的时候可以设置一个超时时间，nginx借用这个超时时间来实现定时器。 connectionconnection是对TCP的封装，包括连接的socket，读/写事件。利用connection来处理与连接相关的事情，比如，建立连接，发送与接收数据等。而且nginx中的http请求的处理就是建立在connection之上。 所以，nginx不仅可以做webServer,还能做sendMail。 request在nginx中则是http请求，结构体为：ngx_http_request_t。ngx_http_request_t是对一个http请求的封装。一个http请求包含：请求行、请求头、请求体、响应行、响应头、响应体。 未完待续。。。]]></content>
      <categories>
        <category>nginx</category>
      </categories>
      <tags>
        <tag>nginx</tag>
        <tag>nginx工作原理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux非root用户文件描述符限制]]></title>
    <url>%2F2015%2F02%2F27%2Flinux%E9%9D%9Eroot%E7%94%A8%E6%88%B7%E6%96%87%E4%BB%B6%E6%8F%8F%E8%BF%B0%E7%AC%A6%E9%99%90%E5%88%B6%2F</url>
    <content type="text"><![CDATA[描述在一次生产环境下切换非root用户，导致如下错误等待： 123456[root@xy_Tomcat_1 exam-service]# su - java-bash: fork: retry: Resource temporarily unavailable-bash: fork: retry: Resource temporarily unavailable-bash: fork: retry: Resource temporarily unavailable-bash: fork: retry: Resource temporarily unavailable-bash: fork: retry: Resource temporarily unavailable 通常上述问题发现是由于非root用户默认打开文件描述符为1024： 12345678cat /etc/security/limits.d/90-nproc.conf# Default limit for number of user&apos;s processes to prevent# accidental fork bombs.# See rhbz #432903 for reasoning.* soft nproc 1024root soft nproc unlimited 解决只要把非root用户值改为合适本身环境即可]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>非root用户最大连接数配置</tag>
        <tag>ulimit</tag>
      </tags>
  </entry>
</search>
